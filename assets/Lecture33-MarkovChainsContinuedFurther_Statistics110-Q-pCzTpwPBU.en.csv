text,start,stop
"Okay, so
we'll finish up Markov chains today, and",00:00:00.700,00:00:04.649
"welcome to our Pen
ultimate Stat 110 lecture.",00:00:04.649,00:00:08.430
"So remind me what we were doing well last
time, we were talking about reversible.",00:00:08.430,00:00:13.985
"Well a lot of things got Markov chains,
but most importantly last time,",00:00:13.985,00:00:17.687
"we're talking about
reversible Markov chains.",00:00:17.687,00:00:20.250
"We did the example, a random walk
on an undirected network, right?",00:00:20.250,00:00:25.290
"And there's another important example
of reversible MArkov chains is",00:00:25.290,00:00:29.850
"birth-death chains, which I think
you can read about on the handout.",00:00:29.850,00:00:34.410
"It's worth working it through, but
I wanted to talk about one kind of",00:00:34.410,00:00:38.538
"generalization while we're still
talking about reversible Markov chains.",00:00:38.538,00:00:43.690
"So just to remind you from last time, and
then we'll try to extend it a little bit.",00:00:43.690,00:00:48.760
"We were looking at random undirected
graph or undirected network.",00:00:48.760,00:00:54.650
"It looks something like,
I'm just gonna draw a picture.",00:00:54.650,00:00:57.909
"You have a bunch of nodes and
some of them have edges between them and",00:00:57.909,00:01:03.709
"they're not one way arrows, right?",00:01:03.709,00:01:07.040
"They're bidirectional, so you can go,
let say from 1 to 2 and 2 to 4 and",00:01:07.040,00:01:12.877
"1 to 4 and 3 to 4 and
maybe there's a 5 here that can goes to 3.",00:01:12.877,00:01:17.992
"And so whatever we wanna draw,
we have a picture that looks like this.",00:01:17.992,00:01:22.720
"And if we want, we can add loops which
we didn't worry about last time.",00:01:22.720,00:01:27.460
"But it's no big deal, we could have
an edge connecting it, a node to itself.",00:01:27.460,00:01:33.340
"The only thing we have to be careful about
there is there are different conventions",00:01:33.340,00:01:36.360
"for what does this
contribute to the degree.",00:01:36.360,00:01:39.200
"So remember the degree of each node
is just the number of edges and",00:01:39.200,00:01:43.020
"some people like to count the degree
in different ways for this.",00:01:43.020,00:01:46.350
Well let's just assume this counts as 1.,00:01:46.350,00:01:47.984
"So in this picture node 1 has degree 3,
cuz there's this edge to itself,",00:01:47.984,00:01:52.803
and then two edges that are going out.,00:01:52.803,00:01:55.530
"We got a picture that looks like this,
and we proved last time that",00:01:55.530,00:01:59.805
"the stationary probability of any node
is proportional to its degree, right?",00:01:59.805,00:02:05.032
"And that is, we don't have to do
any matrix calculations at all.",00:02:05.032,00:02:10.470
"If we want the stationary
distribution of the Markov chain,",00:02:10.470,00:02:12.840
"which is just randomly wandering
around on this network.",00:02:12.840,00:02:15.126
"All we have to do is list out
the vector of all the degrees.",00:02:15.126,00:02:19.200
"This has degree 3, this has degree 2, and
just count the number of edges, right?",00:02:19.200,00:02:26.282
"And then normalize that vector,
so that multiply by a constant so",00:02:26.282,00:02:29.444
"that it adds up to 1, and
then that's the stationary distribution.",00:02:29.444,00:02:32.850
"We proved that last time
using reversibility.",00:02:32.850,00:02:35.520
"So now I wanted to extend
that a little bit and say,",00:02:35.520,00:02:39.594
"well what would actually happen if we,
so we were assuming last time that,",00:02:39.594,00:02:45.705
"let's say you're here at state 4 and
you see three choices.",00:02:45.705,00:02:50.880
"We assume they're all equally likely,
right?",00:02:50.880,00:02:52.648
"So one-third, one-third, one-third.",00:02:52.648,00:02:54.190
"So a natural question is
what happens if certain",00:02:54.190,00:02:59.110
"edges are more likely for
some reason, right?",00:02:59.110,00:03:04.060
"That they're unequal weights, so",00:03:04.060,00:03:06.498
"to handle that all we need to
do is put down some weights.",00:03:06.498,00:03:10.328
"So let's call this w12, I'm just gonna
put little weights on the edges.",00:03:10.328,00:03:17.560
"This is w11,
w14 I'm not gonna fill them all in.",00:03:17.560,00:03:21.286
"In general, let's say we have wij,
Greater than or",00:03:21.286,00:03:27.420
"equal to 0, we call that an edge weight.",00:03:27.420,00:03:29.530
"And let's assume that wij = 0,",00:03:32.431,00:03:37.936
"if there's no edge there, right?",00:03:37.936,00:03:43.842
"That just means you can't get
from i to j in one step, so",00:03:43.842,00:03:46.705
we just give that weight 0.,00:03:46.705,00:03:48.210
"And then the other ones,",00:03:48.210,00:03:50.940
"which is just let's say it's greater or
equal to well.",00:03:50.940,00:03:57.060
"We can assume it's strictly greater that
if they are actually is an edge, but",00:03:57.060,00:04:01.548
"it doesn't actually matter,
as long as we avoid dividing by 0.",00:04:01.548,00:04:05.359
"And then our key assumption is that
wij = wji, that's an assumption.",00:04:05.359,00:04:11.010
Another way to say that is because we're,00:04:11.010,00:04:15.861
talking about random undirected network.,00:04:15.861,00:04:21.149
"And I only wrote one number here, w12.",00:04:21.149,00:04:23.770
"Maybe w12 is 3, it's just some number.",00:04:23.770,00:04:27.100
"But I'm not allowed to write one number
that applies going this direction,",00:04:27.100,00:04:30.727
"and another number that applies this
direction, so the same number, okay?",00:04:30.727,00:04:34.421
"So we may as well just express that
as a symmetry condition, wij = eji.",00:04:34.421,00:04:40.984
"And now the way the random walk proceeds
is that, so here's our random walk,",00:04:40.984,00:04:46.557
"analogous to what we did before, except
we're generalizing with these weights.",00:04:46.557,00:04:52.850
"All we do is we say, okay,
suppose that we are at state 4, and",00:04:52.850,00:04:58.466
"then I see there's 3 different possible
edges, and each one has its weight.",00:04:58.466,00:05:05.607
And we look at these three choices and,00:05:05.607,00:05:07.560
"then we just choose proportional
to the weights, right?",00:05:07.560,00:05:11.025
"So if we let all the weights be 1, then
we do one-third, one-third, one-third,",00:05:11.025,00:05:14.125
"but maybe w24 is relatively larger, right?",00:05:14.125,00:05:18.745
It's just proportional.,00:05:18.745,00:05:19.821
"So from state i,",00:05:19.821,00:05:21.745
"Go to j with probability
proportional to wij.",00:05:26.134,00:05:34.706
"Looks like an alpha, that's
proportionality symbol to wij, okay?",00:05:34.706,00:05:43.630
"So if wij is 0,
then obviously it says we don't go there.",00:05:43.630,00:05:47.565
"So we look at all
the available choices and",00:05:47.565,00:05:50.284
"choose what probability's
proportional to the weights we see.",00:05:50.284,00:05:54.569
"So that's the generalization
of the problem, and",00:05:54.569,00:05:59.544
let's solve in an analogous way.,00:05:59.544,00:06:02.910
"This is still gonna be reversible, so",00:06:02.910,00:06:06.225
"we wanna write down reversibility
equation siqij = sjqji.",00:06:06.225,00:06:11.530
"Okay, let's first write down what's qij?",00:06:11.530,00:06:15.876
"So if ij is actually an edge,",00:06:15.876,00:06:17.652
"if it's not an edge the probability
is 0 going from i to j.",00:06:17.652,00:06:21.280
"If it is an edge,
that is there is an edge there,",00:06:21.280,00:06:24.680
"Then by definition qij,
the transition probability",00:06:27.172,00:06:32.249
"from state i to state j by
definition is just the weight",00:06:32.249,00:06:37.322
"divided by the sum of
the possible weights.",00:06:37.322,00:06:41.520
"That is the sum of the weights
of the possible steps, right?",00:06:41.520,00:06:45.050
"Code proportional, so this'll be the
denominator will just be the sum of wik,",00:06:45.050,00:06:51.178
"over all k, All right?",00:06:51.178,00:06:56.290
"And we're assuming that the denominator is
non-zero, because we have to be able to",00:06:56.290,00:07:01.202
"do something, so
we don't all weight 0, all right?",00:07:01.202,00:07:04.400
"So that's the random walk,
but notice that then",00:07:04.400,00:07:09.659
"it's true that if we, so
in the case without weights,",00:07:09.659,00:07:15.556
"just think of all these wijs as one,
right?",00:07:15.556,00:07:20.320
"And so then this is just one over
the degree of i in that case.",00:07:20.320,00:07:23.610
"And in that case, the stationary
distribution proportional to degrees.",00:07:23.610,00:07:29.370
"So the analogue of that is that instead
of the degree we're looking at the sum of",00:07:29.370,00:07:33.943
the weights.,00:07:33.943,00:07:34.790
"That is from state i, we look at all
these weights and we add them up, right?",00:07:34.790,00:07:40.767
"So okay, if we do that notice that,
If we take the sum of,",00:07:40.767,00:07:49.303
"I'm just gonna multiply by
this denominator here, right?",00:07:49.303,00:07:54.914
"So I'll take this thing,
sum of overall k, Of w i j,",00:07:54.914,00:07:59.143
"that's the generalization of
degree to the weighted case.",00:07:59.143,00:08:03.550
"And if we multiply by q i j,",00:08:03.550,00:08:06.749
"Then that just cancels the denominator,
which is why I chose that, [LAUGH] okay?",00:08:09.893,00:08:16.380
"That's w i j, but
by assumption, w i j = w j i,",00:08:16.380,00:08:21.589
"so that would be the same thing as if
we did it the other way around, and",00:08:21.589,00:08:29.343
"did the sum over all k of w,
this should be w i k.",00:08:29.343,00:08:34.596
"So it's summing over all,
k is a dummy variable.",00:08:34.596,00:08:36.495
"Sum over all k, w i k.",00:08:36.495,00:08:38.750
"And here we (sum over all k, w j k)q j i",00:08:38.750,00:08:43.998
That's the reversibility equation.,00:08:45.538,00:08:49.380
"So therefore, the stationary distribution,",00:08:49.380,00:08:54.162
"S i,
the stationary probability of state i,",00:08:54.162,00:08:58.704
"is proportional to this
generalized degree, w i k over k.",00:08:58.704,00:09:04.576
"This is proportionality, but
if we wanna know what it's equal to,",00:09:05.989,00:09:09.425
"we would just divide by
the sum of this over all i.",00:09:09.425,00:09:11.910
"So this is completely analogous to what
we did last time, but it's good practice.",00:09:13.960,00:09:19.520
"And all we did was just multiply
both sides by this denominator,",00:09:19.520,00:09:24.582
"and used the symmetry, w i j = w j i.",00:09:24.582,00:09:27.406
"Then we get the stationary distribution
without needing to do any matrices.",00:09:27.406,00:09:34.733
"So I don't know if this seems
like a small generalization or",00:09:34.733,00:09:37.786
"a large generalization of
what we did last time.",00:09:37.786,00:09:40.300
"It's a generalization of
what we did last time.",00:09:41.400,00:09:43.734
"Actually, this is completely general,
reversible Markov chain.",00:09:46.110,00:09:53.950
"So this is actually a complete
generalization, in the sense that if we",00:09:53.950,00:09:56.690
"have any reversible Markov chain,
we can actually interpret it this way.",00:09:56.690,00:10:01.620
"So In a sense, this is the entire
theory of reversible Markov chains.",00:10:01.620,00:10:07.440
"Not exactly, because,
if you have a reversible Markov chain,",00:10:07.440,00:10:12.948
"and you know what the S i is,
then you're in good shape.",00:10:12.948,00:10:18.010
"But if you don't know that,",00:10:18.010,00:10:19.570
"it may not be obvious to figure
out what are the stationary.",00:10:19.570,00:10:22.720
"What is the S i, such that S i,
q i j equals S j, q j i, okay?",00:10:22.720,00:10:28.100
"But it's a theorem that any
reversible Markov chain can be",00:10:28.100,00:10:32.689
represented in this form.,00:10:32.689,00:10:34.850
So just to quickly see why that's true.,00:10:36.940,00:10:40.786
"So any reversible chain can
be thought of this way.",00:10:44.062,00:10:48.920
"It may not be obvious to figure out
how to come up with the w i j's and",00:10:48.920,00:10:53.470
stuff like that.,00:10:53.470,00:10:54.430
"But at least in principle,
it can be written this way,",00:10:54.430,00:10:59.201
any reversible chain is of this form.,00:10:59.201,00:11:02.539
So why is that true?,00:11:11.511,00:11:13.300
"Well, we just need to define the w i j's.",00:11:13.300,00:11:16.180
"It's pretty obvious what network we should
use, just the nodes are the states,",00:11:16.180,00:11:23.320
"and we put edges whenever
q i j is positive, right?",00:11:23.320,00:11:28.520
"And all we need to do is just say,
what are the weights?",00:11:28.520,00:11:32.449
"So to do that, let's just say okay,",00:11:34.080,00:11:39.836
"let w i j = S i, q i j.",00:11:39.836,00:11:43.001
"That's the thing that we wanted, right?",00:11:43.001,00:11:46.870
"But S i j, q i j, right now I'm
assuming it's reversible, and",00:11:46.870,00:11:50.927
"I wanna show that the Markov
chain can be viewed in this way.",00:11:50.927,00:11:54.772
"So I'm assuming we already have the S and
the q, and I wanna define the weights,",00:11:56.170,00:12:00.440
"such that the Markov chain just
is this particular random walk..",00:12:00.440,00:12:05.320
"So if we define the weight i j to be S i,
q i j, but since it's reversible,",00:12:05.320,00:12:12.041
"that's the same thing as S j,
q j i, so that would be our w j i.",00:12:12.041,00:12:18.260
So we will have this condition hold.,00:12:18.260,00:12:22.160
"And all we have to do to check
that this works is to show that,",00:12:22.160,00:12:26.494
"if we define the weights this way, and
just do this particular random walk.",00:12:26.494,00:12:32.064
"Let's show that it has the transition
probablies that we want,",00:12:32.064,00:12:36.497
which are the q i j.,00:12:36.497,00:12:37.830
"So in other words,
we're assuming we have q i j,",00:12:37.830,00:12:40.510
"that's our Markov chain
that we're interested in.",00:12:40.510,00:12:42.470
"And we're assuming that it's reversible,
so this holds.",00:12:42.470,00:12:45.450
"And we're showing that it can
be written in this way, right?",00:12:45.450,00:12:49.235
"Well, do do that, at this point, all
we have to do is check that this chain,",00:12:49.235,00:12:53.715
"which is random walk on this network,
with the weights defined this way,",00:12:53.715,00:12:58.055
"has the transition probabilities
that we want, right?",00:12:58.055,00:13:01.980
"Which are q i j by definition, okay?",00:13:01.980,00:13:04.590
"So what are the transition
probabilities here?",00:13:04.590,00:13:07.310
"Well, I'll just write it as,
what's the probability of X n+1,",00:13:07.310,00:13:11.787
"if this X process is random
walk on this network.",00:13:11.787,00:13:15.017
"X n+1 = j given X n = i, that's
the transition probability that we have.",00:13:15.017,00:13:20.850
"Well, by definition, how do we find
the transition probability from i to j?",00:13:21.880,00:13:26.540
"Well, that says okay, we're at state i,
we look around everywhere,",00:13:26.540,00:13:29.710
where are the available edges?,00:13:29.710,00:13:31.050
"We look at all their weights, and",00:13:31.050,00:13:33.206
"we choose to go to j with
probability proportional to w i j.",00:13:33.206,00:13:36.983
That's the definition of the random walk.,00:13:36.983,00:13:38.690
So the probability is w i j over,00:13:38.690,00:13:43.726
the sum of w i k over all of k.,00:13:43.726,00:13:48.366
"That's just the definition of how
we did the random walk, right?",00:13:48.366,00:13:51.530
"Now if we plug in what's w i j,",00:13:51.530,00:13:56.131
"w i j is S i, q i j, and",00:13:56.131,00:13:59.259
"we divide by the sum of S i, q i k.",00:13:59.259,00:14:04.239
"I'm just plugging in how we defined,
we defined the weights in this way,",00:14:04.239,00:14:07.994
I'm plugging in the definition.,00:14:07.994,00:14:09.760
"Now let's just simplify this So
this S i in",00:14:10.930,00:14:16.001
"the denominator does not depend on k,
so we can take that out of the sum.",00:14:16.001,00:14:22.030
I'm assuming that the S i's are positive.,00:14:22.030,00:14:24.410
"It's not a very interesting chain if
some stationery probabilities zero,",00:14:24.410,00:14:28.785
"then we should have just restricted
the space, and not included them anyway.",00:14:28.785,00:14:33.314
"So I'm assuming we're not
dividing by zero here.",00:14:33.314,00:14:36.250
"S i's cancel, so this is just q
i j divided by the sum q i k.",00:14:36.250,00:14:42.019
"All right, well, what's the sum of q i k?",00:14:42.019,00:14:46.210
"It's 1, that should be quick, as it says.",00:14:48.470,00:14:52.270
Why is that 1?,00:14:53.780,00:14:55.174
"Because it's a Markov chain, so
you have to go from i to somewhere,",00:14:56.440,00:15:01.348
"so that's 1, so that's just q i j.",00:15:01.348,00:15:04.930
"So in other words,",00:15:06.040,00:15:07.096
"this chain that we constructed has
the desired transition probabilities.",00:15:07.096,00:15:11.322
"Okay, so
this is the quintessential prototypical",00:15:11.322,00:15:16.727
example of a reversible Markov chain.,00:15:16.727,00:15:20.880
"It's a random walk on and
undirected network,",00:15:20.880,00:15:23.781
"where possibly we put some
weights on the edges.",00:15:23.781,00:15:26.763
So that's the reversible case.,00:15:28.642,00:15:31.270
"And I wanted to do one example
of a non-reversible chain.",00:15:31.270,00:15:37.556
"That non-reversible, in general,
is gonna be much more difficult, right?",00:15:37.556,00:15:42.230
"In the reversible case, it just really
has a lot of really nice properties,",00:15:42.230,00:15:47.150
"both intuitively, cuz you think about
time running backwards and forwards.",00:15:47.150,00:15:51.260
"And practically, you can avoid matrix
stuff a lot of times, things like that.",00:15:51.260,00:15:56.225
"Non-reversible We can still think of it
as random walk on a network with weights,",00:15:56.225,00:16:04.616
"except that we have arrows,
maybe one way arrows or two way arrows.",00:16:04.616,00:16:10.180
"And you can have different
weights in both directions.",00:16:10.180,00:16:14.060
"That extra generality makes it much,
much, much harder, okay?",00:16:14.060,00:16:18.740
"So just wanna do one example
of a non-reversible chain.",00:16:18.740,00:16:27.420
Non-reversible example.,00:16:27.420,00:16:33.611
"Okay, and then that example is Google,",00:16:36.540,00:16:43.171
"Google Chain, more precisely,",00:16:43.171,00:16:48.632
Google PageRank.,00:16:48.632,00:16:51.762
"Google PageRank, which was the algorithm
that Google originally used,",00:16:54.956,00:17:01.607
"and still is using some form of,
is based exactly on a Markov chain,",00:17:01.607,00:17:07.717
"and it happens to be
a non-reversible chain.",00:17:07.717,00:17:12.100
"And I want to tell you
about what that chain is,",00:17:12.100,00:17:16.210
"how it's useful, where that came from.",00:17:16.210,00:17:20.350
"Okay, so this is just one example, but
this is a very big, important example.",00:17:20.350,00:17:26.500
Has anyone here heard of Google?,00:17:26.500,00:17:27.895
"&gt;&gt; [LAUGH]
&gt;&gt; Okay, well if not, Google for it, and",00:17:27.895,00:17:32.620
you'll find a lot of stuff there.,00:17:32.620,00:17:35.555
"&gt;&gt; [LAUGH]
&gt;&gt; It's a search engine.",00:17:35.555,00:17:38.760
"And, it's all based on MAakov chains.",00:17:38.760,00:17:41.050
"So I basically wanna
explain how that works.",00:17:41.050,00:17:45.090
"So, well,
you can kind of guess that what the chain,",00:17:45.090,00:17:50.180
"the states are gonna be, webpages, right?",00:17:50.180,00:17:55.140
"And the links are gonna be links,
right, hyperlinks.",00:17:55.140,00:18:00.650
"That is, we have the entire World Wide
Web, and some pages link to other pages,",00:18:00.650,00:18:05.700
and that's gonna form a Markov chain.,00:18:05.700,00:18:08.576
"We're gonna look at the stationary
distribution of that chain and",00:18:08.576,00:18:11.810
see what we can say.,00:18:11.810,00:18:13.130
"It's not gonna be reversible, so",00:18:13.130,00:18:14.710
"we can't just write down the stationary
distribution as easily as there.",00:18:14.710,00:18:17.330
"But we can still talk about how
could you try to compute that thing.",00:18:17.330,00:18:21.410
"Especially, considering
how large the web is.",00:18:21.410,00:18:25.670
"Okay, so just for
the sake of having a picture,",00:18:25.670,00:18:27.870
"let's assume that the World Wide Web
only has four pages.",00:18:28.870,00:18:33.160
"Which is an underestimate, but at least
I can draw something conceptually.",00:18:34.450,00:18:39.240
"So, there's only four pages on the web.",00:18:39.240,00:18:40.960
I just made up a little example.,00:18:40.960,00:18:43.220
"So, we have four webpages,
numbered one through four, and",00:18:43.220,00:18:48.310
"as I said, we're gonna draw
arrows that just represent links.",00:18:48.310,00:18:51.840
"So, it's just this example that I made up.",00:18:51.840,00:18:54.280
"Page number 1 links to page number 3,
that is, if you go to this web page,",00:18:54.280,00:18:57.430
"you see a link that takes
you to this web page.",00:18:57.430,00:19:00.390
"Okay, page 1 links to page 2,
page 2 links back to page 1.",00:19:00.390,00:19:05.010
"Page 3 is not so nice,
they don't link back to page 1.",00:19:05.010,00:19:08.670
"Page 2 links to page 3 and
page 3 only links to page 4.",00:19:08.670,00:19:14.325
Page 4 has no links on it.,00:19:15.680,00:19:17.370
Not every web page links to other pages.,00:19:17.370,00:19:18.958
"It may just be that page, all right?",00:19:18.958,00:19:20.820
"So that's an oversimplification
of the web, but",00:19:20.820,00:19:25.599
this gives you something to think.,00:19:25.599,00:19:29.024
"If you understand conceptually really
well what's going on with four pages,",00:19:29.024,00:19:33.103
"then you could imagine, in principle,
there could be billions of pages and",00:19:33.103,00:19:37.056
you're just imaging a gigantic version.,00:19:37.056,00:19:39.675
"It's not a very complicated
link structure, but",00:19:39.675,00:19:41.775
"basically you just have web pages
linking to each other ,okay, so",00:19:41.775,00:19:46.620
"I wanna basically explain
what this algorithm does.",00:19:46.620,00:19:50.020
Just to put it in context.,00:19:50.020,00:19:52.720
"I'll talk a little bit about
the earlier history of search engines.",00:19:52.720,00:19:57.780
"Google was started in 1998 by Brin and
Page, who were Stanford grad students.",00:19:57.780,00:20:05.530
"They ended up dropping out
to work full time on Google.",00:20:05.530,00:20:10.230
"The name is kind of convenient,
Brin and Page.",00:20:12.440,00:20:16.150
"Larry Page is kind of convenient for
him that Page is in the name PageRank,",00:20:16.150,00:20:21.230
but it's also a pretty natural name.,00:20:21.230,00:20:23.190
"Right?
Because this is a way for",00:20:23.190,00:20:25.830
ranking web pages.,00:20:25.830,00:20:28.210
"The basic problem is,
suppose you search for",00:20:28.210,00:20:32.540
"a certain thing you're interested in,
okay, and there might be millions or",00:20:32.540,00:20:37.560
"even billions of pages on the web
that contain that topic, right?",00:20:37.560,00:20:43.080
"So the fundamental question and
the insight that made Google way,",00:20:44.530,00:20:49.947
"way better than any of the other
alternatives at that time.",00:20:49.947,00:20:54.795
"I mean, now you can debate whether
their still the best or not, but",00:20:54.795,00:20:59.756
"at the time it was a huge,",00:20:59.756,00:21:01.615
"way beyond any of their competitors
in terms of the ranking, right?",00:21:01.615,00:21:06.766
"Because you don't have time to search
through a million, you're searching for",00:21:06.766,00:21:09.940
"chess and there's a million pages, you
don't have time to go through all of them.",00:21:09.940,00:21:13.220
"The question is,
which page should come up first, second,",00:21:13.220,00:21:16.294
"third, it's the ranking, right?",00:21:16.294,00:21:18.175
"All pages that match your query,
what order should those be displayed in?",00:21:18.175,00:21:22.496
Okay?,00:21:22.496,00:21:23.396
"So the earlier websites took pretty
crude naive approaches to that question.",00:21:23.396,00:21:30.340
"For example, I mean some of the earlier
search engines were basically trying",00:21:30.340,00:21:35.290
"to be human curated, like a museum.",00:21:35.290,00:21:38.020
"You have someone who recommends
this page is really good, right?",00:21:38.020,00:21:41.610
And obviously that doesn't scale so,00:21:41.610,00:21:44.070
"well when the web has billions and
billions of pages now.",00:21:44.070,00:21:48.440
It didn't scale so well.,00:21:48.440,00:21:50.960
"And then, I don't know, so
maybe what else could they have done,",00:21:50.960,00:21:53.850
"like alphabetical or something like,
it's kind of useless.",00:21:53.850,00:21:57.590
"In some of the early search engines,",00:21:57.590,00:21:59.970
"the ordering was based on how many
times the page used that word, right.",00:22:01.690,00:22:06.450
"So if I'm looking for chess,
then a page that mentions chess 100 times",00:22:06.450,00:22:11.360
"must be much better than a page
that only mentions chess once.",00:22:11.360,00:22:14.840
"Okay, well obviously that
opens itself up to abuse.",00:22:15.880,00:22:18.720
"Right?
You can just list the dictionary on your",00:22:18.720,00:22:21.750
site like repeated many times.,00:22:21.750,00:22:23.740
"But one thing, even if you're not
trying to abuse the system, just",00:22:23.740,00:22:27.580
"using the same word over and over again
doesn't mean that is the most reliable,",00:22:27.580,00:22:31.060
"insightful, useful page on that topic.",00:22:31.060,00:22:34.100
"Okay, so",00:22:34.100,00:22:34.601
"the earliest sites were not really using
the network structure of the web at all.",00:22:34.601,00:22:38.880
"Possibly AltaVista was one of
the first search engines that",00:22:41.630,00:22:46.490
"actually at least tried to do something
with the actual structure of the web.",00:22:46.490,00:22:51.660
"And so at some point it was
realized that actually,",00:22:51.660,00:22:55.206
"right, this is the worldwide
web is a network, and",00:22:55.206,00:22:58.300
"the structure of that network is valuable
information for doing these rankings.",00:22:58.300,00:23:02.300
"Okay, so then they started basically
saying that a page is important if",00:23:02.300,00:23:06.940
"a lot of other pages link to it, right?",00:23:06.940,00:23:11.440
Which was a big improvement.,00:23:11.440,00:23:13.220
"The problems with that, well first of
all it's very easy to abuse that, right?",00:23:14.650,00:23:17.740
"Can easily just create thousands of
dummy pages linking to your page, but",00:23:17.740,00:23:22.030
"even aside from the abuse question,
it's like just because a certain page",00:23:22.030,00:23:26.950
"has a lot of other pages linking to it
that doesn't necessarily mean that it's",00:23:26.950,00:23:31.130
"that important if those pages that
link to it are garbage, right?",00:23:31.130,00:23:35.900
"So the insight of PageRank
was that the importance",00:23:35.900,00:23:41.030
"of a page should be based not just on
how many other pages link to it, but",00:23:41.030,00:23:45.720
"how important those pages are, right?",00:23:45.720,00:23:49.920
So that's the key idea.,00:23:49.920,00:23:51.900
"So we have to try to make
that mathematical and",00:23:51.900,00:23:54.320
"then show how that
relates to Markov chains.",00:23:54.320,00:23:56.490
"But just intuitively, the importance of
a page as we want to rank the We wanna",00:23:56.490,00:24:01.663
"give each page a score for
how important it is, right?",00:24:01.663,00:24:06.339
"And rank them in order of
importance in this sense.",00:24:06.339,00:24:09.435
"Importance of page should be based,",00:24:09.435,00:24:13.280
"not only on which page is linking to it,",00:24:13.280,00:24:17.372
"the number of pages, and
the importance of each one",00:24:17.372,00:24:22.718
"Well, that sounds like a circular
definition that we define",00:24:28.049,00:24:33.179
"importance in terms of importance,
but that's okay actually,",00:24:33.179,00:24:38.713
"because that just suggests
an Eigenvector value equation,",00:24:38.713,00:24:43.843
which will interpret it as a Markov chain.,00:24:43.843,00:24:47.486
"So if we let Si,
just think of S as standing for score.",00:24:47.486,00:24:52.378
"That is,
we're gonna give each web page a score.",00:24:52.378,00:24:56.967
And let me just index it with j.,00:24:56.967,00:24:59.685
So that's the score of the jth web page.,00:24:59.685,00:25:02.248
"And so, Brin and Paige Said, they defined,",00:25:02.248,00:25:06.417
"they said we wanna give each page a score,
such that SSJ equals the sum of Si, qij.",00:25:06.417,00:25:14.014
"And I'll tell you qij is,
summed over all i.",00:25:14.014,00:25:21.259
"qij, well,
they pointed out basically, I mean,",00:25:21.259,00:25:25.430
"a simple thing to do would just be
to let this score of the jth page be",00:25:25.430,00:25:30.765
"the sum of all the scores of all,
summed over all i that link to j, right?",00:25:30.765,00:25:36.695
"So in other words, if you're thinking
of a link, an incoming link,",00:25:36.695,00:25:41.667
"as recommending that page and add up all
the scores of the recommenders, right?",00:25:41.667,00:25:47.526
"Except the problem with that is that,
some pages may only have like one",00:25:47.526,00:25:52.644
"outgoing link and other pages may
have a thousand outgoing links and",00:25:52.644,00:25:57.591
"it seems a little unfair to count those
kind of as equal recommendations, right?",00:25:57.591,00:26:03.618
"So it's like imagine that a certain
page has a certain budget for",00:26:03.618,00:26:07.352
"how much stuff it can recommend, and so
if it recommends 1,000 pages by having",00:26:07.352,00:26:12.192
"1,000 links, then each of those
should be diluted, right?",00:26:12.192,00:26:16.089
So that's what this qij is gonna do.,00:26:16.089,00:26:18.757
"So we're gonna let our matrix Q
just be the matrix we would get",00:26:18.757,00:26:24.032
"if we think of this as a Markov
chain just for this example.",00:26:24.032,00:26:29.108
"And we think of a Markov chain where
we're just randomly following links.",00:26:29.108,00:26:33.920
"So in this example I made up,
from page one you can go to page two or",00:26:33.920,00:26:39.007
"page three, assume equal probabilities.",00:26:39.007,00:26:42.509
"So it would do 0 1/2 1/2 0 it
goes to page two or page three.",00:26:42.509,00:26:49.638
"From page two you can go to page one or
page three.",00:26:49.638,00:26:54.418
"So from page 2 you can go to 1 or
3 so 1/2 0, 1/2 0.",00:26:54.418,00:27:00.001
From page 3 you can only go to page 4.,00:27:00.001,00:27:03.175
"So that's just gonna be 0, 0, 0, 1.",00:27:03.175,00:27:07.559
"Page 4 is kind of annoying, right?",00:27:07.559,00:27:11.719
"They don't recommend anything,
they're just their own thing.",00:27:11.719,00:27:16.697
"But we actually want to
have a Markov chain here.",00:27:16.697,00:27:21.854
"So we assume that from page 4,
you can go anywhere on the web with",00:27:21.854,00:27:26.619
"equal probability, so
I'm gonna just change this to 1/4,",00:27:26.619,00:27:31.299
"1/4, that's if it links to everything.",00:27:31.299,00:27:34.683
"Okay, so you define Q in this way,
where doing all the links,",00:27:34.683,00:27:39.447
but you're making each row sum up to 1.,00:27:39.447,00:27:42.574
"And if there's a page that has no
links then just make it 1 over",00:27:42.574,00:27:47.215
the number of pages in the entire web.,00:27:47.215,00:27:50.090
"So this has a pretty natural
interpretation that you might call,",00:27:51.410,00:27:55.550
"that is what you imagine is you have, and",00:27:55.550,00:27:58.108
"this is kind of what they were thinking
about that part of the motivation I think",00:27:58.108,00:28:03.074
"that helped them as you imagine someone
randomly surfing the web, right?",00:28:03.074,00:28:07.844
So what do you do?,00:28:07.844,00:28:08.919
"Well, you're Read a page for a while and
then you're done with that page.",00:28:08.919,00:28:12.748
"And if you're really bored,
just start clicking random links, right?",00:28:12.748,00:28:15.779
"Click a random link, it's a lot
of fun to do on Wikipedia, right?",00:28:15.779,00:28:20.290
"There was a good XKCD about that, right?",00:28:20.290,00:28:23.490
"Click a random link,
you keep clicking random links, right?",00:28:23.490,00:28:27.750
Just randomly surfing the web.,00:28:27.750,00:28:29.297
"That's kind of a natural
thing to think about.",00:28:29.297,00:28:31.885
"And then, now what happens if you
reach a page that has no links,",00:28:31.885,00:28:37.647
"but you're not ready to
stop surfing the web yet?",00:28:37.647,00:28:42.144
You don't give up in despair.,00:28:42.144,00:28:44.291
"Then the assumption is then
you just open a new window and",00:28:44.291,00:28:47.931
"just go to another random page, right?",00:28:47.931,00:28:50.574
"So then you can random walk instead of
being, you don't really wanna be trapped",00:28:50.574,00:28:54.695
"on that page forever just because
it doesn't have any links right?",00:28:54.695,00:28:58.213
So that's what this chain is doing.,00:28:58.213,00:29:01.450
"Okay, so then this equation
should make some sense, right?",00:29:01.450,00:29:07.638
"The importance is based on the importance
of the pages that link to it.",00:29:07.638,00:29:13.429
"qij is zero, unless there's
actually a link from i to j.",00:29:13.429,00:29:17.457
"So you're only adding up the terms
where there actually is a link there.",00:29:17.457,00:29:22.259
"And then the qij's may not all be equal,
because of this dilution thing, all right?",00:29:22.259,00:29:27.090
"So in matrix notation now,
that just says that s,",00:29:27.090,00:29:32.111
"which is s is the vector of
all the page ranks, right?",00:29:32.111,00:29:37.506
It is equal to s times Q.,00:29:37.506,00:29:40.110
"Ie, what does that say?",00:29:44.007,00:29:50.021
"That equation looks familiar, right?",00:29:50.021,00:29:52.490
"It says that s is
the stationary distribution.",00:29:52.490,00:29:56.998
"S is the stationary distribution for
this random web-surfing chain.",00:29:56.998,00:30:01.450
"Random web surfing,
random web surfing chain.",00:30:05.879,00:30:10.120
"Okay, so this has a natural interpretation
in terms of stationary distributions",00:30:12.228,00:30:18.186
"as well that is intuitively we think
of the stationary distribution as",00:30:18.186,00:30:23.279
"giving the long-run probabilities of
being in different states, right?",00:30:23.279,00:30:29.430
"Which says,
I'll just clarify that if s is normalized.",00:30:29.430,00:30:34.448
"Of course, if you have any solution to
this just divide by a constant to make,",00:30:34.448,00:30:40.140
"as long as you have non-negative
numbers here, so if s is normalized.",00:30:40.140,00:30:45.413
"So we just solve this matrix equation,
right?",00:30:45.413,00:30:48.222
"This is some gigantic
linear system of equations",00:30:48.222,00:30:52.991
"that is billions of pages, right?",00:30:52.991,00:30:56.490
"So if there are 10 billion web pages
then Q is gonna be a 10 billion by 10",00:30:56.490,00:31:01.764
"billion matrix, so this is an immensely
difficult computational problem.",00:31:01.764,00:31:07.238
"But in principle, all you're doing
is solving this linear system, and",00:31:07.238,00:31:10.989
"normalizing it, and
then that's the stationary distribution,",00:31:10.989,00:31:14.433
by definition of stationary distribution.,00:31:14.433,00:31:16.782
"So in terms of the interpretation of
stationary distribution is the long run",00:31:16.782,00:31:20.993
fraction of time being in a certain state.,00:31:20.993,00:31:23.375
"What this is saying is that, if you
imagine just randomly surfing the web for",00:31:23.375,00:31:29.311
"ages and ages and ages, and in the long
run this says that the importance",00:31:29.311,00:31:34.874
"of a page is the long run fraction of
time that you spend at that page, right.",00:31:34.874,00:31:41.100
"So that's kind of intuitive, right.",00:31:41.100,00:31:42.538
"The pages that are more important,",00:31:42.538,00:31:44.493
"you'll find yourself spending
more time there in the long run.",00:31:44.493,00:31:48.019
So that's what it's doing.,00:31:48.019,00:31:51.538
"Okay, so you can interpret this is
a Markov chain, as I just said.",00:31:51.538,00:31:58.130
But you might object.,00:31:59.230,00:32:00.760
"Well really this is just an eigenvalue,
eigenvector thing.",00:32:00.760,00:32:03.407
"It's just a matrix equation, and
do we really have to give it this",00:32:03.407,00:32:07.643
"probability interpretation and
really interpret it as a Markov chain?",00:32:07.643,00:32:12.357
"And so I wanted to show you something
about why is that actually a useful way to",00:32:12.357,00:32:16.907
think of it.,00:32:16.907,00:32:18.080
One reason is what I just said.,00:32:18.080,00:32:19.630
"That intuitively it makes sense to think
of these long run fraction of time for",00:32:19.630,00:32:24.220
randomly surfing the web.,00:32:24.220,00:32:25.640
"So this gives a nice extra
interpretation to this.",00:32:25.640,00:32:28.630
"But I also wanna show you how
this helps with the computation.",00:32:28.630,00:32:32.710
"Because the computation
is immensely difficult.",00:32:32.710,00:32:35.980
"If you try to solve,
you know the usual method for",00:32:35.980,00:32:38.860
"solving matrix equations is
Gaussian elimination, right?",00:32:38.860,00:32:42.530
You do all these row operations.,00:32:42.530,00:32:44.350
"Two times row one, plus row three,
and swap rows, and multiply rows.",00:32:44.350,00:32:49.170
"Right?
All that thing.",00:32:49.170,00:32:50.690
"The complexity of Gaussian elimination
if you have m linear equations and",00:32:50.690,00:32:56.560
m variables is of the order of m cubed.,00:32:56.560,00:32:59.930
It's a cubic complexity.,00:32:59.930,00:33:03.110
"You may be happy that that's polynomial
time but in practice it's not so",00:33:03.110,00:33:10.380
"good if m is like 10 billion and
if you have the order",00:33:10.380,00:33:15.450
"of 10 billion that's 10 to the 10,
cube it, that's 10 to the 30.",00:33:15.450,00:33:20.900
10 to the 30.,00:33:20.900,00:33:21.910
"So you'd have order 10 to
the 30th operations to perform.",00:33:21.910,00:33:27.050
"You don't wanna do that,
even on a fast computer.",00:33:27.050,00:33:31.180
"Okay, so I wanna show you how
Markov chains not only gives you",00:33:32.180,00:33:35.000
"a nice interpretation here,
it actually helps with the computation.",00:33:35.000,00:33:38.410
"Which is as far as I know, at least how
Google was originally doing this and",00:33:38.410,00:33:44.890
"I'm sure they've refined things,
but in spirit it should be similar.",00:33:44.890,00:33:48.950
That the basic principle.,00:33:49.970,00:33:51.050
"So to give this the full Markov
chain interpretation, we wanna,",00:33:52.220,00:33:58.430
"and connect this back with what we were
doing, we wanna say is this irreducible?",00:33:58.430,00:34:02.410
"Does this have a stationary, how do we
know the stationary distribution exists?",00:34:02.410,00:34:07.150
"And how do we know to convert it to
the stationary and things like that.",00:34:07.150,00:34:09.870
"So actually, what Google uses or
used in the original, Brin and Page,",00:34:09.870,00:34:14.565
"while they were still grad students,
wrote a paper with the idea for Google.",00:34:14.565,00:34:19.820
"And then they started
actually the company.",00:34:19.820,00:34:22.970
"So the paper that they wrote
actually gives the ideas.",00:34:22.970,00:34:26.480
"And what they said in that paper is,
they set up an equation like this,",00:34:26.480,00:34:31.478
"but then they said actually we're
going to use another chain instead,",00:34:31.478,00:34:36.565
which I'll call G for Google.,00:34:36.565,00:34:38.797
But here's the actual Google chain.,00:34:38.797,00:34:41.838
"The Google chain is alpha times
this one that we just did.",00:34:41.838,00:34:48.665
It's mixing together two Markov chains.,00:34:48.665,00:34:50.970
"Alpha times Q, so Q is the matrix
we just defined based on the web,",00:34:50.970,00:34:57.722
"+ (1- alpha) times J over M,",00:34:57.722,00:35:03.630
where M is the number of pages.,00:35:04.650,00:35:08.200
"So in other words Q is an m by m matrix,
and J is the matrix of all ones.",00:35:10.280,00:35:16.310
So I want to explain why did they do this.,00:35:17.680,00:35:20.170
And alpha is a number between 0 and 1.,00:35:21.400,00:35:26.140
Just a constant.,00:35:26.140,00:35:29.194
"So think of alpha as a probability,
because it's a number between 0 and 1.",00:35:29.194,00:35:32.541
"So what this is saying is imagine
that you have this person randomly",00:35:32.541,00:35:37.259
surfing the web like we were saying.,00:35:37.259,00:35:39.880
"And with probability alpha,",00:35:39.880,00:35:41.570
"so they flip a coin that has
probability alpha of heads each time.",00:35:41.570,00:35:46.020
"If the coin lands heads,",00:35:46.020,00:35:47.360
"they just click a random link on
the page that they were on, right?",00:35:47.360,00:35:51.830
That is they actually use the Q chain.,00:35:51.830,00:35:53.890
"But if the coin lands tails,
they use this chain instead.",00:35:53.890,00:35:57.980
"Notice J over M is a valid
Markov transition matrix, right,",00:35:57.980,00:36:02.242
"cuz the row sums are 1,
and it's all non-negative.",00:36:02.242,00:36:06.096
"So with probability alpha,
just follow the link.",00:36:06.096,00:36:10.758
"With probably 1- alpha,
we do what's called teleportation.",00:36:10.758,00:36:14.810
Teleportation is just a fancy word for,00:36:14.810,00:36:16.790
"saying, don't follow
the link structure anymore.",00:36:16.790,00:36:19.490
"Now, just go to a random,
uniformly random page.",00:36:19.490,00:36:23.310
So this term is the teleportation.,00:36:23.310,00:36:26.703
"All that means is, with probability alpha,
just follow the link structure.",00:36:29.829,00:36:34.800
"With probably 1- alpha, just open up
a new window in your web browser and",00:36:34.800,00:36:40.180
"go to a completely random
page at that point.",00:36:40.180,00:36:42.290
"Of course, alpha has to be chosen.",00:36:42.290,00:36:45.840
The original paper suggested alpha = 0.85.,00:36:47.670,00:36:53.901
"Now, that's like Google's magic number,
0.85.",00:36:53.901,00:36:56.860
"And there's been a lot of speculation and
discussion on why did they use .85?",00:36:56.860,00:37:01.452
"And I don't know whether
they still use 0.85.",00:37:03.490,00:37:06.900
"That was the original
value that they proposed.",00:37:06.900,00:37:09.310
"So 85% of the time you're
just following random links,",00:37:09.310,00:37:12.312
"15% of the time you're
teleporting to random pages.",00:37:12.312,00:37:15.205
"The reason, not specifically for
this 0.85, but the reason for adding",00:37:17.551,00:37:22.465
"this extra term is that this makes things
really, well, one reason is it makes",00:37:22.465,00:37:27.530
"things really nice in terms of the theory
that we developed for stationary issues.",00:37:27.530,00:37:32.975
"But the actual web, you know,",00:37:32.975,00:37:37.050
"if we just had this part, we don't know
whether it's irreducible, you know.",00:37:38.630,00:37:42.070
"Can you get from anywhere on the web
to anywhere just by clicking links?",00:37:42.070,00:37:47.880
"Well, I guess if you have this
page it would help a lot but",00:37:47.880,00:37:52.830
"it may take ages to get
from one page to another.",00:37:54.270,00:37:57.750
"And this is kind of allowing there to
be some small probability of getting",00:37:57.750,00:38:01.760
from anywhere to anywhere in one step.,00:38:01.760,00:38:03.350
"So this guarantees irreducibility for
one thing.",00:38:03.350,00:38:07.893
"And we have other result about,",00:38:11.886,00:38:15.778
"the nice case is when some
power of the transition",00:38:15.778,00:38:21.689
matrix has all entries positive.,00:38:21.689,00:38:26.670
"In this case, notice this is
extremely tiny, tiny, right?",00:38:26.670,00:38:31.570
"If alpha is 0.85, this is 0.15.",00:38:31.570,00:38:35.616
M may be 10 billion.,00:38:35.616,00:38:37.900
"So you're adding some tiny number,
but at least everything's positive.",00:38:37.900,00:38:41.660
You don't have zeroes anymore.,00:38:41.660,00:38:43.550
"So, no zeroes in transition matrix G.",00:38:43.550,00:38:53.820
"So, that has some advantages.",00:38:53.820,00:38:56.100
"And in particular we know
that all the results about...",00:38:56.100,00:38:59.150
"Even though it's not a reversible chain,
because the arrows may be going",00:38:59.150,00:39:04.150
"in one direction for
the web, the results from",00:39:04.150,00:39:10.120
"last time that I stated, that there
exists geostationary distribution.",00:39:10.120,00:39:15.950
It's unique.,00:39:15.950,00:39:16.670
The chain will converge to it.,00:39:16.670,00:39:18.560
All this nice stuff applies.,00:39:18.560,00:39:20.300
"Okay, so we have this thing.",00:39:22.460,00:39:24.040
"Now, how do we actually compute?",00:39:24.040,00:39:26.806
"Because, since it's non-reversible,
we can't just write down a simple",00:39:26.806,00:39:31.828
"equation and immediately write
down the stationary distribution.",00:39:31.828,00:39:36.390
"The stationary distribution,
is something very very complicated here.",00:39:36.390,00:39:40.950
"But on the other hand,
if we go back to the definition and",00:39:40.950,00:39:44.310
"try to solve this matrix equation, then
we're trying to do Gaussian elimination",00:39:44.310,00:39:49.246
with ten billion or 100 billion equations.,00:39:49.246,00:39:52.130
"It's not so good, right?",00:39:52.130,00:39:53.940
"So, the idea for computation is to",00:39:55.080,00:39:59.930
"use the fact that the chain converges
to the stationary distribution.",00:39:59.930,00:40:04.250
"So use convergence to
stationary distribution",00:40:04.250,00:40:10.121
to stationarity to actually to solve.,00:40:10.121,00:40:15.460
"We don't need to solve it exactly, right?",00:40:15.460,00:40:18.190
"All we really need is and
approximate solution to this.",00:40:18.190,00:40:22.825
"Okay, so we know that if we run this,
this defines a Markov chain, right?",00:40:22.825,00:40:26.990
"Either you follow the link structure,
or you teleport each time.",00:40:26.990,00:40:31.480
"Follow that, run that chain for
a long time.",00:40:31.480,00:40:33.850
"It's gonna converge to the stationary
distribution no matter what",00:40:33.850,00:40:36.710
"the starting point was, right?",00:40:36.710,00:40:38.410
Start with any distribution you want.,00:40:38.410,00:40:41.770
Run the chain for a long.,00:40:41.770,00:40:42.940
"There's some very
difficult mathematical and",00:40:44.070,00:40:46.010
"computational questions about how
long should you run the chain for.",00:40:46.010,00:40:49.940
"And those are not really well understood
for a chain as complicated as this.",00:40:49.940,00:40:54.080
"So in practice, what people will do
is just run it as long as they can or",00:40:54.080,00:40:58.830
"run it until it looks
like it has stabilized.",00:40:58.830,00:41:01.780
"And you don't know for
sure that if you then ran it another week,",00:41:01.780,00:41:04.100
it would change to something else.,00:41:04.100,00:41:05.500
"But if it looks like it's stabilized,",00:41:05.500,00:41:07.540
"then just take that as
your approximate solution.",00:41:07.540,00:41:11.350
"Okay, so
how do we actually run this chain though?",00:41:11.350,00:41:15.390
"The computation it looks like
it's going to be extremely,",00:41:15.390,00:41:17.860
"extremely difficult because of
these matrices are so large.",00:41:17.860,00:41:22.420
"It's actually much simpler than it
looks and I just want to show you why.",00:41:22.420,00:41:26.860
"So let's be t be our
initial probability vector.",00:41:28.180,00:41:34.410
"That is if you want t could just be 1 and
then all 0s.",00:41:34.410,00:41:37.340
"That just says always start out at page 1,
right,",00:41:37.340,00:41:42.634
"or let t be 1 over m, 1 over m all the way
through that it starts on a random page.",00:41:42.634,00:41:48.120
"We need some starting distribution
to start out the chain.",00:41:48.120,00:41:52.200
"So that's the initial,
in other words, this is the PMF,",00:41:52.200,00:41:56.030
"at times 0, written as a row vector.",00:41:56.030,00:41:59.690
So initial probability vector.,00:41:59.690,00:42:02.150
"Okay, so we proved before that if we
want the probability distribution",00:42:02.150,00:42:07.050
"after one step, all we have to do
is multiply on the right by G.",00:42:07.050,00:42:11.130
"Right?
So",00:42:11.130,00:42:11.750
"t times G is going to be
the distribution after one step.",00:42:11.750,00:42:16.290
Right?,00:42:16.290,00:42:16.840
We did that before.,00:42:16.840,00:42:17.720
"And then if we want the distribution after
two steps, we multiply this by G, so",00:42:19.460,00:42:22.810
"we can get tG squared,
tG cubed, and so on, all right?",00:42:22.810,00:42:26.510
"Okay.
So,",00:42:26.510,00:42:27.179
"let's just quickly see what is
t times G actually look like?",00:42:27.179,00:42:32.305
"So t times G,
I'm just gonna multiply this by t,",00:42:32.305,00:42:39.162
"this is alpha t q plus 1
minus alpha t J over M.",00:42:39.162,00:42:45.540
"And actually this is not so
complicated because",00:42:45.540,00:42:49.990
"when you think about what Q looks like, Q,",00:42:49.990,00:42:54.820
"that's this chain that captures the link
structure of the entire web, right?",00:42:56.630,00:43:02.400
"What do you think that matrix looks like,
intuitively?",00:43:02.400,00:43:05.876
&gt;&gt; A lot of 0s.,00:43:05.876,00:43:07.420
"&gt;&gt; It's a lot of zeroes,
this is like 10 billion by 10 billion, or",00:43:07.420,00:43:11.550
"100 billion by 100 billion But, right,
a typical page might have, I don't know,",00:43:11.550,00:43:16.460
"three links or ten links or
even 100 links.",00:43:16.460,00:43:19.260
"You're not gonna have many pages that
have tens of thousands of links, or",00:43:19.260,00:43:24.070
"millions of links, right?",00:43:24.070,00:43:25.540
"But this is a 10 billion by 10 billion,
okay?",00:43:25.540,00:43:28.170
So this is dominated by 0s.,00:43:28.170,00:43:29.960
"So in other words,
you would say it's very sparse.",00:43:29.960,00:43:32.959
"That is sparse, meaning mostly zeros.",00:43:34.570,00:43:37.060
"Now, Google has a lot of very, very,
very good computer scientists working on",00:43:41.282,00:43:46.345
"some of the data storage computational
issues of the, what data structure would",00:43:46.345,00:43:51.485
"you use to store this matrix and keep
track of where all the zeros are, right?",00:43:51.485,00:43:56.810
"In other words, how do you efficiently
keep track of where the zeros are and",00:43:56.810,00:44:00.890
"where the non-zero terms
are because it's mostly zeros?",00:44:00.890,00:44:04.220
"But at least intuitively this
matrix has so many zeros in it and",00:44:04.220,00:44:09.470
"having a lot of zeros makes it a lot
easier to do matrix multiplication, right?",00:44:09.470,00:44:12.430
"You do need to be clever in keeping
track of where the zeros are.",00:44:12.430,00:44:16.220
"But it helps a lot with
doing this multiplication.",00:44:16.220,00:44:19.880
Now let's look at this other term.,00:44:19.880,00:44:21.270
Let's think about t times J.,00:44:23.670,00:44:26.370
"So remember t, t is just some vector
of probabilities that add up to 1.",00:44:28.980,00:44:36.710
Right?,00:44:36.710,00:44:37.440
And then J is a very simple matrix.,00:44:37.440,00:44:40.180
J is just all 1's.,00:44:40.180,00:44:41.720
"So I'm gonna take this vector t,
and I'm gonna multiply it by J.",00:44:41.720,00:44:45.080
"And then I just,
the matrix multiplication,",00:44:45.080,00:44:48.808
"tt is a real vectors are going row,
dot it with a column.",00:44:48.808,00:44:53.010
"But you do a dot product with all ones,
that just says add up the entries of t.",00:44:53.010,00:44:57.150
"Well if you add up the entries of t,
you get 1, right?",00:44:57.150,00:45:02.290
Because t is a probability vector.,00:45:03.720,00:45:06.140
So t times J is just all 1s.,00:45:06.140,00:45:09.623
"Cuz you're just going t,
add up the elements of t.",00:45:16.627,00:45:20.470
t elements add up to what?,00:45:20.470,00:45:22.810
"That's very easy, just all ones.",00:45:22.810,00:45:24.720
"So that term is easy, so
actually this is not as bad as it looks.",00:45:24.720,00:45:29.300
"Now that we have t times G,
we use that as the new t.",00:45:29.300,00:45:34.200
This is after running it for one step.,00:45:34.200,00:45:36.870
"Then we do tG squared, that is we
do tg times G, which is tG squared.",00:45:36.870,00:45:43.950
"Well we do that in the same way, which is
tG is now playing the role of t and we",00:45:46.560,00:45:50.890
"multiply this by G and that's not typical
to do for the same reasons I just said.",00:45:50.890,00:45:54.920
"So then we have tG squared,
tG cubed, and so",00:45:54.920,00:45:59.130
"on, run this for a very long time,
that is tG to some large",00:45:59.130,00:46:04.850
"power that corresponds to running this
chain for a large number of steps, right?",00:46:04.850,00:46:10.066
"So then, in the limit, if you do tG to
the n, meaning you ran it for n steps,",00:46:10.066,00:46:17.190
"and you let n go to infinity, that's gonna
converge to the stationary distribution.",00:46:18.900,00:46:23.330
"The stationary distribution
is the page rank vector.",00:46:23.330,00:46:27.430
"So then you have page rank, okay?",00:46:27.430,00:46:29.850
"So, and that's actually computationally, a
lot easier to do, just run this chain, in",00:46:29.850,00:46:37.660
"this way rather than trying to solve the
ten billion by ten billion matrix system.",00:46:37.660,00:46:43.600
"And it has this nice interpretation in
terms of randomly clicking links and",00:46:43.600,00:46:48.430
randomly teleporting every now and then.,00:46:48.430,00:46:51.420
"All right, so
that's the essence of Google PageRank.",00:46:51.420,00:46:54.110
And that's the end of Markov chains.,00:46:54.110,00:46:55.930
So I'll see you on Friday.,00:46:55.930,00:46:58.185
