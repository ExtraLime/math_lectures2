text,start,stop
"The following
content is provided",00:00:00.050,00:00:01.770
"under a Creative
Commons license.",00:00:01.770,00:00:04.010
"Your support will help MIT
OpenCourseWare continue",00:00:04.010,00:00:06.860
"to offer high quality
educational resources for free.",00:00:06.860,00:00:10.720
"To make a donation or
view additional materials",00:00:10.720,00:00:13.320
"from hundreds of MIT courses,
visit MIT OpenCourseWare",00:00:13.320,00:00:17.207
at ocw.mit.edu.,00:00:17.207,00:00:17.832
"PROFESSOR: We're going to start
a brand new, exciting topic,",00:00:21.130,00:00:23.630
dynamic programming.,00:00:23.630,00:00:25.287
AUDIENCE: Yes!,00:00:25.287,00:00:25.870
PROFESSOR: Yeah!,00:00:25.870,00:00:26.830
So exciting.,00:00:26.830,00:00:28.245
"Actually, I am really excited
because dynamic programming",00:00:28.245,00:00:30.620
"is my favorite thing in
the world, in algorithms.",00:00:30.620,00:00:33.820
"And it's going to be
the next four lectures,",00:00:33.820,00:00:37.070
it's so exciting.,00:00:37.070,00:00:38.640
It has lots of different facets.,00:00:38.640,00:00:40.380
"It's a very general,
powerful design technique.",00:00:40.380,00:00:44.720
"We don't talk a lot about
algorithm design in this class,",00:00:44.720,00:00:47.390
"but dynamic programming is
one that's so important.",00:00:47.390,00:00:50.060
"And also takes a little
while to settle in.",00:00:50.060,00:00:52.000
"We like to injected it
into you now, in 006.",00:00:52.000,00:00:57.510
"So in general, our motivation
is designing new algorithms",00:00:57.510,00:01:05.920
"and dynamic programming,
also called DP,",00:01:05.920,00:01:10.600
"is a great way-- or a
very general, powerful way",00:01:10.600,00:01:17.840
to do this.,00:01:17.840,00:01:18.365
"It's especially good, and
intended for, optimization",00:01:33.860,00:01:37.540
"problems, things
like shortest paths.",00:01:37.540,00:01:39.100
"You want to find the
best way to do something.",00:01:39.100,00:01:41.274
"Shortest path is you
want to find the shortest",00:01:41.274,00:01:43.190
"path, the minimum-length path.",00:01:43.190,00:01:46.600
"You want to minimize,
maximize something, that's",00:01:46.600,00:01:48.610
"an optimization
problem, and typically",00:01:48.610,00:01:51.320
"good algorithms to solve them
involve dynamic programming.",00:01:51.320,00:01:54.090
It's a bit of a broad statement.,00:01:54.090,00:01:56.390
"You can also think of
dynamic programming",00:01:56.390,00:01:58.320
as a kind of exhaustive search.,00:01:58.320,00:02:01.700
"Which is usually
a bad thing to do",00:02:01.700,00:02:03.270
"because it leads to
exponential time.",00:02:03.270,00:02:05.260
"But if you do it in a clever
way, via dynamic programming,",00:02:05.260,00:02:09.449
"you typically get
polynomial time.",00:02:09.449,00:02:13.670
"So one perspective is
that dynamic programming",00:02:13.670,00:02:17.430
"is approximately
careful brute force.",00:02:17.430,00:02:23.170
"It's kind of a
funny combination.",00:02:23.170,00:02:25.650
A bit of an oxymoron.,00:02:25.650,00:02:29.340
"But we take the idea of
brute force, which is,",00:02:29.340,00:02:31.600
"try all possibilities
and you do it carefully",00:02:31.600,00:02:35.690
"and you get it to
polynomial time.",00:02:35.690,00:02:37.110
"There are a lot of
problems where essentially",00:02:37.110,00:02:38.985
"the only known polynomial
time algorithm is",00:02:38.985,00:02:41.650
via dynamic programming.,00:02:41.650,00:02:42.650
"It doesn't always work,
there's some problems",00:02:42.650,00:02:44.440
"where we don't think there are
polynomial time algorithms,",00:02:44.440,00:02:46.856
"but when it's possible
DP is a nice, sort of,",00:02:46.856,00:02:50.770
general approach to it.,00:02:50.770,00:02:54.037
"And we're going to be talking a
lot about dynamic programming.",00:02:54.037,00:02:56.620
"There's a lot of different
ways to think about it.",00:02:56.620,00:02:59.850
We'll look at a few today.,00:02:59.850,00:03:02.690
"We're going to warm up today
with some fairly easy problems",00:03:02.690,00:03:05.754
"that we already
know how to solve,",00:03:05.754,00:03:07.170
"namely computing
Fibonacci numbers.",00:03:07.170,00:03:09.690
It's pretty easy.,00:03:09.690,00:03:11.210
And computing shortest paths.,00:03:11.210,00:03:13.092
"And then in the
next three lectures",00:03:13.092,00:03:14.550
"we're going to get to
more interesting examples",00:03:14.550,00:03:16.530
"where it's pretty
surprising that you can even",00:03:16.530,00:03:20.210
"solve the problem
in polynomial time.",00:03:20.210,00:03:24.160
"Probably the first burning
question on your mind,",00:03:24.160,00:03:26.470
"though, is why is it
called dynamic programming?",00:03:26.470,00:03:29.280
What does that even mean?,00:03:29.280,00:03:31.240
"And I used to have this
spiel about, well, you",00:03:31.240,00:03:34.760
"know, programming
refers to the-- I think",00:03:34.760,00:03:37.480
"it's the British
notion of the word,",00:03:37.480,00:03:39.550
where it's about optimization.,00:03:39.550,00:03:42.040
"Optimization in American
English is something",00:03:42.040,00:03:44.750
"like programming
in British English,",00:03:44.750,00:03:47.690
"where you want to
set up the program--",00:03:47.690,00:03:50.350
"the schedule for your
trains or something,",00:03:50.350,00:03:52.800
"where programming
comes from originally.",00:03:52.800,00:03:54.850
"But I looked up the
actual history of,",00:03:54.850,00:03:57.675
"why is it called
dynamic programming.",00:03:57.675,00:04:00.730
"Dynamic programming was invented
by a guy named Richard Bellman.",00:04:00.730,00:04:04.960
"You may have heard of Bellman
in the Bellman-Ford algorithm.",00:04:04.960,00:04:07.850
"So this is actually the
precursor to Bellman-Ford.",00:04:07.850,00:04:10.360
"And we're going to see
Bellman-Ford come up naturally",00:04:10.360,00:04:13.290
in this setting.,00:04:13.290,00:04:15.480
So here's a quote about him.,00:04:15.480,00:04:17.519
"It says, Bellman
explained that he",00:04:17.519,00:04:19.300
"invented the name dynamic
programming to hide the fact",00:04:19.300,00:04:22.250
"that he was doing
mathematical research.",00:04:22.250,00:04:25.840
"He was working at this
place called Rand,",00:04:25.840,00:04:27.950
"and under a secretary of defense
who had a pathological fear",00:04:27.950,00:04:31.890
"and hatred for
the term research.",00:04:31.890,00:04:35.096
"So he settled on the
term dynamic programming",00:04:35.096,00:04:36.970
"because it would be
difficult to give",00:04:36.970,00:04:39.450
a pejorative meaning to it.,00:04:39.450,00:04:42.000
"And because it was
something not even",00:04:42.000,00:04:43.870
a congressman could object to.,00:04:43.870,00:04:45.830
"Basically, it sounded cool.",00:04:45.830,00:04:49.430
"So that's the origin of the
name dynamic programming.",00:04:49.430,00:04:52.540
So why is the called that?,00:04:52.540,00:04:53.630
Who knows.,00:04:53.630,00:04:55.450
"I mean, now you know.",00:04:55.450,00:04:56.780
"But it's not--
it's a weird term.",00:04:56.780,00:04:59.430
Just take it for what it is.,00:04:59.430,00:05:00.720
"It may make some
kind of sense, but--",00:05:04.150,00:05:06.820
All right.,00:05:06.820,00:05:07.500
"So we are going to start
with this example of how",00:05:07.500,00:05:14.570
to compute Fibonacci numbers.,00:05:14.570,00:05:16.800
"And maybe before
we actually start",00:05:16.800,00:05:18.700
"I'm going to give you
a sneak peak of what",00:05:18.700,00:05:23.250
"you can think of
dynamic programming as.",00:05:23.250,00:05:26.480
"And this equation,
so to speak, is",00:05:26.480,00:05:37.830
"going to change throughout
today's lecture.",00:05:37.830,00:05:42.400
"In the end we'll
settle on a sort",00:05:42.400,00:05:43.970
of more accurate perspective.,00:05:43.970,00:05:46.760
"The basic idea of
dynamic programming",00:05:46.760,00:05:49.020
"is to take a problem,
split it into subproblems,",00:05:49.020,00:05:53.120
"solve those subproblems,
and reuse the solutions",00:05:53.120,00:05:55.780
to your subproblems.,00:05:55.780,00:05:56.720
It's like a lesson in recycling.,00:05:56.720,00:05:59.520
"So we'll see that in
Fibonacci numbers.",00:05:59.520,00:06:03.290
"So you remember
Fibonacci numbers, right?",00:06:03.290,00:06:06.270
"The number of rabbits you have
on day n, if they reproduce.",00:06:06.270,00:06:10.445
"We've mentioned them before,
we're talking about AVL trees,",00:06:15.020,00:06:18.630
I think.,00:06:18.630,00:06:19.910
"So this is the
usual-- you can think",00:06:19.910,00:06:23.290
"of it as a recursive definition
or recurrence on Fibonacci",00:06:23.290,00:06:26.710
numbers.,00:06:26.710,00:06:27.770
"It's the definition of what
the nth Fibonacci number is.",00:06:27.770,00:06:30.890
"So let's suppose our goal--
an algorithmic problem is,",00:06:30.890,00:06:34.810
"compute the nth
Fibonacci number.",00:06:34.810,00:06:39.220
"And I'm going to assume here
that that fits in a word.",00:06:39.220,00:06:42.710
"And so basic
arithmetic, addition,",00:06:42.710,00:06:44.980
"whatever's constant
time per operation.",00:06:44.980,00:06:48.100
So how do we do it?,00:06:48.100,00:06:50.590
You all know how to do it.,00:06:50.590,00:06:52.200
"Anyways-- but I'm going to give
you the dynamic programming",00:06:52.200,00:06:56.610
perspective on things.,00:06:56.610,00:06:57.790
"So this will seem
kind of obvious,",00:06:57.790,00:07:00.500
"but it is-- we're going to apply
exactly the same principles",00:07:00.500,00:07:03.610
"that we will apply over and
over in dynamic programming.",00:07:03.610,00:07:06.610
"But here it's in a
very familiar setting.",00:07:06.610,00:07:11.910
"So we're going to start with
the naive recursive algorithm.",00:07:11.910,00:07:16.430
"And that is, if you want to
compute the nth Fibonacci",00:07:24.850,00:07:29.150
"number, you check whether
you're in the base case.",00:07:29.150,00:07:32.010
I'm going to write it this way.,00:07:35.890,00:07:38.520
So f is just our return value.,00:07:55.230,00:07:57.320
"You'll see why I write
it this way in a moment.",00:07:57.320,00:07:59.470
Then you return f.,00:07:59.470,00:08:01.270
"In the base case
it's 1, otherwise",00:08:01.270,00:08:03.030
"you recursively call
Fibonacci of n minus 1.",00:08:03.030,00:08:05.860
"You recursively call
Fibonacci of n minus 2.",00:08:05.860,00:08:08.520
"Add them together, return that.",00:08:08.520,00:08:10.600
This is a correct algorithm.,00:08:10.600,00:08:12.762
Is it a good algorithm?,00:08:12.762,00:08:15.160
No.,00:08:15.160,00:08:16.255
It's very bad.,00:08:16.255,00:08:17.230
Exponential time.,00:08:17.230,00:08:18.260
"How do we know it's
exponential time,",00:08:23.450,00:08:25.480
other than from experience?,00:08:25.480,00:08:27.730
"Well, we can write the
running time as recurrence.",00:08:27.730,00:08:31.880
"T of n represents the time
to compute the nth Fibonacci",00:08:31.880,00:08:34.990
number.,00:08:34.990,00:08:35.780
How can I write the recurrence?,00:08:35.780,00:08:39.440
"You're gonna throwback to
the early lectures, divide",00:08:39.440,00:08:41.630
and conquer.,00:08:41.630,00:08:42.606
I hear whispers.,00:08:48.950,00:08:50.890
Yeah?,00:08:50.890,00:08:51.390
AUDIENCE: [INAUDIBLE].,00:08:51.390,00:08:52.366
PROFESSOR: Yeah.,00:08:55.320,00:08:57.081
"T of n minus 1 plus t of
n minus 2 plus constant.",00:08:57.081,00:09:03.340
"I don't know how
many you have by now.",00:09:07.190,00:09:08.865
"So to create the
nth Fibonacci number",00:09:11.510,00:09:13.540
"we have to compute the n
minus first Fibonacci number,",00:09:13.540,00:09:15.790
"and the n minus second
Fibonacci number.",00:09:15.790,00:09:17.456
That's these two recursions.,00:09:17.456,00:09:19.890
"And then we take
constant time otherwise.",00:09:19.890,00:09:21.760
"We do constant number of
additions, comparisons.",00:09:21.760,00:09:24.910
"Return all these operations--
take constant time.",00:09:24.910,00:09:27.920
So that's a recurrence.,00:09:27.920,00:09:29.550
How do we solve this recurrence?,00:09:29.550,00:09:31.390
"Well one way is to see this
is the Fibonacci recurrence.",00:09:31.390,00:09:35.720
So it's the same thing.,00:09:35.720,00:09:37.350
There's this plus whatever.,00:09:37.350,00:09:38.970
"But in particular, this is at
least the nth Fibonacci number.",00:09:38.970,00:09:41.720
"And if you know
Fibonacci stuff, that's",00:09:41.720,00:09:43.350
"about the golden ratio
to the nth power.",00:09:43.350,00:09:48.440
Which is bad.,00:09:48.440,00:09:50.650
"We had a similar
recurrence in AVL trees.",00:09:50.650,00:09:52.930
"And so another way
to solve it-- it's",00:09:52.930,00:09:55.850
"just good review--
say, oh well, that's",00:09:55.850,00:09:59.100
at least 2 times t of n minus 2.,00:09:59.100,00:10:03.600
"Because it's going
to be monotone.",00:10:03.600,00:10:05.020
"The bigger n is, the
more work you have to do.",00:10:05.020,00:10:07.331
"Because to do the
nth thing you have",00:10:07.331,00:10:08.830
to do the n minus first thing.,00:10:08.830,00:10:10.770
"So we could just reduce t of
n minus 1 to t of n minus 2.",00:10:10.770,00:10:14.260
That will give us a lower bound.,00:10:14.260,00:10:16.620
"And now these two terms-- now
this is sort of an easy thing.",00:10:16.620,00:10:19.700
"You see that you're
multiplying by 2 each time.",00:10:19.700,00:10:22.950
"You're subtracting
2 from n each time.",00:10:22.950,00:10:24.670
"How many times can
I subtract 2 from n?",00:10:24.670,00:10:27.270
"N/2 times, before I
get down to a constant.",00:10:27.270,00:10:30.390
"And so this is equal
to 2 to the n over 2--",00:10:30.390,00:10:37.740
"I mean, times some
constant, which",00:10:37.740,00:10:39.460
"is what you get
in the base case.",00:10:39.460,00:10:41.900
So I guess I should say theta.,00:10:41.900,00:10:45.970
This thing is theta that.,00:10:45.970,00:10:48.890
OK.,00:10:48.890,00:10:49.390
So it's at least that big.,00:10:49.390,00:10:51.320
And the right constant is phi.,00:10:51.320,00:10:56.302
And the base of the exponent.,00:10:56.302,00:10:58.620
OK.,00:10:58.620,00:10:59.120
So that's a bad algorithm.,00:10:59.120,00:11:00.203
"We all know it's
a bad algorithm.",00:11:00.203,00:11:03.690
"But I'm going to give you a
general approach for making",00:11:03.690,00:11:06.670
bad algorithms like this good.,00:11:06.670,00:11:09.000
"And that general approach
is called memoization.",00:11:09.000,00:11:11.036
We'll go over here.,00:11:14.170,00:11:16.600
"And this is a technique
of dynamic programming.",00:11:19.910,00:11:21.900
"So I'm going to call this the
memoized dynamic programming",00:11:24.708,00:11:28.370
algorithm.,00:11:28.370,00:11:28.870
"So did I settle on
using memo in the notes?",00:11:36.840,00:11:44.270
Yeah.,00:11:44.270,00:11:44.770
The idea is simple.,00:11:48.570,00:11:50.520
"Whenever we compute
a Fibonacci number",00:11:50.520,00:11:52.870
we put it in a dictionary.,00:11:52.870,00:11:55.167
"And then when we need to
compute the nth Fibonacci",00:11:55.167,00:11:57.250
"number we check, is it
already in the dictionary?",00:11:57.250,00:11:58.825
"Did we already
solve this problem?",00:11:58.825,00:12:00.241
"If so, return that answer.",00:12:00.241,00:12:03.020
"Otherwise, computer it.",00:12:03.020,00:12:05.085
"You'll see the transformation
is very simple.",00:12:05.085,00:12:06.960
OK.,00:12:57.810,00:12:59.040
"These two lines are
identical to these two lines.",00:12:59.040,00:13:04.650
"So you can see how
the transformation",00:13:04.650,00:13:06.320
works in general.,00:13:06.320,00:13:07.730
"You could do this with
any recursive algorithm.",00:13:07.730,00:13:10.856
"The memoization transformation
on that algorithm--",00:13:10.856,00:13:14.700
"which is, we initially make an
empty dictionary called memo.",00:13:14.700,00:13:19.050
"And before we actually do
the computation we say,",00:13:19.050,00:13:22.950
"well, check whether this version
of the Fibonacci problem,",00:13:22.950,00:13:26.820
"computing f of n, is
already in our dictionary.",00:13:26.820,00:13:31.432
"So if that key is already
in the dictionary,",00:13:31.432,00:13:33.265
"we return the corresponding
value in the dictionary.",00:13:33.265,00:13:35.935
"And then once we've computed
the nth Fibonacci number,",00:13:38.960,00:13:41.590
"if we bothered to do this,
if this didn't apply,",00:13:41.590,00:13:44.780
"then we store it
in the memo table.",00:13:44.780,00:13:47.140
"So we say well, if you ever
need to compute f of n again,",00:13:47.140,00:13:50.900
here it is.,00:13:50.900,00:13:52.370
And then we return that value.,00:13:52.370,00:13:54.820
So this is a general procedure.,00:13:54.820,00:13:57.192
"It can apply to any
recursive algorithm",00:13:57.192,00:14:00.910
"with no side effects
I guess, technically.",00:14:00.910,00:14:04.900
"And it turns out, this makes
the algorithm efficient.",00:14:04.900,00:14:07.789
"Now there's a lot of ways
to see why it's efficient.",00:14:07.789,00:14:09.955
"In general, maybe it's helpful
to think about the recursion",00:14:12.680,00:14:15.260
tree.,00:14:15.260,00:14:16.220
"So if you want to compute
fn in the old algorithm,",00:14:16.220,00:14:19.660
"we compute fn minus
1 and fn minus two",00:14:19.660,00:14:22.550
completely separately.,00:14:22.550,00:14:23.940
"To compute fn minus 1 we compute
fn minus 2 and fn minus 3.",00:14:23.940,00:14:29.820
"To compute fn minus 2 we compute
fn minus 3 and fn minus 4.",00:14:29.820,00:14:34.720
And so on.,00:14:34.720,00:14:35.620
"And you can see why
that's exponential in n.",00:14:35.620,00:14:39.490
"Because we're only decrementing
n by one or two each time.",00:14:39.490,00:14:44.250
"But then you observe, hey,
these fn minus 3's are the same.",00:14:44.250,00:14:48.200
"I should really only have
to compute them once.",00:14:48.200,00:14:50.935
"And that's what
we're doing here.",00:14:50.935,00:14:52.310
"The first time you call
fn minus 3, you do work.",00:14:52.310,00:14:55.660
"But once it's done and you go
over to this other recursive",00:14:55.660,00:14:58.780
"call, this will
just get cut off.",00:14:58.780,00:15:00.760
There's no tree here.,00:15:00.760,00:15:02.040
"Here we might have
some recursive calling.",00:15:02.040,00:15:04.180
"Here we won't, because it's
already in the memo table.",00:15:04.180,00:15:08.700
"In fact, this already
happens with fn minus 2.",00:15:08.700,00:15:11.930
"This whole tree disappears
because fn minus 2",00:15:11.930,00:15:15.600
has already been done.,00:15:15.600,00:15:17.610
OK.,00:15:17.610,00:15:18.110
"So it's clear why
it improves things.",00:15:18.110,00:15:21.090
"So in fact you can argue
that this call will be free",00:15:21.090,00:15:24.750
"because you already
did the work in here.",00:15:24.750,00:15:27.540
"But I want to give you a very
particular way of thinking",00:15:27.540,00:15:30.700
"about why this is efficient,
which is following.",00:15:30.700,00:15:40.015
"So you could write down a
recurrence for the running time",00:16:06.550,00:16:09.800
here.,00:16:09.800,00:16:10.300
"But in some sense recurrences
aren't quite the right way",00:16:10.300,00:16:13.050
"of thinking about
this because recursion",00:16:13.050,00:16:15.240
is kind of a rare thing.,00:16:15.240,00:16:17.220
"If you're calling
Fibonacci of some value, k,",00:16:17.220,00:16:20.840
"you're only going to make
recursive calls the first time",00:16:20.840,00:16:23.700
you call Fibonacci of k.,00:16:23.700,00:16:24.930
"Because henceforth,
you've put it",00:16:24.930,00:16:28.250
"in the memo table
you will not recurse.",00:16:28.250,00:16:30.860
"So you can think of
there being two versions",00:16:30.860,00:16:35.370
of calling Fibonacci of k.,00:16:35.370,00:16:36.640
"There's the first time, which
is the non-memoized version that",00:16:36.640,00:16:40.950
does recursion-- does some work.,00:16:40.950,00:16:42.960
"And then every time
henceforth you're",00:16:42.960,00:16:46.090
"doing memoized calls
of Fibonacci of k,",00:16:46.090,00:16:48.080
and those cost constant time.,00:16:48.080,00:16:51.620
"So the memoized calls
cost constant time.",00:16:51.620,00:16:59.820
"So we can think of
them as basically free.",00:16:59.820,00:17:03.120
"That's when you call
Fibonacci of n minus 2,",00:17:03.120,00:17:06.210
"because that's a
memoized call, you really",00:17:06.210,00:17:09.210
don't pay anything for it.,00:17:09.210,00:17:10.990
"I mean, you're already
paying constant time",00:17:10.990,00:17:12.781
to do addition and whatever.,00:17:12.781,00:17:14.250
"So you don't have to
worry about the time.",00:17:14.250,00:17:16.089
There's no recursion here.,00:17:16.089,00:17:18.900
"And then what we care
about is that the number",00:17:18.900,00:17:21.670
"of non-memorized calls,
which is the first time you",00:17:21.670,00:17:26.950
"call Fibonacci of k, is n.",00:17:26.950,00:17:33.925
No theta is even necessary.,00:17:33.925,00:17:35.640
"We are going to
call Fibonacci of 1.",00:17:35.640,00:17:38.990
"At some point we're going
to call Fibonacci of 2",00:17:38.990,00:17:41.860
"at some point, and the original
call is Fibonacci of n.",00:17:41.860,00:17:46.039
"All of those things will
be called at some point.",00:17:46.039,00:17:48.080
That's pretty easy to see.,00:17:48.080,00:17:49.650
"But in particular,
certainly at most this,",00:17:49.650,00:17:52.050
"we never call
Fibonacci of n plus 1",00:17:52.050,00:17:53.900
to compute Fibonacci of n.,00:17:53.900,00:17:55.820
So it's at most n calls.,00:17:55.820,00:17:57.460
"Indeed it will be exactly n
calls that are not memoized.",00:17:57.460,00:18:00.880
Those ones we have to pay for.,00:18:00.880,00:18:02.130
How much do we have to pay?,00:18:02.130,00:18:03.650
"Well, if you don't count
the recursion-- which",00:18:03.650,00:18:07.610
"is what this recurrence
does-- if you ignore",00:18:07.610,00:18:09.840
"recursion then the total amount
of work done here is constant.",00:18:09.840,00:18:13.235
"So I will say the non-recursive
work per call is constant.",00:18:16.110,00:18:30.630
"And therefore I claim
that the running time is",00:18:30.630,00:18:34.010
"constant-- I'm sorry, is linear.",00:18:34.010,00:18:37.870
"Constant would be
pretty amazing.",00:18:37.870,00:18:41.390
"This is actually not the
best algorithm-- as an aside.",00:18:41.390,00:18:44.310
"The best algorithm for computing
the nth Fibonacci number",00:18:44.310,00:18:46.720
"uses log n arithmetic
operations.",00:18:46.720,00:18:50.299
"So you can do better,
but if you want",00:18:50.299,00:18:51.840
"to see that you
should take 6046.",00:18:51.840,00:18:55.430
OK.,00:18:55.430,00:18:55.950
"We're just going to get
to linear today, which",00:18:55.950,00:18:57.866
"is a lot better
than exponential.",00:18:57.866,00:19:01.430
So why linear?,00:19:01.430,00:19:03.890
"Because there's n non-memoize
calls, and each of them",00:19:03.890,00:19:07.700
cost constant.,00:19:07.700,00:19:08.690
"So it's the product
of those two numbers.",00:19:08.690,00:19:12.330
This is an important idea.,00:19:12.330,00:19:14.820
"And it's so important
I'm going to write it",00:19:14.820,00:19:18.320
"down again in a slightly
more general framework.",00:19:18.320,00:19:25.080
"In general, in
dynamic programming--",00:19:25.080,00:19:37.400
"I didn't say why it's
called memoization.",00:19:37.400,00:19:40.540
"The idea is you have
this memo pad where",00:19:40.540,00:19:42.363
"you write down all
your scratch work.",00:19:42.363,00:19:44.810
That's this memo dictionary.,00:19:44.810,00:19:46.495
"And to memoize is to write
down on your memo pad.",00:19:46.495,00:19:49.390
I didn't make it up.,00:19:49.390,00:19:50.530
Another crazy term.,00:19:50.530,00:19:52.630
It means remember.,00:19:52.630,00:19:55.450
"And then you remember all the
solutions that you've done.",00:19:55.450,00:19:59.610
"And then you reuse
those solutions.",00:19:59.610,00:20:02.380
"Now these solutions are
not really a solution",00:20:02.380,00:20:04.460
"to the problem
that I care about.",00:20:04.460,00:20:06.470
"The problem I care about is
computing the nth Fibonacci",00:20:06.470,00:20:08.970
number.,00:20:08.970,00:20:09.850
"To get there I had to compute
other Fibonacci numbers.",00:20:09.850,00:20:13.230
Why?,00:20:13.230,00:20:15.060
"Because I had a
recursive formulation.",00:20:15.060,00:20:16.730
"This is not always the
way to solve a problem.",00:20:16.730,00:20:19.220
"But usually when you're
solving something",00:20:19.220,00:20:22.550
"you can split it into parts,
into subproblems, we call them.",00:20:22.550,00:20:28.030
"They're not always
of the same flavor",00:20:28.030,00:20:29.700
"as your original goal
problem, but there's",00:20:29.700,00:20:31.450
some kind of related parts.,00:20:31.450,00:20:34.290
"And this is the big challenge
in designing a dynamic program,",00:20:34.290,00:20:38.040
"is to figure out what
are the subproblems.",00:20:38.040,00:20:41.410
"Let's say, the
first thing I want",00:20:41.410,00:20:43.080
"to know about a dynamic program,
is what are the subproblems.",00:20:43.080,00:20:45.621
"Somehow they are designed to
help solve your actual problem.",00:20:47.610,00:20:51.640
"And the idea of memoization is,
once you solve a subproblem,",00:20:58.650,00:21:01.650
write down the answer.,00:21:01.650,00:21:02.650
"If you ever need to solve
that same problem again",00:21:02.650,00:21:05.350
you reuse the answer.,00:21:05.350,00:21:07.400
So that is the core idea.,00:21:07.400,00:21:09.134
"And so in this sense
dynamic programming",00:21:09.134,00:21:10.800
"is essentially recursion
plus memoization.",00:21:10.800,00:21:16.025
"And so in this case these
are the subproblems.",00:21:23.490,00:21:27.450
"Fibonacci of 1 through
Fibonacci of n.",00:21:27.450,00:21:29.950
"The one we care about
is Fibonacci of n.",00:21:29.950,00:21:31.677
"But to get there we solve
these other subproblems.",00:21:31.677,00:21:33.760
"In all cases, if this
is the situation-- so",00:21:36.290,00:21:40.180
"for any dynamic program,
the running time",00:21:40.180,00:21:43.280
"is going to be equal to the
number of different subproblems",00:21:43.280,00:21:46.560
"you might have to solve,
or that you do solve,",00:21:46.560,00:21:50.590
"times the amount of time
you spend per subproblem.",00:21:50.590,00:21:54.480
OK.,00:22:00.950,00:22:01.450
"In this situation we
had n subproblems.",00:22:01.450,00:22:06.960
"And for each of them
we spent constant time.",00:22:06.960,00:22:10.900
"And when I measure the
time per subproblem",00:22:10.900,00:22:13.580
"which, in the Fibonacci
case I claim is constant,",00:22:13.580,00:22:15.890
I ignore recursive calls.,00:22:15.890,00:22:18.790
That's the key.,00:22:18.790,00:22:19.914
"We don't have to
solve recurrences",00:22:19.914,00:22:21.330
with dynamic programming.,00:22:21.330,00:22:22.630
Yay.,00:22:22.630,00:22:23.355
No recurrences necessary.,00:22:23.355,00:22:25.250
OK.,00:22:25.250,00:22:25.750
Don't count recursions.,00:22:25.750,00:22:29.840
"Obviously, don't count
memoized recursions.",00:22:34.280,00:22:36.800
"The reason is, I only
need to count them once.",00:22:36.800,00:22:39.750
"After the first time
I do it, it's free.",00:22:39.750,00:22:42.540
"So I count how many different
subproblems do I need to do?",00:22:42.540,00:22:45.835
"These are they going to be
the expensive recursions where",00:22:45.835,00:22:48.210
"I do work, I do
some amount of work,",00:22:48.210,00:22:49.810
"but I don't count the
recursions because otherwise I'd",00:22:49.810,00:22:52.060
be double counting.,00:22:52.060,00:22:53.600
"I only want to count
each subproblem once,",00:22:53.600,00:22:56.930
and then this will solve it.,00:22:56.930,00:22:59.010
So a simple idea.,00:22:59.010,00:23:00.840
"In general, dynamic programming
is a super simple idea.",00:23:00.840,00:23:03.860
It's nothing fancy.,00:23:03.860,00:23:05.390
It's basically just memoization.,00:23:05.390,00:23:07.440
"There is one extra trick
we're going to pull out,",00:23:07.440,00:23:10.730
but that's the idea.,00:23:10.730,00:23:12.770
All right.,00:23:12.770,00:23:14.110
"Let me tell you
another perspective.",00:23:14.110,00:23:24.010
"This is the one maybe
most commonly taught.",00:23:24.010,00:23:28.050
"Is to think of-- but I'm
not a particular fan of it.",00:23:28.050,00:23:31.260
I really like memoization.,00:23:31.260,00:23:32.470
I think it's a simple idea.,00:23:32.470,00:23:35.240
"And as long as you
remember this formula here,",00:23:35.240,00:23:38.500
it's really easy to work with.,00:23:38.500,00:23:39.900
"But some people like to
think of it this way.",00:23:43.240,00:23:45.560
"And so you can pick whichever
way you find most intuitive.",00:23:45.560,00:23:49.315
"Instead of thinking of a
recursive algorithm, which",00:23:49.315,00:23:51.440
"in some sense starts at the
top of what you want to solve",00:23:51.440,00:23:55.940
"and works its way down,
you could do the reverse.",00:23:55.940,00:23:58.660
"You could start at the
bottom and work your way up.",00:23:58.660,00:24:00.829
"And this is probably
how you normally",00:24:00.829,00:24:02.370
"think about computing
Fibonacci numbers",00:24:02.370,00:24:03.994
or how you learned it before.,00:24:03.994,00:24:05.754
"I'm going to write it
in a slightly funny way.",00:24:05.754,00:24:07.670
"The point I want to make
is that the transformation",00:24:31.655,00:24:33.780
"I'm doing from the naive
recursive algorithm,",00:24:33.780,00:24:38.840
"to the memoized algorithm,
to the bottom-up algorithm",00:24:38.840,00:24:42.080
is completely automated.,00:24:42.080,00:24:44.030
"I'm not thinking,
I'm just doing.",00:24:44.030,00:24:46.650
OK.,00:24:46.650,00:24:47.470
It's easy.,00:24:47.470,00:24:49.500
"This code is exactly
the same as this code",00:24:49.500,00:24:52.470
"and as that code, except
I replaced n by k.",00:24:52.470,00:24:56.590
"Just because I needed a couple
of different n values here.",00:24:56.590,00:24:59.850
"Or I want to iterate
over n values.",00:24:59.850,00:25:01.380
"And then there's this
stuff around that code",00:25:04.110,00:25:06.490
which is just formulaic.,00:25:06.490,00:25:07.690
"A little bit of thought
goes into this for loop,",00:25:11.000,00:25:13.460
but that's it.,00:25:13.460,00:25:15.160
OK.,00:25:15.160,00:25:15.660
"This does exactly the same
thing as the memoized algorithm.",00:25:15.660,00:25:19.110
"Maybe it takes a
little bit of thinking",00:25:22.525,00:25:24.150
"to realize, if you unroll all
the recursion that's happening",00:25:24.150,00:25:26.840
"here and just write
it out sequentially,",00:25:26.840,00:25:29.350
"this is exactly
what's happening.",00:25:29.350,00:25:31.830
"This code does exactly the
same additions, exactly",00:25:31.830,00:25:34.580
the same computations as this.,00:25:34.580,00:25:37.020
"The only difference
is how you get there.",00:25:37.020,00:25:39.690
"Here we're using a loop,
here we're using recursion.",00:25:39.690,00:25:42.310
"But the same things
happen in the same order.",00:25:42.310,00:25:45.559
"It's really no difference
between the code.",00:25:45.559,00:25:47.350
"This code's probably going
to be more efficient practice",00:25:47.350,00:25:49.683
"because you don't make
function calls so much.",00:25:49.683,00:25:52.980
"In fact I made a
little mistake here.",00:25:52.980,00:25:55.840
"This is not a
function call, it's",00:25:55.840,00:25:57.240
just a lookup into a table.,00:25:57.240,00:25:59.470
"Here I'm using a hash
table to be simple,",00:25:59.470,00:26:01.180
"but of course you
could use an array.",00:26:01.180,00:26:02.721
"But they're both constant
time with good hashing.",00:26:05.920,00:26:10.330
All right.,00:26:10.330,00:26:10.830
"So is it clear
what this is doing?",00:26:10.830,00:26:12.380
I think so.,00:26:12.380,00:26:13.580
I think I made a little typo.,00:26:13.580,00:26:16.410
"So we have to compute--
oh, another typo.",00:26:16.410,00:26:21.630
"We have to compute f1 up to
fn, which in python is that.",00:26:21.630,00:26:27.010
"And we compute it
exactly how we used to.",00:26:27.010,00:26:31.860
"Except now, instead
of recursing,",00:26:31.860,00:26:34.020
"I know that when I'm computing
the k Fibonacci number-- man.",00:26:34.020,00:26:38.170
So many typos.,00:26:38.170,00:26:39.135
AUDIENCE: [LAUGHTER],00:26:39.135,00:26:40.504
"PROFESSOR: You
guys are laughing.",00:26:40.504,00:26:42.920
"When I compute the
kth Fibonacci number",00:26:42.920,00:26:45.230
"I know that I've already
computed the previous two.",00:26:45.230,00:26:48.230
Why?,00:26:48.230,00:26:48.730
"Because I'm doing them
in increasing order.",00:26:48.730,00:26:50.550
Nothing fancy.,00:26:50.550,00:26:52.620
"Then I can just do
this and the solutions",00:26:52.620,00:26:55.230
will just be waiting there.,00:26:55.230,00:26:56.750
"If they work, I'd
get a key error.",00:26:56.750,00:26:58.450
So I'd know that there's a bug.,00:26:58.450,00:27:00.120
"But in fact, I won't
get a key error.",00:27:00.120,00:27:01.670
"I will have always computed
these things already.",00:27:01.670,00:27:05.090
Then I store it in my table.,00:27:05.090,00:27:06.610
Then I iterate.,00:27:06.610,00:27:07.290
"Eventually I've solved all the
subproblems, f1 through fn.",00:27:07.290,00:27:11.250
"And the one I cared
about was the nth one.",00:27:11.250,00:27:14.140
OK.,00:27:14.140,00:27:14.640
So straightforward.,00:27:14.640,00:27:17.490
"I do this because
I don't really want",00:27:17.490,00:27:19.432
"to have to go through
this transformation",00:27:19.432,00:27:21.140
for every single problem we do.,00:27:21.140,00:27:22.870
"I'm doing it in Fibonacci
because it's super easy",00:27:22.870,00:27:25.150
"to write the code
out explicitly.",00:27:25.150,00:27:27.080
"But you can do it for all
of the dynamic programs",00:27:27.080,00:27:29.200
"that we cover in the
next four lectures.",00:27:29.200,00:27:33.130
OK.,00:27:33.130,00:27:33.630
"I'm going to give you
now the general case.",00:27:33.630,00:27:35.810
"This was the special
Fibonacci version.",00:27:35.810,00:27:39.260
"In general, the bottom-up does
exactly the same computation",00:27:39.260,00:27:44.230
as the memoized version.,00:27:44.230,00:27:45.565
"And what we're doing is
actually a topological sort",00:27:51.270,00:27:59.920
"of the subproblem
dependency DAG.",00:27:59.920,00:28:05.195
"So in this case, the
dependency DAG is very simple.",00:28:13.840,00:28:17.240
"In order to compute--
I'll do it backwards.",00:28:17.240,00:28:21.330
"In order to compute fn,
I need to know fn minus 1",00:28:21.330,00:28:26.450
and fn minus 2.,00:28:26.450,00:28:28.820
"If I know those
I can compute fn.",00:28:28.820,00:28:32.090
"Then there's fn
minus 3, which is",00:28:32.090,00:28:35.080
"necessary to compute this
one, and that one, and so on.",00:28:35.080,00:28:38.450
"So you see what
this DAG looks like.",00:28:38.450,00:28:40.470
"Now, I've drawn
it conveniently so",00:28:40.470,00:28:42.160
all the edges go left to right.,00:28:42.160,00:28:43.510
"So this is a topological
order from left to right.",00:28:43.510,00:28:46.420
"And so I just need to do
f1, f2, up to fn in order.",00:28:46.420,00:28:50.760
"Usually it's totally
obvious what order",00:28:50.760,00:28:53.850
to solve the subproblems in.,00:28:53.850,00:28:55.560
"But in general, what
you should have in mind",00:28:55.560,00:28:58.320
"is that we are doing
a topological sort.",00:28:58.320,00:29:00.430
"Here we just did it in our
heads because it's so easy.",00:29:00.430,00:29:03.070
And usually it's so easy.,00:29:03.070,00:29:04.220
It's just a for loop.,00:29:04.220,00:29:05.480
Nothing fancy.,00:29:05.480,00:29:06.430
All right.,00:29:09.900,00:29:10.500
I'm missing an arrow.,00:29:13.404,00:29:14.450
All right.,00:29:20.030,00:29:22.554
"Let's do something a little
more interesting, shall we?",00:29:22.554,00:29:24.845
All right.,00:29:37.971,00:29:38.470
"One thing you can do from
this bottom-up perspective",00:29:38.470,00:29:41.770
is you can save space.,00:29:41.770,00:29:42.775
Storage space in the algorithm.,00:29:46.310,00:29:48.572
"We don't usually worry
about space in this class,",00:29:48.572,00:29:51.110
but it matters in reality.,00:29:51.110,00:29:55.910
"So here we're
building a table size,",00:29:55.910,00:29:57.500
"n, but in fact we
really only need",00:29:57.500,00:29:59.830
to remember the last two values.,00:29:59.830,00:30:02.280
"So you could just store
the last two values,",00:30:02.280,00:30:04.190
"and each time you make a
new one delete the oldest.",00:30:04.190,00:30:07.620
"so by thinking a
little bit here you",00:30:07.620,00:30:10.100
"realize you only
need constant space.",00:30:10.100,00:30:12.470
"Still linear time,
but constant space.",00:30:12.470,00:30:15.790
And that's often the case.,00:30:15.790,00:30:17.444
"From the bottom-up
perspective you",00:30:17.444,00:30:18.860
"see what you really
need to store,",00:30:18.860,00:30:20.699
what you need to keep track of.,00:30:20.699,00:30:21.990
All right.,00:30:24.830,00:30:26.359
"I guess another nice thing
about this perspective",00:30:26.359,00:30:28.400
"is, the running time
is totally obvious.",00:30:28.400,00:30:30.710
This is clearly constant time.,00:30:30.710,00:30:32.430
So this is clearly linear time.,00:30:32.430,00:30:34.730
"Whereas, in this
memoized algorithm",00:30:34.730,00:30:37.030
"you have to think
about, when's it",00:30:37.030,00:30:40.110
"going to be memoized,
when is it not?",00:30:40.110,00:30:42.150
"I still like this perspective
because, with this rule,",00:30:42.150,00:30:44.979
"just multiply a
number of subproblems",00:30:44.979,00:30:46.520
"by time per subproblem,
you get the answer.",00:30:46.520,00:30:49.110
"But it's a little less
obvious than code like this.",00:30:49.110,00:30:54.300
"So choose however you
like to think about it.",00:30:54.300,00:30:57.060
All right.,00:31:00.340,00:31:00.840
We move onto shortest paths.,00:31:00.840,00:31:02.700
"So I'm again, as usual, thinking
about single-source shortest",00:31:28.890,00:31:32.310
paths.,00:31:32.310,00:31:33.980
"So we want to compute the
shortest pathway from s",00:31:33.980,00:31:37.040
to v for all v. OK.,00:31:37.040,00:31:41.550
"I'd like to write this initially
as a naive recursive algorithm,",00:31:41.550,00:31:46.040
"which I can then memoize,
which I can then bottom-upify.",00:31:46.040,00:31:49.900
I just made that up.,00:31:49.900,00:31:53.040
"So how could I write this as
a naive recursive algorithm?",00:31:53.040,00:31:57.080
It's not so obvious.,00:31:57.080,00:31:59.710
"But first I'm going to tell you
how, just as an oracle tells",00:31:59.710,00:32:06.850
"you, here's what you should do.",00:32:06.850,00:32:08.470
"But then we're going to think
about-- go back, step back.",00:32:08.470,00:32:10.950
"Actually, it's up to you.",00:32:10.950,00:32:11.992
"I could tell you
the answer and then",00:32:11.992,00:32:13.491
"we could figure out
how we got there,",00:32:13.491,00:32:15.070
"or we could just
figure out the answer.",00:32:15.070,00:32:18.381
Preferences?,00:32:18.381,00:32:18.880
Figure it out.,00:32:22.350,00:32:22.934
All right.,00:32:22.934,00:32:23.433
Good.,00:32:23.433,00:32:24.050
No divine inspiration allowed.,00:32:24.050,00:32:26.140
So let me give you a tool.,00:32:26.140,00:32:37.584
The tool is guessing.,00:32:37.584,00:32:38.760
"This may sound silly, but
it's a very powerful tool.",00:32:42.660,00:32:45.880
"The general idea is, suppose
you don't know something",00:32:48.500,00:32:51.320
but you'd like to know it.,00:32:51.320,00:32:53.360
"So what's the answer
to this question?",00:32:53.360,00:32:55.350
I don't know.,00:32:55.350,00:32:56.630
"Man, I really want a cushion.",00:32:56.630,00:32:57.860
"How am I going to
answer the question?",00:32:57.860,00:32:59.650
Guess.,00:32:59.650,00:33:00.440
OK?,00:33:00.440,00:33:00.940
AUDIENCE: [LAUGHTER],00:33:00.940,00:33:02.530
"PROFESSOR: It's a
tried and tested method",00:33:02.530,00:33:04.310
for solving any problem.,00:33:04.310,00:33:05.490
"I'm kind of belaboring
the point here.",00:33:16.920,00:33:19.720
"The algorithmic concept is,
don't just try any guess.",00:33:19.720,00:33:23.610
Try them all.,00:33:23.610,00:33:25.960
OK?,00:33:25.960,00:33:26.747
AUDIENCE: [LAUGHTER],00:33:26.747,00:33:29.490
PROFESSOR: Also pretty simple.,00:33:29.490,00:33:30.810
"I said dynamic
programming was simple.",00:33:30.810,00:33:32.881
OK.,00:33:32.881,00:33:33.380
Try all guesses.,00:33:38.400,00:33:43.030
"This is central to the
dynamic programming.",00:33:43.030,00:33:45.430
"I know it sounds obvious, but if
I want to fix my equation here,",00:33:45.430,00:33:52.470
"dynamic programming is roughly
recursion plus memoization.",00:33:52.470,00:33:58.260
"This should really
be, plus guessing.",00:33:58.260,00:34:01.800
"Memoization, which is obvious,
guessing which is obvious,",00:34:01.800,00:34:06.340
"are the central concepts
to dynamic programming.",00:34:06.340,00:34:08.928
"I'm trying to make it sound
easy because usually people",00:34:08.928,00:34:11.219
"have trouble with
dynamic programming.",00:34:11.219,00:34:12.802
It is easy.,00:34:12.802,00:34:15.310
Try all the guesses.,00:34:15.310,00:34:16.792
"That's something a
computer can do great.",00:34:16.792,00:34:18.500
This is the brute force part.,00:34:18.500,00:34:20.111
OK.,00:34:20.111,00:34:20.610
"But we're going to
do it carefully.",00:34:20.610,00:34:23.690
Not that carefully.,00:34:23.690,00:34:24.689
"I mean, we're just
trying all the guesses.",00:34:24.689,00:34:26.690
Take the best one.,00:34:26.690,00:34:27.590
"That's kind of important
that we can choose one",00:34:33.960,00:34:35.980
to be called best.,00:34:35.980,00:34:36.864
"That's why dynamic
programming is",00:34:36.864,00:34:38.239
good for optimization problems.,00:34:38.239,00:34:39.610
"You want to maximize
something, minimize something,",00:34:39.610,00:34:42.110
"you try them all and then you
can forget about all of them",00:34:42.110,00:34:45.130
"and just reduce it
down to one thing which",00:34:45.130,00:34:47.020
"is the best one, or a best one.",00:34:47.020,00:34:50.890
OK.,00:34:50.890,00:34:51.389
"So now I want you
to try to apply",00:34:51.389,00:34:53.830
"this principle to
shortest paths.",00:34:53.830,00:34:56.639
"Now I'm going to draw a
picture which may help.",00:34:56.639,00:34:59.380
"We have the source, s,
we have some vertex,",00:34:59.380,00:35:08.790
"v. We'd like to
find the shortest--",00:35:08.790,00:35:11.370
a shortest path from s to v.,00:35:11.370,00:35:13.870
"Suppose I want to know
what this shortest path is.",00:35:13.870,00:35:16.250
Suppose this was it.,00:35:16.250,00:35:18.092
You have an idea already?,00:35:18.092,00:35:19.790
Yeah.,00:35:19.790,00:35:21.245
"AUDIENCE: What you could do is
you could look at everywhere",00:35:21.245,00:35:27.550
you can go from s.,00:35:27.550,00:35:29.490
"[INAUDIBLE] shortest path
of each of those notes.",00:35:29.490,00:35:33.074
PROFESSOR: Good.,00:35:33.074,00:35:33.740
"So I can look at all the
places I could go from s,",00:35:33.740,00:35:37.920
"and then look at the shortest
paths from there to v.",00:35:37.920,00:35:41.790
So we could call this s prime.,00:35:41.790,00:35:45.600
So here's the idea.,00:35:45.600,00:35:46.730
"There's some hypothetical
shortest path.",00:35:46.730,00:35:50.720
"I don't know where
it goes first,",00:35:50.720,00:35:53.460
"so I will guess
where it goes first.",00:35:53.460,00:35:56.080
"I know the first
edge must be one",00:35:56.080,00:35:58.800
of the outgoing edges from s.,00:35:58.800,00:36:00.090
I don't know which one.,00:36:00.090,00:36:01.100
Try them all.,00:36:01.100,00:36:03.210
Very simple idea.,00:36:03.210,00:36:04.479
"Then from each of
those, if somehow I",00:36:04.479,00:36:06.020
"can compute the shortest
path from there to v,",00:36:06.020,00:36:10.590
"just do that and
take the best choice",00:36:10.590,00:36:13.740
for what that first edge was.,00:36:13.740,00:36:15.650
"So this would be the
guess first edge approach.",00:36:15.650,00:36:18.670
It's a very good idea.,00:36:22.340,00:36:23.690
"Not quite the one I wanted
because unfortunately",00:36:23.690,00:36:28.470
that changes s.,00:36:28.470,00:36:30.589
"And so this would
work, it would just",00:36:30.589,00:36:32.130
"be slightly less
efficient if I'm",00:36:32.130,00:36:33.504
"solving single-source
shortest paths.",00:36:33.504,00:36:36.090
"So I'm going to tweak
that idea slightly",00:36:36.090,00:36:38.010
"by guessing the last edge
instead of the first edge.",00:36:38.010,00:36:40.310
They're really equivalent.,00:36:40.310,00:36:41.962
"If I was doing this
I'd essentially",00:36:41.962,00:36:43.420
"be solving a single-target
shortest paths,",00:36:43.420,00:36:46.480
which we talked about before.,00:36:46.480,00:36:49.820
"So I'm going to draw
the same picture.",00:36:49.820,00:36:51.645
"I want to get to v. I'm
going to guess the last edge,",00:36:56.510,00:36:59.430
call it uv.,00:36:59.430,00:37:01.560
"I know it's one of the incoming
edges to v-- unless s equals v,",00:37:01.560,00:37:06.260
then there's a special case.,00:37:06.260,00:37:07.780
"As long as this path has
length of at least 1,",00:37:07.780,00:37:09.910
there's some last edge.,00:37:09.910,00:37:11.290
What is it?,00:37:11.290,00:37:12.040
I don't know.,00:37:12.040,00:37:12.840
Guess.,00:37:12.840,00:37:14.070
"Guess all the possible
incoming edges to v, and then",00:37:14.070,00:37:19.010
"recursively compute the
shortest path from s to u.",00:37:19.010,00:37:23.130
And then add on the edge v.,00:37:23.130,00:37:25.871
OK.,00:37:25.871,00:37:26.370
So what is this shortest path?,00:37:26.370,00:37:27.750
"It's delta of s comma
u, which looks the same.",00:37:27.750,00:37:32.160
"It's another subproblem
that I want to solve.",00:37:32.160,00:37:34.910
"There's v subproblems
here I care about. .",00:37:34.910,00:37:37.780
So that's good.,00:37:37.780,00:37:38.660
I take that.,00:37:38.660,00:37:39.780
"I add on the weight
of the edge uv.",00:37:39.780,00:37:41.805
"And that should hopefully
give me delta of s comma v.",00:37:44.800,00:37:50.020
"Well, if I was lucky and I
guessed the right choice of u.",00:37:50.020,00:37:53.460
"In reality, I'm not lucky.",00:37:53.460,00:37:55.490
"So I have to minimize
over all edges uv.",00:37:55.490,00:38:02.790
"So this is the--
we're minimizing",00:38:02.790,00:38:05.370
over the choice of u.,00:38:05.370,00:38:06.580
V is already given here.,00:38:06.580,00:38:08.420
"So I take the minimum over
all edges of the shortest",00:38:08.420,00:38:12.130
"path from s to u, plus
the weight of the edge uv.",00:38:12.130,00:38:17.324
"That should give me the shortest
path because this gave me",00:38:17.324,00:38:19.740
the shortest path from s to u.,00:38:19.740,00:38:21.580
"Then I added on the edge
I need to get there.",00:38:21.580,00:38:24.110
"And wherever the shortest path
is, it uses some last edge, uv.",00:38:24.110,00:38:30.120
"There's got to be some choice
of u that is the right one.",00:38:30.120,00:38:32.650
"That's the good guess
that we're hoping for.",00:38:32.650,00:38:35.245
"We don't know what
the good guess",00:38:35.245,00:38:36.620
is so we just try them all.,00:38:36.620,00:38:38.650
"But whatever it is, this will
be the weight of that path.",00:38:38.650,00:38:43.265
"It's going to take
the best path from s",00:38:43.265,00:38:44.890
"to u because sub
paths are shortest",00:38:44.890,00:38:46.650
paths are shortest paths.,00:38:46.650,00:38:47.691
Optimal substructure.,00:38:47.691,00:38:48.900
"So this part will
be delta of su.",00:38:48.900,00:38:51.456
This part is obviously w of uv.,00:38:51.456,00:38:53.950
"So this will give
the right answer.",00:38:53.950,00:38:57.760
Hopefully.,00:38:57.760,00:38:59.610
OK.,00:38:59.610,00:39:00.865
"It's certainly
going to-- I mean,",00:39:00.865,00:39:02.240
"this is the analog of the
naive recursive algorithm",00:39:02.240,00:39:05.100
for Fibonacci.,00:39:05.100,00:39:05.830
"So it's not going to be
efficient if I-- I mean,",00:39:05.830,00:39:08.190
"this is an algorithm, right?",00:39:08.190,00:39:09.850
"You could say-- this
is a recursive call.",00:39:09.850,00:39:13.720
"We're going to treat this
as recursive call instead",00:39:13.720,00:39:17.520
of just a definition.,00:39:17.520,00:39:19.910
"Then this is a
recursive algorithm.",00:39:19.910,00:39:23.290
"How good or bad is this
recursive algorithm?",00:39:23.290,00:39:27.086
AUDIENCE: Terrible.,00:39:27.086,00:39:28.010
PROFESSOR: Terrible.,00:39:28.010,00:39:28.850
Very good.,00:39:28.850,00:39:29.960
"Very bad, I should say.",00:39:29.960,00:39:31.240
"It's definitely going
to be exponential",00:39:34.000,00:39:38.080
without memoization.,00:39:38.080,00:39:39.120
But we know.,00:39:39.120,00:39:39.957
"We know how to make
algorithms better.",00:39:39.957,00:39:41.540
We memoize.,00:39:41.540,00:39:42.640
OK.,00:39:42.640,00:39:43.140
"So I think you know how to write
this as a memoized algorithm.",00:39:43.140,00:39:46.850
"To define the function delta
of sv, you first check,",00:39:46.850,00:39:51.820
is s comma v in the memo table?,00:39:51.820,00:39:54.080
If so return that value.,00:39:54.080,00:39:55.560
"Otherwise, do this computation
where this is a recursive call",00:39:55.560,00:39:59.450
"and then stored it
in the memo table.",00:39:59.450,00:40:02.820
OK.,00:40:02.820,00:40:03.460
"I don't think I need
to write that down.",00:40:03.460,00:40:05.126
"It's just like the
memoized code over there.",00:40:05.126,00:40:07.360
"Just there's now two
arguments instead of one.",00:40:07.360,00:40:11.190
"In fact, s isn't changing.",00:40:11.190,00:40:12.390
"So I only need to store
with v instead of s comma v.",00:40:12.390,00:40:18.500
Is that a good algorithm?,00:40:18.500,00:40:19.845
"I claim memoization
makes everything faster.",00:40:19.845,00:40:23.570
Is that a fast algorithm?,00:40:23.570,00:40:25.700
"Not so obvious, I guess.",00:40:36.560,00:40:37.640
Yes?,00:40:51.080,00:40:52.570
"How many people think, yes,
that's a good algorithm?",00:40:52.570,00:40:54.990
AUDIENCE: Better.,00:40:54.990,00:40:55.750
PROFESSOR: Better.,00:40:55.750,00:40:56.030
Definitely better.,00:40:56.030,00:40:57.090
Can't be worse.,00:40:57.090,00:40:58.340
"How many people think it's
a bad algorithm still?",00:40:58.340,00:41:00.960
OK.,00:41:00.960,00:41:01.460
"So three for yes, zero for no.",00:41:01.460,00:41:04.760
How many people aren't sure?,00:41:04.760,00:41:08.840
Including the yes votes?,00:41:08.840,00:41:09.871
Good.,00:41:09.871,00:41:10.370
All right.,00:41:12.970,00:41:13.570
It's not so tricky.,00:41:13.570,00:41:14.410
Let me draw you a graph.,00:41:14.410,00:41:15.415
Something like that.,00:41:27.372,00:41:30.350
"So we wanted to commit
delta of s comma",00:41:30.350,00:41:32.330
"v. Let me give these
guys names, a and b.",00:41:32.330,00:41:36.670
"So we compute delta of
s comma v. To compute",00:41:36.670,00:41:39.380
"that we need to know delta
of s comma a and delta",00:41:39.380,00:41:45.830
of s comma v. All right?,00:41:45.830,00:41:48.110
"Those are the two ways-- sorry,
actually we just need one.",00:41:48.110,00:41:51.990
"Only one incoming edge to v.
So its delta of s comma a.",00:41:51.990,00:41:57.640
"Sorry-- I should have
put a base case here too.",00:42:00.950,00:42:04.090
Delta of s comma s equals 0.,00:42:04.090,00:42:07.150
OK.,00:42:10.200,00:42:10.700
"Delta of s comma
a plus the edge.",00:42:10.700,00:42:12.801
OK.,00:42:12.801,00:42:13.300
"There is some
shortest path to a.",00:42:13.300,00:42:14.940
"To compute the
shortest path to a we",00:42:14.940,00:42:16.520
"look at all the
incoming edges to a.",00:42:16.520,00:42:18.020
There's only one.,00:42:18.020,00:42:19.400
So delta of s comma b.,00:42:19.400,00:42:22.320
"Now I want to compute the
shortest paths from b.",00:42:22.320,00:42:24.620
"Well, there's two
ways to get to b.",00:42:24.620,00:42:26.220
"One of them is delta of s
comma b-- sorry, s comma s.",00:42:26.220,00:42:33.730
Came from s.,00:42:33.730,00:42:35.470
"The other way is delta of s
comma v. Do you see a problem?",00:42:35.470,00:42:42.760
Yeah.,00:42:42.760,00:42:44.540
"Delta of s comma v is what
we were trying to figure out.",00:42:44.540,00:42:47.420
"Now you might say, oh,
it's OK because we're",00:42:50.080,00:42:51.990
"going to memoize our
answer to delta s comma v",00:42:51.990,00:42:54.060
and then we can reuse it here.,00:42:54.060,00:42:55.309
"Except, we haven't finished
computing delta of s",00:42:55.309,00:42:57.530
"comma v. We can only put it in
the memo table once we're done.",00:42:57.530,00:43:02.340
"So when this call happens the
memo table has not been set.",00:43:02.340,00:43:06.430
"And we're going to
do the same thing",00:43:06.430,00:43:07.930
over and over and over again.,00:43:07.930,00:43:09.840
This is an infinite algorithm.,00:43:09.840,00:43:12.890
Oops.,00:43:12.890,00:43:14.740
Not so hot.,00:43:14.740,00:43:15.560
"So it's going to be infinite
time on graphs with cycles.",00:43:19.410,00:43:30.160
OK.,00:43:35.155,00:43:35.655
"For DAGs, for acyclic graphs, it
actually runs in v plus e time.",00:43:35.655,00:43:42.400
This is the good case.,00:43:42.400,00:43:43.670
"In this situation we
can use this formula.",00:43:43.670,00:43:46.930
"The time is equal to the
number of subproblems",00:43:46.930,00:43:48.940
times the time per subproblem.,00:43:48.940,00:43:52.320
"So I guess we have to think
about that a little bit.",00:43:52.320,00:43:55.040
Where's my code?,00:43:55.040,00:43:55.720
Here's my code.,00:43:55.720,00:43:57.190
"Number of subproblems
is v. There's",00:43:57.190,00:44:00.660
"v different subproblems
that I'm using here.",00:44:00.660,00:44:03.110
"I'm always reusing
subproblems of the form delta",00:44:03.110,00:44:05.360
s comma something.,00:44:05.360,00:44:06.400
"The something could be
any of the v vertices.",00:44:06.400,00:44:10.310
"How much time do I
spend per subproblem?",00:44:10.310,00:44:14.620
That's a little tricky.,00:44:14.620,00:44:15.790
"It's the number
of incoming edges",00:44:15.790,00:44:17.640
"to v. So time for a
sub problem delta of sv",00:44:17.640,00:44:30.710
"is the indegree of v. The
number of incoming edges to v.",00:44:30.710,00:44:36.850
"So this depends on
v. So I can't just",00:44:36.850,00:44:39.230
"take a straightforward
product here.",00:44:39.230,00:44:41.050
"What this is really
saying is, you",00:44:41.050,00:44:42.466
"should sum up over
all sub problems",00:44:42.466,00:44:44.130
of the time per sub problem.,00:44:44.130,00:44:46.600
"So total time is the sum over
all v and v, the indegree of v.",00:44:46.600,00:44:58.360
"And we know this
is number of edges.",00:44:58.360,00:45:02.920
"It's really-- so indegree
plus 1, indegree plus 1.",00:45:02.920,00:45:06.650
So this is v plus v. OK.,00:45:06.650,00:45:11.000
Handshaking again.,00:45:11.000,00:45:14.060
OK.,00:45:14.060,00:45:14.680
"Now we already knew an algorithm
for shortest paths and DAGs.",00:45:14.680,00:45:17.340
And it ran a v plus e time.,00:45:17.340,00:45:18.650
"So it's another way
to do the same thing.",00:45:18.650,00:45:21.370
"If you think about
it long enough,",00:45:21.370,00:45:23.930
"this algorithm
memoized, is essentially",00:45:23.930,00:45:27.340
"doing a depth first search
to do a topological sort",00:45:27.340,00:45:30.770
"to run one round
of Bellman-Ford.",00:45:30.770,00:45:33.440
"So we had topological sort
plus one round of Bellman-Ford.",00:45:33.440,00:45:36.120
"This is kind of it
all rolled into one.",00:45:36.120,00:45:38.160
"This should look kind of like
the Bellman Ford relaxation",00:45:38.160,00:45:40.630
"step, or shortest
paths relaxation step.",00:45:40.630,00:45:42.960
It is.,00:45:42.960,00:45:44.150
"This min is really
doing the same thing.",00:45:44.150,00:45:46.724
"So it's really the
same algorithm.",00:45:46.724,00:45:48.140
"But we come at it from
a different perspective.",00:45:48.140,00:45:50.098
OK.,00:45:52.400,00:45:53.470
"But I claim I can use
this same approach",00:45:53.470,00:45:55.870
"to solve shortest paths in
general graphs, even when they",00:45:55.870,00:45:58.830
have cycles.,00:45:58.830,00:46:01.540
How am I going to do that?,00:46:01.540,00:46:04.170
"DAGs seem fine-- oh, what
was the lesson learned here?",00:46:04.170,00:46:08.980
"Lesson learned is that
subproblem dependencies",00:46:08.980,00:46:18.400
should be acyclic.,00:46:18.400,00:46:19.450
"Otherwise, we get an
infinite algorithm.",00:46:19.450,00:46:22.240
"For memoization to work
this is what you need.",00:46:22.240,00:46:24.990
It's all you need.,00:46:24.990,00:46:26.050
OK.,00:46:29.590,00:46:30.090
We've almost seen this already.,00:46:30.090,00:46:32.460
"Because I said that, to
do a bottom up algorithm",00:46:32.460,00:46:35.090
"you do a topological sort of
this subproblem dependency DAG.",00:46:35.090,00:46:39.140
"I already said it
should be acyclic.",00:46:39.140,00:46:40.641
OK.,00:46:40.641,00:46:41.140
We just forgot.,00:46:41.140,00:46:42.490
I didn't tell you yet.,00:46:42.490,00:46:43.872
"So for that to work
it better be acyclic.",00:46:43.872,00:46:45.580
"For DP to work, for memoization
to work, it better be acyclic.",00:46:45.580,00:46:48.870
"If you're acyclic then
this is the running time.",00:46:48.870,00:46:55.530
So that's all general.,00:46:55.530,00:46:59.590
OK.,00:46:59.590,00:47:00.090
"So somehow I need to
take a cyclic graph",00:47:00.090,00:47:02.060
and make it acyclic.,00:47:02.060,00:47:03.005
"We've actually done this
already in recitation.",00:47:08.047,00:47:10.005
"So if I have a
graph-- let's take",00:47:18.740,00:47:22.830
a very simple cyclic graph.,00:47:22.830,00:47:25.850
OK.,00:47:25.850,00:47:26.350
"One thing I could do is explode
it into multiple layers.",00:47:26.350,00:47:29.570
"We did this on quiz
two in various forms.",00:47:29.570,00:47:32.400
"It's like the only cool thing
you can do with shortest paths,",00:47:32.400,00:47:35.020
I feel like.,00:47:35.020,00:47:37.882
"If you want to make a
shortest path problem harder,",00:47:37.882,00:47:40.200
"require that you reduce your
graph to k copies of the graph.",00:47:40.200,00:47:45.597
"I'm going to do it
in a particular way",00:47:45.597,00:47:47.180
"here-- which I think you've
seen in recitation-- which",00:47:47.180,00:47:50.580
"is to think of this axis as
time, or however you want,",00:47:50.580,00:47:54.360
"and make all of the
edges go from each layer",00:47:54.360,00:47:57.090
to the next layer.,00:47:57.090,00:47:58.050
"This should be a
familiar technique.",00:48:01.080,00:48:03.470
"So the idea is,
every time I follow",00:48:03.470,00:48:05.340
"an edge I go down
to the next layer.",00:48:05.340,00:48:07.440
This makes any graph acyclic.,00:48:07.440,00:48:09.740
Done.,00:48:09.740,00:48:11.510
"What in the world
does this mean?",00:48:11.510,00:48:13.640
What is it doing?,00:48:13.640,00:48:14.550
What does it mean?,00:48:20.070,00:48:21.960
Double rainbow.,00:48:21.960,00:48:23.100
All right.,00:48:23.100,00:48:23.600
AUDIENCE: [LAUGHTER],00:48:23.600,00:48:24.433
"PROFESSOR: So-- I
don't know how I've",00:48:24.433,00:48:26.694
"gone so long in the
semester without referring",00:48:26.694,00:48:28.610
to double rainbow.,00:48:28.610,00:48:29.360
It used to be my favorite.,00:48:29.360,00:48:30.680
All right.,00:48:30.680,00:48:31.180
So here's what it means.,00:48:31.180,00:48:34.570
Delta sub k of sv.,00:48:34.570,00:48:37.019
"I'm going to define
this first-- this",00:48:37.019,00:48:38.560
"is a new kind of
subproblem-- which",00:48:38.560,00:48:41.640
"is, what is the shortest-- what
is the weight of the shortest",00:48:41.640,00:48:49.220
"s to v path that uses,
at most, k edges.",00:48:49.220,00:48:54.525
"So I want it to be shortest
in terms of total weight,",00:48:58.732,00:49:00.940
"but I also want it to
use few edges total.",00:49:00.940,00:49:03.090
So this is going to be 0.,00:49:03.090,00:49:05.200
"In some sense, if you
look at-- so here's s",00:49:05.200,00:49:08.580
"and I'm always going
to make s this.",00:49:08.580,00:49:11.890
"And then this is going to
be v in the zero situation.",00:49:11.890,00:49:15.370
"This is going to be v
in the one situation,",00:49:15.370,00:49:17.460
"v-- so if I look at this
v, I look at the shortest",00:49:17.460,00:49:20.600
"path from s to v, that
is delta sub 0 of sv.",00:49:20.600,00:49:24.040
"So maybe I'll call this v
sub 0, v sub 1, v sub 2.",00:49:24.040,00:49:28.460
OK.,00:49:28.460,00:49:28.960
"Shortest path from
here to here is,",00:49:28.960,00:49:30.585
"there's no way to
get there on 0 edges.",00:49:30.585,00:49:32.390
"Shortest path from
here to here, that",00:49:32.390,00:49:33.970
"is the best way to get there
with, at most, one edge.",00:49:33.970,00:49:38.166
"Shortest path from
here to here--",00:49:38.166,00:49:39.540
"well, if I add some
vertical edges too,",00:49:39.540,00:49:41.770
"I guess, cheating a little bit.",00:49:41.770,00:49:43.436
"Then this is the best
way to get from s",00:49:43.436,00:49:45.060
to v using at most two edges.,00:49:45.060,00:49:46.960
"And then you get
a recurrence which",00:49:46.960,00:49:51.000
is the min over all last edges.,00:49:51.000,00:49:54.750
"So I'm just copying
that recurrence,",00:49:54.750,00:49:56.570
"but realizing that the s to
u part uses one fewer edge.",00:49:56.570,00:50:03.040
And then I use the edge uv.,00:50:03.040,00:50:04.331
OK.,00:50:07.198,00:50:07.698
That's our new recurrence.,00:50:07.698,00:50:09.330
"By adding this k
parameter I've made",00:50:09.330,00:50:11.380
"this recurrence on
subproblems acyclic.",00:50:11.380,00:50:14.180
"Unfortunately, I've increased
the number of subproblems.",00:50:14.180,00:50:17.050
"The number of subproblems
now is v squared.",00:50:17.050,00:50:28.250
"Technically, v times v minus 1.",00:50:28.250,00:50:30.840
"Because I really--
actually, v squared.",00:50:30.840,00:50:32.880
Sorry.,00:50:32.880,00:50:34.130
I start at 0.,00:50:34.130,00:50:36.860
"And what I care about, my goal,
is delta sub v minus 1 of sv.",00:50:36.860,00:50:46.210
"Because by
Bellman-Ford analysis I",00:50:46.210,00:50:47.900
"know that I only care about
simple paths, paths of length",00:50:47.900,00:50:51.270
at most v minus 1.,00:50:51.270,00:50:52.040
"I'm assuming here no
negative weight cycles.",00:50:52.040,00:50:53.873
I should've said that earlier.,00:50:53.873,00:50:55.450
"If you assume that, then
this is what I care about.",00:50:55.450,00:50:58.620
So k ranges from 0 to v minus 1.,00:50:58.620,00:51:00.380
So there are v choices for k.,00:51:00.380,00:51:02.160
"There are v choices for v.
So the number of subproblems",00:51:02.160,00:51:04.860
is v squared.,00:51:04.860,00:51:05.510
"How much time do I
spend per subproblem?",00:51:05.510,00:51:07.230
"Well, the same as before.",00:51:07.230,00:51:08.271
"The indegree-- where
did I write it?",00:51:08.271,00:51:09.890
"Up here-- the indegree
of that problem.",00:51:09.890,00:51:13.012
"So what I'm really
doing is summing",00:51:13.012,00:51:14.470
over all v of the indegree.,00:51:14.470,00:51:17.400
"And then I multiply it by
v. So the running time,",00:51:17.400,00:51:19.850
total running time is ve.,00:51:19.850,00:51:25.240
Sound familiar?,00:51:25.240,00:51:26.740
"This is Bellman-Ford's
algorithm again.",00:51:26.740,00:51:29.660
"And this is actually where
Bellman-Ford algorithm",00:51:29.660,00:51:32.410
"came from is this view
on dynamic programming.",00:51:32.410,00:51:35.810
"So we're seeing yet another
way to do Bellman-Ford.",00:51:35.810,00:51:38.640
It may seem familiar.,00:51:38.640,00:51:39.660
"But in the next
three lectures we're",00:51:39.660,00:51:41.160
"going to see a whole
bunch of problems",00:51:41.160,00:51:42.743
"that can succumb to
the same approach.",00:51:42.743,00:51:44.650
And that's super cool.,00:51:44.650,00:51:47.040
