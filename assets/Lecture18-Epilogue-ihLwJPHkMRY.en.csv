text,start,stop
"ANNOUNCER: The following program
is brought to you by Caltech.",00:00:00.580,00:00:03.270
YASER ABU-MOSTAFA: Welcome back.,00:00:16.149,00:00:17.399
"Last time, we talked about three learning
principles that, if you're in",00:00:19.570,00:00:24.410
"the business of machine learning, you
should be aware of in order to avoid",00:00:24.410,00:00:27.910
"the very common pitfalls in
applying machine learning.",00:00:27.910,00:00:32.299
"The first one is Occam's razor, which
says simpler is better-- and better in",00:00:32.299,00:00:37.150
terms of the performance.,00:00:37.150,00:00:38.860
"And therefore, you should use a razor
in order to trim the explanation of",00:00:38.860,00:00:43.690
"the data-- the hypothesis, or the
complexity of the hypothesis set in",00:00:43.690,00:00:46.690
"this case-- in order to get to the bare
minimum that is consistent with the",00:00:46.690,00:00:51.910
data that you have.,00:00:51.910,00:00:53.810
"Now, in making this a specific statement
that is justified, we had",00:00:53.810,00:00:59.280
"simply two arguments that are
interesting in their own right.",00:00:59.280,00:01:03.030
"One of them is the fact that a complexity
of an object corresponds to",00:01:03.030,00:01:08.190
the complexity of a class of objects.,00:01:08.190,00:01:11.230
So this correspondence was one.,00:01:11.230,00:01:13.270
"The other one is that if you have
an unlikely event, then when it does",00:01:13.270,00:01:18.730
"happen, that is more significant than if
it was a likely event to begin with.",00:01:18.730,00:01:24.140
"And when we put them together, we get
the proofs of Occam's razor under",00:01:24.140,00:01:28.850
different assumptions.,00:01:28.850,00:01:31.770
"The second principle had to do with
sampling bias, which reminds you of",00:01:31.770,00:01:36.580
"the fact that we said that the training
data comes from the same",00:01:36.580,00:01:42.130
distribution as the test data.,00:01:42.130,00:01:43.680
"That was the basic assumption in all
of our theoretical analysis.",00:01:43.680,00:01:47.130
"And when it doesn't, then
there is a bias.",00:01:47.130,00:01:49.380
"And since your learning algorithm learns
only from the training data, it",00:01:49.380,00:01:54.070
"is going to inherit whatever it is
that is in the training data as",00:01:54.070,00:01:57.490
a distribution.,00:01:57.490,00:01:58.460
"And therefore, the result will
be accordingly biased.",00:01:58.460,00:02:02.190
"If the mismatch is nice and continuous,
at least nonzero for all",00:02:02.190,00:02:08.630
"the points, then there is a way to
compensate for the sampling bias, by",00:02:08.630,00:02:11.820
"trying to make the sample look as
if it was coming from the other",00:02:11.820,00:02:14.920
distribution.,00:02:14.920,00:02:16.200
"But if the training data doesn't
represent a particular part of the",00:02:16.200,00:02:19.930
"space, so that space has a probability
0 as far as the training",00:02:19.930,00:02:22.840
is concerned.,00:02:22.840,00:02:23.700
"But it has a positive probability for
the test, then there is really nothing",00:02:23.700,00:02:27.740
"that can be done to replicate the
behavior of the target function over",00:02:27.740,00:02:30.960
that part of the space.,00:02:30.960,00:02:32.250
"And therefore, you get something
that is inherently biased.",00:02:32.250,00:02:36.610
"The last principle had to do with data
snooping, which is the most important",00:02:36.610,00:02:40.940
"in terms of being a trap
that you fall into.",00:02:40.940,00:02:43.600
"And the idea here is that when you
use a data set in the training,",00:02:43.600,00:02:49.010
in any capacity--,00:02:49.010,00:02:49.860
it could be very light capacity.,00:02:49.860,00:02:51.260
"And we saw an example, where the only way
the data was used was in order to",00:02:51.260,00:02:56.770
"derive normalization constants for
the inputs, something very light.",00:02:56.770,00:03:01.490
"Nonetheless, the fact that you used
the data means that you cannot",00:03:01.490,00:03:04.480
"call it test set after that, and
trust the performance that is",00:03:04.480,00:03:09.470
suggested by that data set.,00:03:09.470,00:03:11.930
"And indeed, we took a case where we
allowed snooping, and we ended up with",00:03:11.930,00:03:15.760
very optimistic view,00:03:15.760,00:03:16.890
"when in reality, the performance
was very poor.",00:03:16.890,00:03:19.720
"And of course, if you go for the real
out-of-sample, you hand the system to",00:03:19.720,00:03:23.140
your customer and they test it.,00:03:23.140,00:03:24.910
"They will see the real out of
sample, not the optimistic",00:03:24.910,00:03:26.980
performance that you had.,00:03:26.980,00:03:28.230
Today's lecture is the final lecture.,00:03:30.830,00:03:32.820
"And I am going to use it in order to
give the big picture of machine",00:03:32.820,00:03:37.300
"learning, and try to fit the
stuff that we covered",00:03:37.300,00:03:39.990
within the big picture.,00:03:39.990,00:03:41.340
"And then, tie up a couple of loose
ends that are relevant to that.",00:03:41.340,00:03:46.480
So here is the outline.,00:03:46.480,00:03:49.700
"First, I'm going to talk about the map
of machine learning, because machine",00:03:49.700,00:03:53.880
"learning is pretty diverse
as you will see.",00:03:53.880,00:03:57.190
"And we will see what we covered and
how you can pursue it further, and",00:03:57.190,00:04:01.690
"what topics I would recommend
that you read about.",00:04:01.690,00:04:05.490
And then we'll take two topics--,00:04:05.490,00:04:06.720
"I'll explain why we picked these
two topics, and talk about",00:04:06.720,00:04:09.640
them in some detail.,00:04:09.640,00:04:10.500
"Not in very technical detail like we covered
the topics of this course, but at",00:04:10.500,00:04:14.820
"least to give you some background about
where these topics stand as far",00:04:14.820,00:04:19.070
as machine learning is concerned.,00:04:19.070,00:04:20.720
"So that if you decide to pursue
them, you have a head start.",00:04:20.720,00:04:24.630
"And finally, I'm going to acknowledge
the people who have contributed",00:04:24.630,00:04:27.530
greatly to this course.,00:04:27.530,00:04:29.670
"Well, when it comes to machine learning,
it's a jungle out there.",00:04:33.920,00:04:37.710
"And it's interesting that if you buy two
books on machine learning, and you",00:04:37.710,00:04:42.100
"look at them, you will feel that you
are reading about two completely",00:04:42.100,00:04:45.290
different subjects.,00:04:45.290,00:04:46.510
"If one of them is theoretical, and
particular theory-- there are a bunch",00:04:46.510,00:04:49.750
"of theories-- and one of them is
practical, or one of them is",00:04:49.750,00:04:52.790
"emphasizing a particular technique,
they just have nothing in common.",00:04:52.790,00:04:56.090
Not even the jargon.,00:04:56.090,00:04:57.970
"So if you go out on your own and just
look at what happens in machine",00:04:57.970,00:05:02.850
"learning, pretty much this is
the picture you will get.",00:05:02.850,00:05:05.390
Not a pretty picture.,00:05:08.900,00:05:11.530
"And you can see buzzwords galore,",00:05:11.530,00:05:14.160
"and people will get excited about one
thing and tell you that this is God's",00:05:14.160,00:05:18.570
gift to humanity.,00:05:18.570,00:05:19.570
"And the other thing-- people
will be very opinionated.",00:05:19.570,00:05:22.530
It's just all over the place.,00:05:22.530,00:05:25.140
"So I'm not going to attempt
to be complete.",00:05:25.140,00:05:29.920
Because being complete here is fatal.,00:05:29.920,00:05:31.720
"Trying to cover everything so that
everybody is happy that you covered",00:05:31.720,00:05:34.700
"the results they got, I don't think
this is a good strategy.",00:05:34.700,00:05:38.160
"I preached Occam's razor
last time.",00:05:38.160,00:05:43.770
Remember Occam's razor?,00:05:43.770,00:05:45.530
"You should have a razor, and then you
should trim, trim, trim, until you get",00:05:45.530,00:05:49.560
the essential part.,00:05:49.560,00:05:51.140
"This is pretty much what
I tried to do here.",00:05:51.140,00:05:53.800
"Because I believe that if you understand
the fundamentals, inside",00:05:53.800,00:05:57.550
"out, you can pursue things completely
on your own from then on.",00:05:57.550,00:06:03.130
"You are not going to be intimidated
by grandiose statements of",00:06:03.130,00:06:07.400
one nature or another.,00:06:07.400,00:06:09.120
"You will know where things
lie, and whatnot.",00:06:09.120,00:06:10.770
"So my task was to get the
foundation right.",00:06:10.770,00:06:13.960
"And in the course of doing that, I
had to omit many, many topics.",00:06:13.960,00:06:18.930
"So now I'm going to give you the map
of the whole thing, what we covered",00:06:18.930,00:06:22.410
"and what can be pursued, in
order just to have a good",00:06:22.410,00:06:26.090
outlook on the situation.,00:06:26.090,00:06:28.060
So here is the map.,00:06:28.060,00:06:29.310
There is theory.,00:06:32.950,00:06:34.990
"And theory means that you mathematically
model what happens in",00:06:34.990,00:06:39.530
"reality, and then try to do mathematical
derivation in order to",00:06:39.530,00:06:43.270
"arrive at results that are
not otherwise obvious.",00:06:43.270,00:06:45.940
That's what theory is in general.,00:06:45.940,00:06:48.530
"And there are usually two aspects when
you look at a theory: what assumptions",00:06:48.530,00:06:52.780
"they made, and then what the derivation
is in order to get to the results.",00:06:52.780,00:06:58.500
"I hardly ever saw a situation
where there's a problem",00:06:58.500,00:07:01.590
with the second part.,00:07:01.590,00:07:03.080
"People are very competent
mathematicians.",00:07:03.080,00:07:04.700
"They are not going to make
a mistake in derivation.",00:07:04.700,00:07:06.960
"So the chances are, when they make
a statement mathematically, they",00:07:06.960,00:07:10.410
actually mean it and they proved it.,00:07:10.410,00:07:12.310
So that is not our concern.,00:07:12.310,00:07:14.490
"The biggest pitfall in theory is that
people make assumptions that make what",00:07:14.490,00:07:19.210
"they are solving really divorced from
the practice that you are going to see",00:07:19.210,00:07:23.670
when you use machine learning.,00:07:23.670,00:07:25.470
"And when I picked a theory,
I picked it with a view to",00:07:25.470,00:07:28.100
relevance to practice.,00:07:28.100,00:07:29.880
I wanted to get something.,00:07:29.880,00:07:30.890
"It has to obviously be mathematical,",00:07:30.890,00:07:32.210
"and it has to be proved,
and all of that.",00:07:32.210,00:07:34.640
"But then when you see the
result, you can use it.",00:07:34.640,00:07:37.440
"And I will go through other alternatives
that have succeeded in",00:07:37.440,00:07:40.860
that to different degrees.,00:07:40.860,00:07:43.670
"Then there are techniques, and that is
really the bulk of machine learning.",00:07:43.670,00:07:48.030
"We covered some techniques, but I'm
going to categorize techniques into",00:07:48.030,00:07:51.290
two sets and give you samples.,00:07:51.290,00:07:53.340
"And then you'll understand from what we
have done where it lies and how you",00:07:53.340,00:07:57.530
can pursue it further.,00:07:57.530,00:07:59.930
"And finally, there are paradigms.",00:07:59.930,00:08:02.560
"And paradigms mean different
assumptions about",00:08:02.560,00:08:05.780
the learning situation.,00:08:05.780,00:08:06.900
"Not mathematical assumptions, but
different assumptions that deal with",00:08:06.900,00:08:10.020
"different learning situations, like
for example, supervised learning",00:08:10.020,00:08:12.850
versus reinforcement learning.,00:08:12.850,00:08:15.010
"And when you make these assumptions,
the problems you are solving are",00:08:15.010,00:08:17.870
"sufficiently different that you end up
with really a different body of",00:08:17.870,00:08:21.270
knowledge that you have to study.,00:08:21.270,00:08:22.890
"And therefore, we call them
different paradigms.",00:08:22.890,00:08:25.580
So these are basically the categories.,00:08:25.580,00:08:27.110
"Let me start with the paradigms first,
because it's the higher level,",00:08:27.110,00:08:29.590
and then go to the other ones.,00:08:29.590,00:08:31.330
We covered supervised learning.,00:08:31.330,00:08:34.500
"That was almost the exclusive
topic of the course.",00:08:34.500,00:08:37.409
"And it is, by far, the most popular
and the most useful",00:08:37.409,00:08:41.299
form of machine learning.,00:08:41.299,00:08:43.059
"So if you cover just that, you
are already very much ahead.",00:08:43.059,00:08:46.020
"The other topics are interesting and
they have applications, and they",00:08:46.020,00:08:49.350
"should be studied, but definitely not
in the league of supervised learning",00:08:49.350,00:08:53.770
in terms of impact on practice.,00:08:53.770,00:08:57.390
"We touched on unsupervised learning
with a single algorithm we had.",00:08:57.390,00:09:00.560
"But we at least got the idea
that clustering is the key.",00:09:00.560,00:09:03.340
"And indeed, clustering is the key.",00:09:03.340,00:09:04.820
"And with unsupervised, there are
also variations of that.",00:09:04.820,00:09:07.120
There are semi-supervised.,00:09:07.120,00:09:09.390
"Everything I say here has a bunch
of variations already there.",00:09:09.390,00:09:12.460
"So I'm just giving you the center
of mass of these paradigms.",00:09:12.460,00:09:17.220
"Then there is reinforcement learning
that I described in the first lecture",00:09:17.220,00:09:20.320
"very briefly, but we didn't
cover at all.",00:09:20.320,00:09:22.700
And the reason is justified.,00:09:22.700,00:09:27.960
"Because the main problem in supervised
learning was the question of",00:09:27.960,00:09:33.000
information.,00:09:33.000,00:09:33.880
"Do I have enough information in the
data in order to get the target",00:09:33.880,00:09:36.450
"function and generalize, right?",00:09:36.450,00:09:38.980
"When you go to reinforcement
learning-- remember what",00:09:38.980,00:09:40.990
reinforcement learning was.,00:09:40.990,00:09:42.270
"You don't have the target
value on the examples.",00:09:42.270,00:09:45.720
"You just take an action,
which is an output, not",00:09:45.720,00:09:48.640
"necessarily the target output,",00:09:48.640,00:09:50.150
"and then something comes to tell
you that you did well or",00:09:50.150,00:09:53.070
you didn't do well.,00:09:53.070,00:09:54.330
"So it's reinforcement of good
actions, and elimination of bad",00:09:54.330,00:10:00.270
"actions, that will make you eventually
converge to a good solution.",00:10:00.270,00:10:04.410
And we said that it applies to games.,00:10:04.410,00:10:05.890
"Let's say you're trying
to learn backgammon.",00:10:05.890,00:10:09.030
"And what you do, you just play against
yourself, generating at will examples",00:10:09.030,00:10:12.990
as you want.,00:10:12.990,00:10:13.540
Here is a situation.,00:10:13.540,00:10:14.250
What do I do?,00:10:14.250,00:10:14.880
I'll do something.,00:10:14.880,00:10:15.960
I can generate that.,00:10:15.960,00:10:17.160
"The only question is, after you do that,
how do you take the feedback of",00:10:17.160,00:10:20.690
"winning and losing and go back and
adjust your strategy, such that you",00:10:20.690,00:10:24.340
converge to a good strategy?,00:10:24.340,00:10:26.170
"So the issue here is completely
different from supervised learning.",00:10:26.170,00:10:28.480
It's not a question of information.,00:10:28.480,00:10:29.680
"It's the question of the algorithm that
will take all of these tons of",00:10:29.680,00:10:33.450
"examples that you can generate at will,
and produce a way to converge to",00:10:33.450,00:10:37.840
"a solution from one strategy to a better
strategy to a better strategy.",00:10:37.840,00:10:41.340
"So it's a completely
different paradigm.",00:10:41.340,00:10:43.250
"And if there's one topic in this
entire viewgraph that I would",00:10:43.250,00:10:49.320
"encourage you to pursue, read
about reinforcement learning.",00:10:49.320,00:10:53.030
It's a very sweet subject.,00:10:53.030,00:10:54.280
"Finally, there are many paradigms--",00:10:56.870,00:10:58.580
active learning.,00:10:58.580,00:10:59.320
"So active learning, it could be active
reinforcement or active supervised.",00:10:59.320,00:11:02.570
"Active learning means that, instead of
someone giving you the data set, you",00:11:02.570,00:11:06.840
"query about the value at
a particular point.",00:11:06.840,00:11:09.740
"So you give me the input and you ask
for the output if it's supervised.",00:11:09.740,00:11:12.890
"Or, you give me the input and expect
a reward or punishment if it's",00:11:12.890,00:11:15.960
reinforcement learning.,00:11:15.960,00:11:17.430
"So it's an adjustment, and there are
some interesting results there.",00:11:17.430,00:11:20.480
"And the other mini-paradigm
is online learning.",00:11:20.480,00:11:24.350
"And this is purely computational
consideration.",00:11:24.350,00:11:27.470
So take any form of learning.,00:11:27.470,00:11:29.800
"And instead of giving you the full data
set, and allowing you to work with",00:11:29.800,00:11:33.460
"it any way you want, I am streaming
the data set to you.",00:11:33.460,00:11:37.430
"So you take something and you try to
modify your current hypothesis,",00:11:37.430,00:11:41.750
"and then you take the other guy.
And you cannot store everything.",00:11:41.750,00:11:45.540
"If you could store everything,
you have the whole data set.",00:11:45.540,00:11:47.600
"So there are limitations on
storage and computation.",00:11:47.600,00:11:49.870
"And under those constraints, you ask
yourself, how can I learn and how",00:11:49.870,00:11:53.805
"close can I get to the optimal as
if I had the whole data set, and",00:11:53.805,00:11:56.480
whatnot.,00:11:56.480,00:11:57.240
"So, these are the most
famous paradigms.",00:11:57.240,00:11:59.910
There are other paradigms.,00:11:59.910,00:12:01.110
I'm not trying to be exhaustive here.,00:12:01.110,00:12:02.610
"Now, let's go for the theory.",00:12:02.610,00:12:05.010
"The main theory in machine learning
is the Vapnik-Chervonenkis theory.",00:12:05.010,00:12:08.780
"And it is the one that I covered
in great detail in this",00:12:08.780,00:12:12.220
"course, as you realize.",00:12:12.220,00:12:13.560
"And the reason is very
straightforward.",00:12:13.560,00:12:18.270
It's relevant.,00:12:18.270,00:12:19.670
You do the math.,00:12:19.670,00:12:20.500
"You go through the proofs, and then
you get the VC dimension.",00:12:20.500,00:12:22.970
"You equate it to the number of
parameters in some cases.",00:12:22.970,00:12:25.140
"And when you go to practice, even if
you are taking bounds and treating",00:12:25.140,00:12:28.770
"them as if they were equalities,
that leap of faith works",00:12:28.770,00:12:32.470
very well in practice.,00:12:32.470,00:12:33.880
"So it's not that the theory was
there, and we decided that",00:12:33.880,00:12:38.430
this is a good one.,00:12:38.430,00:12:39.390
"The theory was there, and then we tried
to take wisdom from the theory and",00:12:39.390,00:12:42.690
"apply it in practice, and it worked.",00:12:42.690,00:12:45.070
"This is the value added by choosing
a topic and putting it here.",00:12:45.070,00:12:48.210
"You know that there is
a reason why it's here.",00:12:48.210,00:12:50.190
"And the reason here is that it is
actually relevant to practice.",00:12:50.190,00:12:54.310
"Then, there is bias-variance.",00:12:54.310,00:12:55.820
"Well, bias-variance is
a sweet little theory.",00:12:55.820,00:12:57.620
"And it gave us some intuition
about this.",00:12:57.620,00:13:01.340
"And indeed, it was included.",00:13:01.340,00:13:03.020
"It was low cost to include it,
and it does lead to some",00:13:03.020,00:13:06.290
"understandings, like
the learning curves.",00:13:06.290,00:13:09.150
"There are theories that I didn't
describe, although they are very",00:13:09.150,00:13:12.470
substantial in the literature.,00:13:12.470,00:13:13.760
"One of them is based on
computational complexity.",00:13:13.760,00:13:16.090
"It basically treats machine learning
as a branch of computational",00:13:16.090,00:13:19.280
"complexity, with an emphasis
on asymptotic results.",00:13:19.280,00:13:21.980
"So it's the question of can I
do this in polynomial time or not?",00:13:21.980,00:13:25.590
"And it's a very respectable
body of work.",00:13:25.590,00:13:29.080
"And the only question for including it
or not including it is whether these",00:13:29.080,00:13:33.830
"particular results correspond to
something that I face in practice.",00:13:33.830,00:13:38.510
"So when I look at it, should I do the
computational complexity part of it,",00:13:38.510,00:13:43.140
"or should I do the generalization
part of it?",00:13:43.140,00:13:45.490
"The generalization part of it won hands
down, because it's the one that",00:13:45.490,00:13:48.940
"is the bottleneck when I practice
machine learning.",00:13:48.940,00:13:53.000
"And finally, there is the famous
Bayesian approach.",00:13:53.000,00:13:56.230
"Now, this treats machine learning
as a branch of probability.",00:13:56.230,00:13:59.870
So you have a problem.,00:13:59.870,00:14:01.310
"We can always put a probability
distribution.",00:14:01.310,00:14:02.940
"And by the time you put the full joint
probability distribution, you can",00:14:02.940,00:14:05.830
answer all questions.,00:14:05.830,00:14:07.670
"And it's a very sweet theory, because
you can ask any question you want",00:14:07.670,00:14:13.790
"and you will find a very concrete,
rigorous mathematical answer to that",00:14:13.790,00:14:17.470
"question, if you have the setup of
the joint probability distribution.",00:14:17.470,00:14:22.120
"Now, let's go for the techniques.",00:14:25.020,00:14:26.280
"There are other theories, again.",00:14:26.280,00:14:27.590
I just gave you the biggest players.,00:14:27.590,00:14:32.100
"When you look at techniques, you
should separate models, as in",00:14:32.100,00:14:35.280
"hypothesis sets and algorithms
that go with them.",00:14:35.280,00:14:37.850
That's one category.,00:14:37.850,00:14:39.550
"And then, the high-level methods, like
regularization for example, that",00:14:39.550,00:14:43.350
"doesn't restrict itself to a particular
model, but is super-imposed",00:14:43.350,00:14:47.730
on anything you use.,00:14:47.730,00:14:48.960
"So I will look at members
of those categories.",00:14:48.960,00:14:52.540
So we looked at the models.,00:14:52.540,00:14:55.020
Linear we emphasized a lot.,00:14:55.020,00:14:56.250
"It is not usually emphasized in regular
machine learning courses.",00:14:56.250,00:15:00.080
They usually go for other models.,00:15:00.080,00:15:02.150
"It's emphasized very much in
statistics, for example.",00:15:02.150,00:15:04.660
"And I find it to be very
underrepresented in machine learning.",00:15:04.660,00:15:08.990
It's a very important model.,00:15:08.990,00:15:10.220
"With a nonlinear transform, you
can cover a lot of territory.",00:15:10.220,00:15:13.090
"And it's very low cost, and it should
be tried in many learning problems.",00:15:13.090,00:15:18.310
Then we went on to neural networks.,00:15:18.310,00:15:20.150
You have seen that.,00:15:20.150,00:15:22.170
"Support vector machines, and
the kernel methods.",00:15:22.170,00:15:25.150
We covered quite a bit of territory.,00:15:25.150,00:15:26.870
"Nearest neighbors, I alluded to very
quickly when I talked about RBF.",00:15:26.870,00:15:30.110
It's a very standard method.,00:15:30.110,00:15:32.273
"Not much to say about it, except
that it's a good benchmark.",00:15:32.273,00:15:37.300
"If you have a data set, why don't you
categorize everything according to the",00:15:37.300,00:15:40.470
nearest neighbor?,00:15:40.470,00:15:41.260
"And this will give you a performance,
and then you can compare",00:15:41.260,00:15:43.350
other methods to that.,00:15:43.350,00:15:44.740
It's not that difficult to implement.,00:15:44.740,00:15:48.070
"We looked at RBF and its relation to
many things in machine learning.",00:15:48.070,00:15:53.230
"And then there is Gaussian processes,
which some people are completely fond",00:15:53.230,00:15:56.622
"of, which is great.",00:15:56.622,00:15:58.500
"And it really has the same
spirit of Bayesian.",00:15:58.500,00:16:01.040
It's a full probability distribution.,00:16:01.040,00:16:02.750
"So a process here means
a random process.",00:16:02.750,00:16:05.840
"A random process is nothing
but a random function.",00:16:05.840,00:16:07.580
"If a random variable is
a random number, a random",00:16:07.580,00:16:09.620
process is a random function.,00:16:09.620,00:16:11.030
"So we have probability distribution over
different functions that can come out.",00:16:11.030,00:16:15.480
"And the assumption here is that they are
Gaussian, which means that if you",00:16:15.480,00:16:18.120
"take any finite number of points, the
probability distribution of the",00:16:18.120,00:16:22.190
"y-coordinate is jointly Gaussian
for those guys.",00:16:22.190,00:16:25.380
"So if you have a full description of
that probability distribution, you can",00:16:25.380,00:16:30.840
solve anything you want.,00:16:30.840,00:16:32.250
"Because you can say, if I have this data
point, then I am conditioning on",00:16:32.250,00:16:35.880
"that Gaussian variable
being equal to that.",00:16:35.880,00:16:38.240
"And I'm asking myself, what is now
the conditional distribution",00:16:38.240,00:16:40.830
of the other guys?,00:16:40.830,00:16:41.570
"And for Gaussian, this is completely
solved and you have nice matrices to",00:16:41.570,00:16:44.790
"just multiply out and
get that solution.",00:16:44.790,00:16:47.120
So it's very good to use.,00:16:47.120,00:16:49.240
"And if you are modeling something that
happens to be a Gaussian process, then",00:16:49.240,00:16:54.040
"obviously you win greatly because
you are actually matching that.",00:16:54.040,00:16:58.170
"There is SVD, which is the singular
value decomposition, used figuratively",00:17:01.200,00:17:05.359
in this case.,00:17:05.359,00:17:05.880
"This is the factor analysis we used
in the Netflix problem, where we",00:17:05.880,00:17:09.490
"represented the user as a bunch of
factors, and the movie as a bunch of",00:17:09.490,00:17:12.960
"factors, and we tried to match.",00:17:12.960,00:17:14.440
"When you put this, you find that
it's as if you are decomposing the",00:17:14.440,00:17:18.450
"ratings matrix, the entire ratings
matrix into two matrices.",00:17:18.450,00:17:22.170
"And this would be similar to singular
value decomposition in mathematics.",00:17:22.170,00:17:24.980
So we have seen part of that.,00:17:24.980,00:17:28.109
"Finally, there is graphical models.",00:17:28.109,00:17:29.600
"And graphical models is almost
a different paradigm in its own right.",00:17:29.600,00:17:35.000
What are graphical models?,00:17:35.000,00:17:36.240
"They are a model where the target
is a joint probability distribution.",00:17:36.240,00:17:43.260
That's what you're trying to learn.,00:17:43.260,00:17:45.500
"And the key here is that the joint
probability distribution between",00:17:45.500,00:17:48.640
"a very large number of variables
becomes very difficult to manage",00:17:48.640,00:17:51.920
"computationally, because the number of
possibilities would be exponential in",00:17:51.920,00:17:55.690
the number of variables.,00:17:55.690,00:17:57.150
"So the bulk of work in graphical models
is trying to find a simple way,",00:17:57.150,00:18:01.920
"or an efficient way, in order to get
answers about that joint probability",00:18:01.920,00:18:05.000
"distribution, and to learn it.",00:18:05.000,00:18:07.020
So it is mostly computational.,00:18:07.020,00:18:09.170
And it's based on graph algorithms.,00:18:09.170,00:18:11.570
"And the main aspect of putting it in
a graph is to use the properties, that",00:18:11.570,00:18:17.420
"happen to be conditional independence,
as a way to simplify the graph.",00:18:17.420,00:18:22.330
"So if you look at the things I showed so
far, probably there would be a full",00:18:22.330,00:18:27.630
"course in graphical models, which
is completely justified.",00:18:27.630,00:18:30.280
"If you are in the business of modeling
joint probability distributions, and",00:18:30.280,00:18:34.270
"computation is a consideration,
this is the thing to learn.",00:18:34.270,00:18:37.810
There is no question about that.,00:18:37.810,00:18:39.210
"It's specialized, but it's very
helpful in that case.",00:18:39.210,00:18:43.660
"And the other one I mentioned was
reinforcement learning, usually taught",00:18:43.660,00:18:46.630
"together with active learning because
there are a lot of commonalities.",00:18:46.630,00:18:51.160
"Now, we go for the methods.",00:18:51.160,00:18:52.440
"And the methods are very important,
because they cover a lot of territory",00:18:52.440,00:18:55.090
regardless of the model you have.,00:18:55.090,00:18:56.150
We used regularization.,00:18:56.150,00:18:57.460
"Can you think of other methods,
at the same level, that we used?",00:18:57.460,00:19:01.790
Regularization and?,00:19:01.790,00:19:04.380
"We used validation, right?",00:19:04.380,00:19:05.830
These were all methods overall.,00:19:05.830,00:19:09.170
There are things we didn't cover.,00:19:09.170,00:19:10.520
"And one of them is aggregation, putting
together different solutions.",00:19:10.520,00:19:15.980
"And the last one we didn't cover
was input processing.",00:19:15.980,00:19:19.440
"This is something you do regardless
of the model you are going to use.",00:19:19.440,00:19:22.170
"And I find that input processing is best
taught within a projects course.",00:19:22.170,00:19:27.820
It's a very practical matter.,00:19:27.820,00:19:29.660
"And when you teach a projects course
and people will have to deal",00:19:29.660,00:19:32.260
"with the real data, it's a good thing
to start by telling them, here is",00:19:32.260,00:19:35.130
"the principal component analysis in
order to normalize and de-correlate the",00:19:35.130,00:19:39.050
"inputs, and whatnot.",00:19:39.050,00:19:39.940
And this is the value.,00:19:39.940,00:19:40.970
And then they can try it.,00:19:40.970,00:19:41.850
"There is little intellectual
value to input processing.",00:19:41.850,00:19:45.540
It's a practical matter.,00:19:45.540,00:19:46.470
"And therefore, it is best taught when
you are teaching a practical course.",00:19:46.470,00:19:50.410
"Now, from all of this, I am going
to talk about two topics today.",00:19:50.410,00:19:57.580
"One of them is Bayesian, and
the other one is aggregation.",00:19:57.580,00:20:02.810
"I'm not going to talk
about them in-depth.",00:20:02.810,00:20:04.410
"I'm actually going to try to make
a point, particularly about Bayesian.",00:20:04.410,00:20:08.350
"And you say, you just told
us about the razor.",00:20:08.350,00:20:13.110
"And you trimmed it, and you
got the solution right.",00:20:13.110,00:20:15.400
"Why are you now adding up stuff
to the minimal possible?",00:20:15.400,00:20:19.230
There is a good reason.,00:20:19.230,00:20:22.140
"The Bayesian is the elephant
in the room.",00:20:22.140,00:20:25.290
"If I don't talk about it, you will
hear about it a lot and you will",00:20:25.290,00:20:28.530
"wonder, why in the world
didn't I talk about it?",00:20:28.530,00:20:30.840
"Looks great when you look
at the results.",00:20:30.840,00:20:33.480
So I need to put it in perspective.,00:20:33.480,00:20:35.650
"And that's what I'm going
to try to do.",00:20:35.650,00:20:36.800
"I'm not going to cover the
scope of Bayesian.",00:20:36.800,00:20:40.640
"I'm going to cover the foundations of
the Bayesian approach, and make a point",00:20:40.640,00:20:44.440
about when is it valid?,00:20:44.440,00:20:46.870
When can you use it?,00:20:46.870,00:20:47.570
What are the drawbacks?,00:20:47.570,00:20:50.520
The other one is aggregation.,00:20:50.520,00:20:51.810
"I would say that aggregation was the
runner-up topic in this course.",00:20:51.810,00:20:55.300
I would have normally included it.,00:20:55.300,00:20:57.920
"If I had more time and I had
a natural position for it.",00:20:57.920,00:21:00.630
"Because it's a fairly simple technique
and covers a lot of territory, and has",00:21:00.630,00:21:03.880
been successful.,00:21:03.880,00:21:04.950
"So I'm going to try to cover it in some
level of detail that will make",00:21:04.950,00:21:10.180
"you at least able to read it, and
understand what you are reading and",00:21:10.180,00:21:12.870
where it lies.,00:21:12.870,00:21:14.310
So this is the plan.,00:21:14.310,00:21:16.080
"With that, let's go to the two topics.",00:21:16.080,00:21:18.860
"Bayesian learning first, and then I'm
going to talk about aggregation methods.",00:21:18.860,00:21:22.670
"Bayesian learning is
trying to get a full",00:21:25.650,00:21:28.020
probabilistic approach to learning.,00:21:28.020,00:21:30.500
"The first thing to do is to remind
you of the learning diagram.",00:21:30.500,00:21:35.340
Let me magnify it a little bit.,00:21:35.340,00:21:38.320
"We are not going to go through
the details of it.",00:21:38.320,00:21:41.010
"We are just going to concentrate
on the probabilistic aspect.",00:21:41.010,00:21:44.160
There are many probabilistic components.,00:21:44.160,00:21:46.930
"One of them is inherent, which is the
fact that the target could be noisy.",00:21:46.930,00:21:51.710
"And therefore, we model the target not
as a function but as a probability",00:21:51.710,00:21:55.540
distribution.,00:21:55.540,00:21:56.940
"Think of the case, for example,
we dealt with as trying to",00:21:56.940,00:21:59.900
predict heart attacks.,00:21:59.900,00:22:02.430
"Getting a heart attack or not
getting a heart attack is",00:22:02.430,00:22:04.360
a probabilistic aspect.,00:22:04.360,00:22:05.970
"And if we have our target as the
probability of getting a heart attack",00:22:05.970,00:22:09.810
"given certain conditions within
a certain amount of time, then the",00:22:09.810,00:22:13.900
"examples I'm going to give you don't
give you that value of the target",00:22:13.900,00:22:16.580
"function, but give you realizations
from that probability distribution",00:22:16.580,00:22:19.550
that are noisy.,00:22:19.550,00:22:20.680
"And therefore, I give you that
probability distribution",00:22:20.680,00:22:22.740
P of y given x.,00:22:22.740,00:22:24.070
"So that one is built-in, in terms
of the functions or the noisy",00:22:24.070,00:22:28.970
functions we are trying to learn.,00:22:28.970,00:22:31.590
"The other probability distribution
we had was the input probability",00:22:31.590,00:22:34.730
"distribution, and that was admittedly
an artificial addition to the problem,",00:22:34.730,00:22:39.640
"in order to be able to
get the theory going.",00:22:39.640,00:22:42.800
"And in spite of the fact that it is
an assumption, it's a very benign",00:22:42.800,00:22:45.990
"assumption for the very simple reason
of the word 'unknown'. I wanted",00:22:45.990,00:22:51.240
"a probability distribution just to get
the machinery of probability going.",00:22:51.240,00:22:55.050
"And I'm making no assumptions about
the probability distribution.",00:22:55.050,00:22:58.300
You can pick any one you want.,00:22:58.300,00:22:59.590
And I don't even want to know it.,00:22:59.590,00:23:02.040
"So this is very light
as assumptions go.",00:23:02.040,00:23:05.300
"Now, when it comes to the Bayesian
approach, what you want to do is you",00:23:05.300,00:23:10.200
"want to extend the probabilistic
role completely.",00:23:10.200,00:23:14.110
"So that everything is just a big joint
probability distribution of all the",00:23:14.110,00:23:17.560
notions involved.,00:23:17.560,00:23:18.890
"And if you get that going, then you
will obviously be able to derive",00:23:18.890,00:23:21.830
"anything, in terms of that joint
probability distribution.",00:23:21.830,00:23:26.350
"So when you do this, let's
think of something.",00:23:26.350,00:23:30.050
"In the prediction of the heart attack
case, remember that we did use",00:23:30.050,00:23:35.320
"probability in order to derive the
algorithm for picking a hypothesis.",00:23:35.320,00:23:39.920
What did we do?,00:23:39.920,00:23:41.540
We said you have a data set.,00:23:41.540,00:23:42.680
What is the data set?,00:23:42.680,00:23:43.340
"A bunch of patients with their
attributes, and whether or not they got",00:23:43.340,00:23:46.710
"a heart attack within a year of
getting these measurements.",00:23:46.710,00:23:49.180
That was the data set.,00:23:49.180,00:23:51.230
"And you were trying to say that I am
going to pick the hypothesis that, if",00:23:51.230,00:23:58.330
"this hypothesis truly reflected the
probability of getting a heart attack",00:23:58.330,00:24:03.650
"within that time frame, then the
probability of getting that data set,",00:24:03.650,00:24:08.360
"which actually took place,
would be higher.",00:24:08.360,00:24:11.260
That was our approach.,00:24:11.260,00:24:12.350
And we called this the likelihood.,00:24:12.350,00:24:16.710
Remember?,00:24:16.710,00:24:17.630
"So it's not we are picking the
highest-probability hypothesis.",00:24:17.630,00:24:21.920
"We don't have the luxury to do that, for
a reason that will become clear.",00:24:21.920,00:24:25.070
"We are picking the hypothesis that
will make the data that actually",00:24:25.070,00:24:29.640
"happened highest possible
probability--",00:24:29.640,00:24:32.230
maximum likelihood.,00:24:32.230,00:24:33.630
"So we already used the probabilistic
approach here.",00:24:33.630,00:24:37.080
"Now the only difference, when you go to
the Bayesian approach, is that you",00:24:37.080,00:24:39.920
actually go for the real quantity.,00:24:39.920,00:24:42.710
"The data already happened, why are
you maximizing the probability?",00:24:42.710,00:24:45.010
"Well, maximize the probability-- if
what happened is likely given",00:24:45.010,00:24:47.900
"a scenario, then
that scenario is likely.",00:24:47.900,00:24:49.570
That's why you call it likelihood.,00:24:49.570,00:24:51.600
"But a more principled approach would be
to actually try to use the probability",00:24:51.600,00:24:56.800
"that this is the correct hypothesis
given the data.",00:24:56.800,00:24:59.730
That is the bottom line.,00:24:59.730,00:25:00.760
I give you the data.,00:25:00.760,00:25:01.720
This is given.,00:25:01.720,00:25:03.390
And you have a bunch of hypotheses.,00:25:03.390,00:25:04.620
"You ask yourself, is it this hypothesis,
or this hypothesis, or",00:25:04.620,00:25:07.320
"this hypothesis that reflects
the target function.",00:25:07.320,00:25:10.090
"Well, you look for which one
is the most probable to be,",00:25:10.090,00:25:12.690
and you declare that.,00:25:12.690,00:25:14.400
"And that would be the
Bayesian approach.",00:25:14.400,00:25:16.580
"If you go to statistics, there is always
a school that loves Bayesian and",00:25:16.580,00:25:21.810
there is a school that hates Bayesian.,00:25:21.810,00:25:23.290
"And there is sort of an ongoing
struggle between them.",00:25:23.290,00:25:26.330
"And it's funny, because you think this is
mathematics, people shouldn't have",00:25:26.330,00:25:29.660
just-- tastes like that.,00:25:29.660,00:25:31.800
"But the problem is that Bayesian
depends on something that I will",00:25:31.800,00:25:34.120
"describe here, and the controversy
all comes from that assumption.",00:25:34.120,00:25:37.930
"But it came to the level in statistics
where they describe a person, as, oh,",00:25:37.930,00:25:41.860
"this is a Bayesian person versus
no, I'm not a Bayesian.",00:25:41.860,00:25:46.110
"It's almost like it was
a religion or something.",00:25:46.110,00:25:48.520
But that's the reality of the field.,00:25:48.520,00:25:50.580
"And you will understand why it evolved
into that, when I describe the",00:25:50.580,00:25:54.440
components.,00:25:54.440,00:25:55.690
"The main component that raises
the controversy is the prior.",00:25:57.820,00:26:01.050
So let's look at what that is.,00:26:01.050,00:26:04.710
"We want the probability of a hypothesis
being the correct target",00:26:04.710,00:26:09.980
"function, given the data.",00:26:09.980,00:26:12.760
"And if you want to compute that, and
even if you have the model for the",00:26:12.760,00:26:18.660
"noise and the model for the input
probability distribution--",00:26:18.660,00:26:20.680
"all of the stuff that we had
in the learning diagram is",00:26:20.680,00:26:23.220
already taken for granted.,00:26:23.220,00:26:24.770
"You still need one more
probability distribution in",00:26:24.770,00:26:27.940
order to complete this.,00:26:27.940,00:26:29.820
"And the way to discover it is
just-- let's write it down.",00:26:29.820,00:26:33.150
This probability.,00:26:33.150,00:26:33.960
"And you apply Bayes' rule, hence the
word 'Bayesian', in order to get this",00:26:33.960,00:26:37.550
from the quantities we know.,00:26:37.550,00:26:40.060
So we know this one.,00:26:40.060,00:26:42.240
"We know the probability of the data
given that-- if this hypothesis.",00:26:42.240,00:26:45.300
"was faithful description of how people
got heart attack, then the probability",00:26:45.300,00:26:49.400
of getting that data is--,00:26:49.400,00:26:50.870
"you just compute how much noise in
each point, according to this",00:26:50.870,00:26:53.680
being f.,00:26:53.680,00:26:54.130
"And you get it, which we got in logistic
regression, and resulted in",00:26:54.130,00:26:57.780
the error measure over there.,00:26:57.780,00:26:59.190
So that was given.,00:26:59.190,00:27:01.490
"The part that we need that
is not given is this one.",00:27:01.490,00:27:06.280
"When you multiply them, you get the
joint probability distribution.",00:27:06.280,00:27:09.060
"And when you divide by the probability
of D, you get the conditional-- the",00:27:09.060,00:27:13.090
other direction which you want.,00:27:13.090,00:27:15.850
"Now, there is no sweat in
getting this.",00:27:15.850,00:27:18.230
"Because if I have the joint probability
distribution, I just",00:27:18.230,00:27:20.380
"integrate out whatever I don't want,
and I end up with the marginal.",00:27:20.380,00:27:23.110
So there is no difficulty in this.,00:27:23.110,00:27:24.900
"And in fact, if your job is to just
pick h according to this criterion,",00:27:24.900,00:27:31.000
"then this fellow doesn't matter because
it doesn't depend on h.",00:27:31.000,00:27:33.880
It scales all of them up or down.,00:27:33.880,00:27:35.900
"So if you are picking between two
hypotheses according to this",00:27:35.900,00:27:38.150
"probability, you might as well forget
about this and take the numerator as",00:27:38.150,00:27:41.610
"your indicator, and pick the one that
gives you the bigger numerator.",00:27:41.610,00:27:44.990
"So you think of this as
proportional to this.",00:27:44.990,00:27:47.110
And this is what I'm going to use.,00:27:47.110,00:27:50.110
"Now, this is the mystery quantity, so
let's put it down and describe it.",00:27:50.110,00:27:54.110
What does that mean?,00:27:54.110,00:27:56.720
It's not conditioned on anything.,00:27:56.720,00:27:58.230
"I'm asking you, here's
the hypothesis set.",00:27:58.230,00:28:00.220
It's a perceptron.,00:28:00.220,00:28:00.870
It has a bunch of weights.,00:28:00.870,00:28:02.920
"Could you please tell me, what is the
probability that this particular",00:28:02.920,00:28:06.280
"combination of weights will actually
give you the target function?",00:28:06.280,00:28:09.700
"How in the world are you
going to know that?",00:28:12.820,00:28:15.990
"So what you are doing here is assuming
that there is a probability",00:28:15.990,00:28:19.540
distribution for that.,00:28:19.540,00:28:21.140
"You're going to put a probability
distribution over the hypothesis set,",00:28:21.140,00:28:23.800
"the last component in the diagram that
didn't really have a probability.",00:28:23.800,00:28:27.100
"The probability reflecting the statement
that this hypothesis is,",00:28:27.100,00:28:31.070
"indeed, the target function.",00:28:31.070,00:28:32.860
"And any discrepancy between the data
set and the hypothesis, which is",00:28:32.860,00:28:37.290
"supposed to be the target function,
is attributed to the fact",00:28:37.290,00:28:39.840
that the data is noisy.,00:28:39.840,00:28:41.230
"The data does not reflect
the target function.",00:28:41.230,00:28:43.020
The data deviates by added noise.,00:28:43.020,00:28:46.010
So this one is called the prior.,00:28:46.010,00:28:49.460
"Prior because it is your belief
about the hypothesis set",00:28:49.460,00:28:53.800
before you got any data.,00:28:53.800,00:28:54.980
Before.,00:28:54.980,00:28:56.690
"After you got the data, you can modify
this and you get the probability of h",00:28:56.690,00:29:02.590
given the data.,00:29:02.590,00:29:04.230
That's now more informed.,00:29:04.230,00:29:05.800
"You get the specific data from the
target function, and then you are",00:29:05.800,00:29:08.990
"going to zoom in and make a better
choice among the hypotheses that you",00:29:08.990,00:29:12.630
"have for which one qualifies
as the target.",00:29:12.630,00:29:15.770
And this one is called the posterior.,00:29:15.770,00:29:18.600
It happens after the fact.,00:29:18.600,00:29:19.950
"Now, if you are given the
prior-- let's say that I",00:29:22.510,00:29:25.650
actually give you a problem.,00:29:25.650,00:29:27.650
"I don't know the target function, but
I know quite a bit about it in terms",00:29:27.650,00:29:31.970
of probabilities.,00:29:31.970,00:29:33.250
"And here is the way I'm going
to formalize that.",00:29:33.250,00:29:35.520
"I am going to give you a full
probability distribution over the",00:29:35.520,00:29:38.310
"entire hypothesis set that tells you the
relative probability of different",00:29:38.310,00:29:42.520
"hypotheses being the correct
target function.",00:29:42.520,00:29:44.530
That's my prior.,00:29:44.530,00:29:46.390
"If you have that, you have the joint
probability distribution.",00:29:46.390,00:29:50.280
"And if you have the joint probability
distribution, you",00:29:50.280,00:29:52.050
can answer any question.,00:29:52.050,00:29:54.210
"So that's a very attractive
route to follow.",00:29:54.210,00:29:56.355
You can get anything.,00:29:59.460,00:30:02.220
"And because of that, it's important
to look at the prior.",00:30:02.220,00:30:05.240
"That is the center of the idea
of a Bayesian approach.",00:30:05.240,00:30:10.170
"So the main point I'm making, the only
point I'm making in fact, in this",00:30:10.170,00:30:14.490
"particular section, is the fact
that prior is an assumption.",00:30:14.490,00:30:18.300
"So before I get to that, let
me give you an example of",00:30:18.300,00:30:20.840
a prior to make it concrete--,00:30:20.840,00:30:22.310
the one I referred to.,00:30:22.310,00:30:23.760
"So let's say that you are
having a perceptron.",00:30:23.760,00:30:26.030
So your perceptron model.,00:30:26.030,00:30:26.920
What is a perceptron model?,00:30:26.920,00:30:28.360
"It's hyperplanes in some
space, d-dimensional.",00:30:28.360,00:30:31.000
"So I have weights w_0 up to w_d that
tell me the slope and the offset.",00:30:31.000,00:30:36.390
"And this will tell me what
is the separating plane.",00:30:36.390,00:30:38.240
"And I'm going to use this as a hypothesis
in order to separate some",00:30:38.240,00:30:40.720
data points generated from a target.,00:30:40.720,00:30:43.270
"And I'm going to assume that
the target is there--",00:30:43.270,00:30:45.870
"let's say, even you can take a linear
target if you want, and added noise.",00:30:45.870,00:30:49.690
"After you generate the points from that
target, you flip the labels of",00:30:49.690,00:30:53.920
"some of the guys according
to some noise.",00:30:53.920,00:30:55.990
"So 10% of the points are flipped, so
this is your contribution of the",00:30:55.990,00:30:59.170
"noise. Just to have something concrete
in your mind to imagine.",00:30:59.170,00:31:03.190
So you have a perceptron.,00:31:03.190,00:31:04.610
h is specified by the weights.,00:31:04.610,00:31:06.730
"Perceptron is-- you call it h
because it's a full function.",00:31:06.730,00:31:09.350
"But in reality, you just tell me what
the parameters are and I know what is",00:31:09.350,00:31:12.150
"the function, because I know what
is the separating plane.",00:31:12.150,00:31:16.140
"So here is a prior-- I suggest
a possible prior.",00:31:16.140,00:31:18.350
"The prior, now, I'm going to give
it in terms of the weights.",00:31:18.350,00:31:21.660
"So I'm going to tell you which weights
are more likely than others.",00:31:21.660,00:31:24.800
"And what I'm going to try to do, I'm
going to try to make the assumption as",00:31:24.800,00:31:28.340
benign as possible.,00:31:28.340,00:31:30.390
Because I really don't know.,00:31:30.390,00:31:31.310
"When I say which weights are
more likely than others, I'm not",00:31:31.310,00:31:34.500
"saying which weights are more
likely to come out.",00:31:34.500,00:31:36.600
"I'm asking, which weights are likely
to actually reflect what the target",00:31:36.600,00:31:39.680
"function is, the target function
that we said was unknown.",00:31:39.680,00:31:42.270
So I'm making some assumptions.,00:31:42.270,00:31:44.030
"I'm trying to reduce the level of
crimes that I'm doing, and trying to",00:31:44.030,00:31:48.010
"give you something that is fairly
vague so I am not making a big",00:31:48.010,00:31:52.060
commitment.,00:31:52.060,00:31:53.480
"Knowing that for the perceptrons,
the magnitude of the",00:31:53.480,00:31:57.070
weights doesn't matter--,00:31:57.070,00:31:58.120
"if you scale all the w's by any
positive number up or down, you get",00:31:58.120,00:32:01.560
the same surface.,00:32:01.560,00:32:02.630
"Because it is just classifying +1
or -1. You care about the signal",00:32:02.630,00:32:06.180
being positive or negative.,00:32:06.180,00:32:07.980
"So I'm going to take w's in a limited
range, and I'm going to take them to be",00:32:07.980,00:32:13.060
"uniform, independently.",00:32:13.060,00:32:14.750
"So each weight is between -1
and +1 independently",00:32:14.750,00:32:17.940
from the other weight.,00:32:17.940,00:32:19.180
That is my prior.,00:32:19.180,00:32:20.450
"And my hope in putting that prior is
that I didn't make a big assumption.",00:32:20.450,00:32:24.620
'hope' is the operative word here.,00:32:24.620,00:32:28.020
So what does that mean?,00:32:28.020,00:32:29.770
"It means that, if I get the
probability distribution over all the",00:32:29.770,00:32:32.300
"weights, then I can see which weights
contribute to a particular hypothesis.",00:32:32.300,00:32:35.930
"And then I have the prior over
h, which is the one I want.",00:32:35.930,00:32:41.490
"So I have the probability
of h, given nothing.",00:32:41.490,00:32:45.280
"And when I am given the data, I mix
now my prior belief about which",00:32:45.280,00:32:50.910
"hypothesis is the target function
according to this, which seems to be",00:32:50.910,00:32:53.870
completely uniform.,00:32:53.870,00:32:55.420
"And then take the data, and the data
will tell me that some guys are more",00:32:55.420,00:32:59.910
possible than others.,00:32:59.910,00:33:00.700
"If I pick something that will require my
interpretation of the noise to say",00:33:00.700,00:33:05.320
"that 90% of the points had to flip in
order for this to be the correct",00:33:05.320,00:33:08.730
"target, then this is very unlikely
because the flipped was only 10%.",00:33:08.730,00:33:12.820
"And therefore, this will get demoted
among hypotheses according to the",00:33:12.820,00:33:16.520
evidence coming from the data.,00:33:16.520,00:33:19.500
"And you compute the probability of the
data given h, and then you multiply",00:33:19.500,00:33:23.670
"them and you get what you want,
which is the posterior.",00:33:23.670,00:33:28.190
"And the posterior is the product--
at least proportional to the",00:33:28.190,00:33:30.270
product of the two.,00:33:30.270,00:33:31.350
"So this is a concrete example
if you want to apply this.",00:33:31.350,00:33:35.400
"Now, we make the main statement
about the prior.",00:33:35.400,00:33:38.460
"And the main statement is that the
prior is, indeed, an assumption.",00:33:38.460,00:33:42.760
Let's look at it.,00:33:42.760,00:33:44.640
Let me take a very simple case.,00:33:44.640,00:33:47.325
"It doesn't have to do with learning
in particular, to make the point.",00:33:47.325,00:33:51.570
"Let's say that I take the most neutral
prior to describe something unknown.",00:33:51.570,00:33:56.830
"You have something that is unknown,
like a target function.",00:33:56.830,00:33:59.550
"In this case, it will be a number.",00:33:59.550,00:34:01.240
So I have an unknown number.,00:34:01.240,00:34:02.650
"And all I know about it is that it's
between -1 and +1.",00:34:02.650,00:34:07.740
"And someone decides that it will be
convenient to have a probability",00:34:07.740,00:34:10.630
"distribution over x, notwithstanding
the fact that x is not really",00:34:10.630,00:34:14.300
probabilistic.,00:34:14.300,00:34:14.770
"I'm not running any experiment and
generating x's repeatedly.",00:34:14.770,00:34:17.699
"x is just a number sitting out
there that I don't know.",00:34:17.699,00:34:20.590
"I don't know, not in a probabilistic
sense that it's a random variable.",00:34:20.590,00:34:25.040
"I don't know-- it's
an unknown parameter.",00:34:25.040,00:34:27.520
"So you ask yourself, would this
be equivalent to x being",00:34:27.520,00:34:31.550
random in some setting?,00:34:31.550,00:34:32.770
Can you model this with probability?,00:34:32.770,00:34:34.810
"And invariably, people will tell
you, you look at this.",00:34:34.810,00:34:37.800
I don't know what x is.,00:34:37.800,00:34:39.300
"So let me model this using a uniform
probability distribution",00:34:39.300,00:34:43.620
from -1 to +1.,00:34:43.620,00:34:45.760
"On face value, this looks completely
innocent and credible.",00:34:45.760,00:34:50.469
"Because here you didn't
make any commitment.",00:34:50.469,00:34:52.310
"It is as likely to be this,
as this, as this, as this.",00:34:52.310,00:34:55.730
"This one is unknown, so it seems that
you captured what the meaning is.",00:34:55.730,00:35:01.930
I would like to argue that it doesn't.,00:35:01.930,00:35:03.812
It actually makes a huge assumption.,00:35:03.812,00:35:07.300
"Now, you are not saying
that you don't know x.",00:35:07.300,00:35:13.450
"You're saying that, I know that
x came from this distribution.",00:35:13.450,00:35:17.660
"So if you know that, here are a bunch of
stuff that I know, that actually I",00:35:17.660,00:35:22.350
didn't know here.,00:35:22.350,00:35:24.510
"If you generate a bunch of x's and take
their average, the chances are",00:35:24.510,00:35:27.895
you will be around 0.,00:35:27.895,00:35:30.850
"If you look at a bunch of x's here and
you average, I have no clue what",00:35:30.850,00:35:34.310
you're going to get.,00:35:34.310,00:35:36.990
"If you do this, I can tell you even
not only that the average will be",00:35:36.990,00:35:41.170
close to 0.,00:35:41.170,00:35:41.660
"I can tell you how close it
is, in terms of variance.",00:35:41.660,00:35:44.980
"Here, I could be all over the place.",00:35:44.980,00:35:48.040
"So you realize that, innocent as this
may be, this is a different problem",00:35:48.040,00:35:53.380
than this one.,00:35:53.380,00:35:55.500
"And if you insist on modeling x as
a probability, and you want to capture",00:35:55.500,00:36:02.250
"the statement here exactly, without
adding any assumptions, you can",00:36:02.250,00:36:06.620
definitely do that.,00:36:06.620,00:36:07.920
"Although, it looks much less
attractive than this one.",00:36:07.920,00:36:12.200
This is not equivalent.,00:36:12.200,00:36:13.300
"And if you want the true equivalent in
terms of probability of this fellow,",00:36:13.300,00:36:18.690
this is what you're going to have.,00:36:18.690,00:36:22.080
"So here, x is unknown.",00:36:22.080,00:36:24.260
"Here, x is random, and
the probability",00:36:24.260,00:36:27.750
"density function of that happens to be
a delta function centered around",00:36:27.750,00:36:31.790
a point 'a' that I don't know.,00:36:31.790,00:36:35.940
That would be strictly modeling this.,00:36:35.940,00:36:38.943
This does not model it.,00:36:38.943,00:36:42.210
"And the fact that people take the
liberty of doing that, results in many",00:36:42.210,00:36:46.440
"cases in really a huge building
based on a false premise.",00:36:46.440,00:36:52.550
"In some cases, you get away with it.",00:36:52.550,00:36:54.150
"But in some cases, you don't.",00:36:54.150,00:36:56.320
"So this is the key point, that when
you put a prior, you are actually",00:36:56.320,00:37:00.360
making a huge assumption.,00:37:00.360,00:37:01.500
Think of it this way.,00:37:01.500,00:37:02.750
"We took great pains to say, the
target function is unknown.",00:37:02.750,00:37:05.600
It could be anything.,00:37:05.600,00:37:06.480
"I'm not going to make assumptions about
it. Because in reality, when you",00:37:06.480,00:37:09.035
"are in machine learning, if someone
knocks on my door and they say they",00:37:09.035,00:37:12.430
"want to learn a function, I really
don't know what the function is.",00:37:12.430,00:37:15.340
"So you go to your hypothesis set, which
you picked out of your hat.",00:37:15.340,00:37:18.870
"I'm going to use neural networks,
or I'm going to use linear--",00:37:18.870,00:37:21.410
whatever it is.,00:37:21.410,00:37:23.070
"And then you say, now, here is the
probability that for each of these",00:37:23.070,00:37:27.380
"points, I'm going to specify very
specifically the probability that this",00:37:27.380,00:37:31.470
is exactly the target function.,00:37:31.470,00:37:34.830
"And people do that with great
ease, and then build on it.",00:37:34.830,00:37:39.830
"All I'm asking for you to realize--
I'm not saying don't do that.",00:37:39.830,00:37:42.750
"I'm just making the statement: realize
that you are making an assumption.",00:37:42.750,00:37:46.610
And it's a big assumption.,00:37:46.610,00:37:49.420
"So let's see the ramifications
of that.",00:37:49.420,00:37:52.210
"If you actually knew the prior, you
would be in fantastic shape.",00:37:52.210,00:37:56.240
Why is that?,00:37:56.240,00:37:57.750
"Because you can compute the posterior
for every point in",00:37:57.750,00:38:04.250
your hypothesis set.,00:38:04.250,00:38:05.090
"For every hypothesis, I know now what is
the probability of it given D. Mind",00:38:05.090,00:38:09.820
"you, this is h equals f over
the entire space.",00:38:09.820,00:38:15.580
"That is, this is really out-of-sample.",00:38:15.580,00:38:17.830
"I am taking D which is in-sample, and
I'm making a statement about the",00:38:17.830,00:38:21.180
"probability for every hypothesis
to be, out-of-sample.",00:38:21.180,00:38:24.390
"I don't worry about regularization
and VC bounds.",00:38:24.390,00:38:28.420
This is it.,00:38:28.420,00:38:30.030
You know the prior.,00:38:30.030,00:38:31.490
You give the data set.,00:38:31.490,00:38:32.660
You have a model for it.,00:38:32.660,00:38:33.710
You can compute this explicitly.,00:38:33.710,00:38:35.840
"And based on this probability
distribution, you can",00:38:35.840,00:38:37.770
get a bunch of stuff.,00:38:37.770,00:38:38.550
"For example, you can pick the
most probable hypothesis.",00:38:38.550,00:38:42.920
"Without any dispute, this is
the most probable hypothesis.",00:38:42.920,00:38:46.580
You can even go further.,00:38:46.580,00:38:47.830
"Well, I picked a hypothesis set, and this
is the probability that each of",00:38:47.830,00:38:50.940
them is the target function.,00:38:50.940,00:38:52.670
"And now that I have the evidence from
the data, I have a better picture of",00:38:52.670,00:38:55.840
"it, which is the posterior.",00:38:55.840,00:38:57.590
"I can now actually ask myself, I can
derive the expected value of h because",00:38:57.590,00:39:06.560
"for every h, there's a probability.",00:39:06.560,00:39:08.610
"Instead of picking just the highest
probability and sticking with it, why",00:39:08.610,00:39:12.570
"don't I get the benefit of the entire
probability distribution?",00:39:12.570,00:39:16.210
"Well, the target function could be this
one, could be this one, could be",00:39:16.210,00:39:18.750
"this one, with these probabilities.",00:39:18.750,00:39:20.320
"If you want a good estimate of the value
of the target function at any",00:39:20.320,00:39:24.020
"point x, why don't you take the value of
h of x for every hypothesis in your",00:39:24.020,00:39:29.460
"set, and put them together as expected
value because you have the probability",00:39:29.460,00:39:34.230
distribution?,00:39:34.230,00:39:35.210
"And then you get a very
good estimate of that.",00:39:35.210,00:39:38.830
"And you can even get an estimate
for the error bar.",00:39:38.830,00:39:43.840
After you get the estimate--,00:39:43.840,00:39:44.960
this is my estimate for this--,00:39:44.960,00:39:46.920
"I can tell you, what are the
chances that I'm wrong?",00:39:46.920,00:39:49.880
Think of the possibilities.,00:39:49.880,00:39:50.770
I'm predicting the stock market.,00:39:50.770,00:39:53.590
"And I learned using this
Bayesian learning.",00:39:53.590,00:39:55.820
And I have the inputs for today.,00:39:55.820,00:39:57.510
"And I want to predict the output, which
is what will happen tomorrow.",00:39:57.510,00:40:01.300
"Now, I can tell you the
price movement.",00:40:01.300,00:40:03.330
"What is the expected value
of the price movement,",00:40:03.330,00:40:05.880
"very specifically on that
x, which I care about.",00:40:05.880,00:40:08.760
"And I can also tell you,
what is the error bar.",00:40:08.760,00:40:10.830
"So if I tell you that the expected value
is positive, and the error bar is",00:40:10.830,00:40:13.660
"small, then the chances are
overwhelming that I will move",00:40:13.660,00:40:16.220
"positively, and I would be putting my
money in going in that direction.",00:40:16.220,00:40:19.010
"If the error bar is huge,
then I'm not so sure.",00:40:19.010,00:40:21.260
"And I'm not sure it's worthwhile
betting on it.",00:40:21.260,00:40:23.750
That's a good situation to be in.,00:40:23.750,00:40:27.340
"And also, you can derive anything
you can imagine.",00:40:27.340,00:40:30.900
"You have a joint
probability distribution.",00:40:30.900,00:40:32.140
"You can really put any events, and you
just plug in and collect the points",00:40:32.140,00:40:36.500
that constitute that event.,00:40:36.500,00:40:37.770
"And you get the probability, and
you have an answer for that.",00:40:37.770,00:40:41.730
"Now, let me make a statement
about the approach so far.",00:40:41.730,00:40:46.010
"We have been struggling with VC bounds,
and loose bounds, and then we have to",00:40:46.010,00:40:51.065
"use regularization, and we use
a heuristic for the regularizer.",00:40:51.065,00:40:54.450
"And then we have to the set aside
a validation set, and we wonder about the",00:40:54.450,00:40:57.640
independence of the cross-validation.,00:40:57.640,00:40:58.960
we really have a tough life.,00:40:58.960,00:41:01.600
"So in this approach, it looks like
they are doing much better.",00:41:01.600,00:41:05.080
"All they need to do is plug in the
quantities, and they get the answer.",00:41:05.080,00:41:08.160
"And they know that the
answer is correct.",00:41:08.160,00:41:09.400
"They don't worry about
any of the stuff.",00:41:09.400,00:41:11.800
"So the way I think about
it is the following.",00:41:11.800,00:41:17.590
"When you are following this ideology,
it's as if you want to have a good",00:41:17.590,00:41:22.790
"life, and this is your approach
to getting the good life.",00:41:22.790,00:41:29.000
"First, you rob a bank.",00:41:29.000,00:41:31.800
"Then, you live righteously ever after.",00:41:34.750,00:41:39.200
"Well, you can live righteously
ever after.",00:41:39.200,00:41:41.380
You can afford it.,00:41:41.380,00:41:42.850
"The other guys are struggling
with this and that, with",00:41:42.850,00:41:45.160
regularization and whatnot.,00:41:45.160,00:41:46.890
"The problem here obviously,
is the first step.",00:41:46.890,00:41:50.190
"And the first step here is
sugarcoated greatly.",00:41:50.190,00:41:54.000
It's a benign prior.,00:41:54.000,00:41:55.390
It's just uniform.,00:41:55.390,00:41:56.240
We didn't do anything.,00:41:56.240,00:41:57.450
"Because obviously, it's very
attractive afterwards.",00:41:57.450,00:42:00.340
"But you are standing on
very shaky ground.",00:42:00.340,00:42:03.690
"And you should ask yourself, when
is this actually justified?",00:42:03.690,00:42:08.480
"If you do it in general without any
justification, then it's a nice",00:42:08.480,00:42:12.070
"theory built on an assumption that
doesn't necessarily hold.",00:42:12.070,00:42:15.650
"On the other hand, it can be very
valuable, and it can be justified in",00:42:15.650,00:42:20.890
basically two cases.,00:42:20.890,00:42:22.140
"One of them is that the
prior is valid.",00:42:24.690,00:42:26.620
"And the other one is that
the prior is irrelevant.",00:42:29.450,00:42:33.240
What do I mean?,00:42:33.240,00:42:34.230
"Prior is valid is that for some reason
that I really don't know, you put",00:42:34.230,00:42:37.890
"a prior and this is, indeed, the
probability that a particular",00:42:37.890,00:42:41.940
hypothesis equals the target function.,00:42:41.940,00:42:43.550
That is a fact.,00:42:43.550,00:42:44.500
"In which case, I concede.",00:42:44.500,00:42:47.650
"You are doing better than me, I can
go with all my approximations, and",00:42:47.650,00:42:50.720
"heuristics, and this and that.",00:42:50.720,00:42:51.710
"And I'm not going to do nearly
as good as you do.",00:42:51.710,00:42:54.720
"So in this case, this trumps all
the cases if you know that the",00:42:54.720,00:42:57.730
assumption is valid.,00:42:57.730,00:42:59.380
"So if there are cases where the
assumption is valid, I highly",00:42:59.380,00:43:02.920
"recommend that you follow
this approach.",00:43:02.920,00:43:05.010
"It may be computationally expensive
because for example, when you get",00:43:05.010,00:43:08.130
"expected value with respect to the
posterior in a high-dimensional space,",00:43:08.130,00:43:10.310
that's not an easy task.,00:43:10.310,00:43:11.840
"On the other hand, since this is the
ultimate performance, it may be worth",00:43:11.840,00:43:14.840
the effort.,00:43:14.840,00:43:16.300
"""The prior is irrelevant"" is
a more interesting aspect.",00:43:16.300,00:43:18.910
The idea is the following.,00:43:18.910,00:43:21.090
"When you put a prior, if you get more
and more data and you look at the",00:43:21.090,00:43:25.300
"posterior, you realize that the
posterior is affected largely by the",00:43:25.300,00:43:29.030
"data set, and less and
less by the prior.",00:43:29.030,00:43:31.900
"If you start from another prior and
another prior and another prior, as",00:43:31.900,00:43:35.040
long as you don't take extremes.,00:43:35.040,00:43:36.140
"You don't put it to zero
at certain points.",00:43:36.140,00:43:37.790
You just get something reasonable.,00:43:37.790,00:43:39.890
"It basically gets factored out, as
you get more and more data.",00:43:39.890,00:43:44.340
"And because of that, if you have enough
data that the prior doesn't",00:43:44.340,00:43:47.850
"matter, then you can think of the prior
not as a conceptual addition.",00:43:47.850,00:43:51.530
"It's just a catalyst for
the computation.",00:43:51.530,00:43:55.050
"And there is a particular approach to
this where you think, let me pick",00:43:55.050,00:43:59.260
"a prior just because of its
analytic properties.",00:43:59.260,00:44:02.530
"I have no reason whatsoever to believe
that this is a valid prior.",00:44:02.530,00:44:06.930
"But it happens to be that when I have
this prior, and you give me a data",00:44:06.930,00:44:09.510
"point and I compute the posterior,
that computation is easy.",00:44:09.510,00:44:13.680
"These are called conjugate priors, where
you don't have to recompute the",00:44:13.680,00:44:17.100
posterior for the entire function.,00:44:17.100,00:44:18.870
"You parameterize the thing, and you find
that all you need to do is change",00:44:18.870,00:44:22.150
"the parameters when you
get new data points.",00:44:22.150,00:44:24.410
"So this is completely valid if you are
going to do is this enough that by the",00:44:24.410,00:44:28.040
"time you arrive, it didn't matter
what you started with.",00:44:28.040,00:44:30.960
"Then what you are really doing, you
are putting a system in your",00:44:30.960,00:44:34.760
"computation such that you arrive at
the correct result, and it doesn't",00:44:34.760,00:44:38.040
matter what your assumption was.,00:44:38.040,00:44:41.290
That's all I'm going to say.,00:44:41.290,00:44:43.350
"So you can take a full course on
Bayesian learning, and the techniques",00:44:43.350,00:44:47.570
are really wonderful.,00:44:47.570,00:44:48.960
I'm not doubting any of that.,00:44:48.960,00:44:52.230
"Just be careful where to apply them,
because there is an assumption, and the",00:44:52.230,00:44:55.920
"assumption is stronger than it
seems to the uninitiated.",00:44:55.920,00:44:59.860
Let's move to aggregation methods.,00:45:04.160,00:45:07.450
"So I am talking about aggregation
methods, as I mentioned, because they",00:45:07.450,00:45:10.610
"are really useful and they are not
that difficult to understand.",00:45:10.610,00:45:14.680
"So I'll give you the big picture,
and then you can pursue different",00:45:14.680,00:45:17.810
algorithms.,00:45:17.810,00:45:18.690
"So first, what is aggregation?",00:45:18.690,00:45:20.770
"It's a method that applies
to all models, as we said.",00:45:20.770,00:45:24.500
"The idea here is that you combine
different solutions.",00:45:24.500,00:45:28.680
"Let's say that I give a homework problem
to the class that requires you",00:45:28.680,00:45:32.510
to develop machine learning--,00:45:32.510,00:45:34.220
"you develop the machine
learning algorithm.",00:45:34.220,00:45:35.700
You get a final hypothesis.,00:45:35.700,00:45:37.040
Everyone gets a final hypothesis.,00:45:37.040,00:45:39.060
"And now I want to get the final
hypothesis of each of you guys and put",00:45:39.060,00:45:42.050
"them together, and combine
them into a solution.",00:45:42.050,00:45:44.770
"Hopefully better, because it got
the wisdom of everybody here.",00:45:44.770,00:45:47.220
That is the idea.,00:45:47.220,00:45:50.330
"So what you have, you have
a bunch of hypotheses.",00:45:50.330,00:45:52.070
"I would have called them g, as
a final hypothesis, because",00:45:52.070,00:45:54.760
that's what they are.,00:45:54.760,00:45:55.620
"They are the outcome
from full training.",00:45:55.620,00:45:57.490
"So each of them comes from training
on the entire D, with certain",00:45:57.490,00:46:00.850
specifications.,00:46:00.850,00:46:02.220
"But I'm still calling them h. Because
I'm using aggregation, the final",00:46:02.220,00:46:05.900
"hypothesis will really be
a combination of those guys.",00:46:05.900,00:46:07.780
"So they remain the h notation,
not the final hypothesis.",00:46:07.780,00:46:12.350
The picture that goes with that--,00:46:12.350,00:46:14.270
Here is the system that you got.,00:46:15.560,00:46:17.350
"Here is the system that the guy
next to you got, et cetera.",00:46:17.350,00:46:20.570
So I have all of those guys.,00:46:20.570,00:46:21.850
"Now I want to put them together,
and get one solution.",00:46:21.850,00:46:24.860
Very easy concept to have.,00:46:24.860,00:46:26.620
"So one example is the
example that I gave.",00:46:26.620,00:46:28.990
"People already solved it, and I want
to combine the solutions.",00:46:28.990,00:46:31.950
"Another one is interesting, and
is particularly interesting",00:46:31.950,00:46:34.140
for computer vision.,00:46:34.140,00:46:36.370
"In many cases, let's say that
you want detect a face.",00:46:36.370,00:46:41.580
"Now, this is a very complicated task.",00:46:41.580,00:46:43.990
"So you could do very simple detections
that are related to being a face.",00:46:43.990,00:46:49.530
"You can try to detect,
is there an eye?",00:46:49.530,00:46:52.850
"And you will get it right 51% of
the time, 52% of the time.",00:46:52.850,00:46:57.560
Is there a nose?,00:46:57.560,00:46:58.870
"Are the positions relative
to each other?",00:46:58.870,00:47:00.470
Is the lighting consistent?,00:47:00.470,00:47:01.570
"Whatever. Just put stuff,
and it doesn't have to",00:47:01.570,00:47:04.450
have that great meaning.,00:47:04.450,00:47:05.340
"You can just have simple masks that
look at the picture, and extract",00:47:05.340,00:47:09.210
"a feature that you think is
related to being a face.",00:47:09.210,00:47:12.190
"If you take any single feature, and you
try to decide whether this is a face",00:47:12.190,00:47:15.210
"based on it, you will do horribly.",00:47:15.210,00:47:17.790
The error will be huge.,00:47:17.790,00:47:20.100
"Now, if you put them all together and
think of them as different ways of",00:47:20.100,00:47:24.150
"looking at it, and then you combine them
correctly, then the decision all",00:47:24.150,00:47:27.380
of a sudden is reliable.,00:47:27.380,00:47:29.260
"This is important in computer vision
because in computer vision, the",00:47:29.260,00:47:36.960
computation is a big deal.,00:47:36.960,00:47:38.550
"You need to do things quickly, because
you are trying to be either real-time",00:47:38.550,00:47:41.920
or close to real-time.,00:47:41.920,00:47:43.110
"So using very simple features, as they're
called in this case, and then",00:47:43.110,00:47:47.240
"combining them, then that is
a good application for it.",00:47:47.240,00:47:51.560
"So let's talk about
what is combining.",00:47:51.560,00:47:55.300
"Well, combining is very simple.",00:47:55.300,00:47:56.270
There are many ways of combining.,00:47:56.270,00:47:57.480
"The most common is that if it's
a regression problem, these are guys",00:47:57.480,00:47:59.860
giving you real numbers.,00:47:59.860,00:48:01.456
Take an average.,00:48:01.456,00:48:02.706
"If you are doing classification,
so everybody is deciding yes",00:48:05.170,00:48:08.870
"or no, take a vote.",00:48:08.870,00:48:12.230
"Could be weighted average and weighted
vote, but that's basically",00:48:12.230,00:48:15.370
the essence of it.,00:48:15.370,00:48:16.140
"And there are other ways
of combining them.",00:48:16.140,00:48:18.910
"Now, there are many names
for aggregation.",00:48:18.910,00:48:20.880
"You can see it as ensemble learning.
Boosting is definitely one of them.",00:48:20.880,00:48:24.050
Mixture of experts is another.,00:48:24.050,00:48:25.660
"There are lots of methods that
belong to that category.",00:48:25.660,00:48:29.930
"Now, let me make the point that it is
different to do aggregation than to",00:48:29.930,00:48:33.670
just do a two-layer learning.,00:48:33.670,00:48:36.120
What do I mean by that?,00:48:36.120,00:48:38.350
If you have a two-layer model--,00:48:38.350,00:48:39.500
"so there are a bunch of
features followed by--",00:48:39.500,00:48:41.210
"you have seen that already,
like a neural network.",00:48:41.210,00:48:42.950
"Neurons in the hidden layer feeding
into the output, and you",00:48:42.950,00:48:46.000
are trying to learn.,00:48:46.000,00:48:48.530
The learning is joint.,00:48:48.530,00:48:49.550
You learn all of the units at once.,00:48:49.550,00:48:51.050
"So you look at this--
let me magnify it.",00:48:51.050,00:48:53.680
These are your units.,00:48:56.880,00:48:58.280
"What your learning algorithm does, it takes the
data and simultaneously adjusts all of",00:48:58.280,00:49:02.570
"these guys, in order to get
the right solution.",00:49:02.570,00:49:04.480
"This could be backpropagation,
for example.",00:49:04.480,00:49:07.130
"And in that case, any one of them is
not necessarily trying to replicate",00:49:07.130,00:49:10.560
the function.,00:49:10.560,00:49:12.170
"It's just trying to contribute
positively to the function.",00:49:12.170,00:49:15.140
"So at the final layer, you could
be taking the difference between",00:49:15.140,00:49:18.490
these two units.,00:49:18.490,00:49:19.190
"And that is the important thing that
affects you in the output.",00:49:19.190,00:49:22.340
"So the guys here are not trying to get
it right. They are just trying to be",00:49:22.340,00:49:27.420
"good soldiers and good
features in that.",00:49:27.420,00:49:30.530
"And the reason you do that because you
are doing it all at once, and you are",00:49:30.530,00:49:33.360
trying to minimize the error.,00:49:33.360,00:49:34.440
"So whatever combination
happens, happens.",00:49:34.440,00:49:36.660
So this is what we have done before.,00:49:36.660,00:49:40.350
"Now, in the case of aggregation,
the units learn independently.",00:49:40.350,00:49:45.260
"Each one learns as if it
was the only unit.",00:49:45.260,00:49:47.930
"So you are actually trying to learn
the function, and then",00:49:47.930,00:49:50.770
you combine them.,00:49:50.770,00:49:51.810
So you look at this picture.,00:49:51.810,00:49:54.480
"And in this case, the learning algorithm
looks at one at a time.",00:49:54.480,00:49:57.970
"Maybe it's different learning algorithms,
but at least it considers one at a time,",00:49:57.970,00:50:00.710
and then gets you what that is.,00:50:00.710,00:50:02.180
"And this guy is actually trying
to replicate the function.",00:50:02.180,00:50:04.590
"And this one is also trying to replicate
the function, et cetera.",00:50:04.590,00:50:07.730
"And finally, when you have all of
these guys that are trying to",00:50:07.730,00:50:10.080
"replicate the function, you combine
them and you get the output.",00:50:10.080,00:50:12.520
So that is the difference.,00:50:12.520,00:50:13.770
"Now, there are two types
of aggregation.",00:50:17.620,00:50:19.920
"And I'm going to call them certain
names for lack of a better word.",00:50:19.920,00:50:24.540
"But they are really different categories,
and I wanted to emphasize",00:50:24.540,00:50:27.230
this point.,00:50:27.230,00:50:29.092
"One of them I call ""after the fact"".",00:50:29.092,00:50:32.330
What does that mean?,00:50:32.330,00:50:34.060
"It means that you already
have solutions.",00:50:34.060,00:50:35.920
Remember the Netflix guys?,00:50:39.320,00:50:41.190
"So you have the crowd-sourcing, and
you let the problem out.",00:50:41.190,00:50:44.160
"Everybody tries hard, and
then gets a solution.",00:50:44.160,00:50:47.440
"Now you would like to combine
these solutions.",00:50:47.440,00:50:49.370
These solutions exist.,00:50:49.370,00:50:51.540
"They were developed with a view
to performance individually.",00:50:51.540,00:50:55.240
"Nobody was thinking about
putting them together.",00:50:55.240,00:50:58.240
"If you are thinking about putting them
together, you may have other",00:50:58.240,00:51:00.120
considerations.,00:51:00.120,00:51:00.790
"For example, you may decide, this
is going to go into a blend, which is",00:51:00.790,00:51:04.500
the word that goes with it.,00:51:04.500,00:51:06.550
"And therefore, I'd better get something
that is different from what the other",00:51:06.550,00:51:09.730
"guys are having, in order to
be able to contribute.",00:51:09.730,00:51:12.530
So there are other considerations.,00:51:12.530,00:51:14.010
"But in this case, you just get the
solutions, and then you combine them.",00:51:14.010,00:51:17.660
So that's one approach.,00:51:17.660,00:51:19.480
"The other one, which is the
boosting approach, is--",00:51:19.480,00:51:23.895
"I'm calling it ""before the fact"" to
contrast-- which is the fact that you",00:51:23.895,00:51:26.900
"are developing the solutions with
a view to the fact that",00:51:26.900,00:51:30.170
they will be blended.,00:51:30.170,00:51:32.320
So you get one guy.,00:51:32.320,00:51:35.840
"And then when you go to the other guy,
you are trying to develop a guy that",00:51:35.840,00:51:38.390
"will blend well with the
first guy, et cetera.",00:51:38.390,00:51:41.520
"So you are not trying to get it to
perform well in its own right.",00:51:41.520,00:51:44.930
"You are trying to make it
a good part of a blend.",00:51:44.930,00:51:48.190
"And we saw an example of that in one
of the Q&amp;A sessions, which was",00:51:48.190,00:51:52.000
a question of Bagging.,00:51:52.000,00:51:53.180
"Where I give you the data set, and
let's say that I want to give the",00:51:53.180,00:51:56.500
"class the problem, but I want
to combine at the end.",00:51:56.500,00:52:01.090
"And they are going to
work independently.",00:52:01.090,00:52:03.050
"So I want to do something to make sure
that they are fairly independent.",00:52:03.050,00:52:06.210
"So what I do, I re-sample D, and give
everybody a different sample from D--",00:52:06.210,00:52:12.730
a bootstrap sample.,00:52:12.730,00:52:14.110
"So because of that, I introduce some
independence in the information you",00:52:14.110,00:52:17.540
are getting.,00:52:17.540,00:52:18.320
"So when you get something, I am hoping
then when I put them together, I will",00:52:18.320,00:52:20.940
get the benefit of that independence.,00:52:20.940,00:52:22.190
"So in this case, this is what I am
doing for the case of bagging.",00:52:25.850,00:52:29.220
"I'm actually giving everyone of
them a different data set.",00:52:29.220,00:52:32.890
"But it's independent from the other
guys, and then I'm going to combine",00:52:32.890,00:52:35.510
what they have.,00:52:35.510,00:52:36.760
"Now, this leads to the boosting
algorithms, which are very successful",00:52:39.980,00:52:43.940
algorithms.,00:52:43.940,00:52:45.570
"And the idea here is that instead of
leaving the de-correlation to chance,",00:52:45.570,00:52:50.380
I'm going to enforce it.,00:52:50.380,00:52:52.480
"So I am building one hypothesis,
and the next one.",00:52:52.480,00:52:56.820
"And I am making sure that whatever I
am getting in the new hypothesis is",00:52:56.820,00:53:00.330
"novel-- was not covered
by the previous guys.",00:53:00.330,00:53:03.660
"That, obviously, improves my
chances of getting a good mix.",00:53:03.660,00:53:07.900
"So what you do, you create the
hypotheses sequentially.",00:53:07.900,00:53:11.210
"So you do one, two, three, four.",00:53:11.210,00:53:12.940
"And then, given the four that you have
so far, what is the best fifth that I",00:53:12.940,00:53:17.480
can add to the mix?,00:53:17.480,00:53:20.440
"And you make it good by making it
de-correlated with the other guys.",00:53:20.440,00:53:24.440
"So the picture here is
rather interesting.",00:53:24.440,00:53:26.350
"It's not quite independent,
but it's not as bad as doing",00:53:26.350,00:53:29.540
all of them at once.,00:53:29.540,00:53:31.360
What you do--,00:53:31.360,00:53:32.610
"you have already done those, so
this is a recursive procedure.",00:53:32.610,00:53:36.640
"Now, you read off from these and
you realize how they perform.",00:53:36.640,00:53:41.340
"And based on that, you do something such
that the data set you pass onto",00:53:41.340,00:53:44.820
"the new guy makes it develop something
that is fairly independent from the",00:53:44.820,00:53:48.530
previous guys.,00:53:48.530,00:53:50.340
"And now this is frozen, and
it contributes here.",00:53:50.340,00:53:53.810
"And then, this guy is trying to be
independent of all the previous guys.",00:53:53.810,00:53:56.870
"So every time you have one,
you get something new.",00:53:56.870,00:53:59.980
"Therefore, by the time you put them
in the mix, you get something",00:53:59.980,00:54:02.390
interesting.,00:54:02.390,00:54:03.620
So this is the idea.,00:54:03.620,00:54:05.630
"And the way to do the independence
is rather interesting.",00:54:05.630,00:54:12.860
"Let's say that so far, I have
60% correct and 40% wrong.",00:54:12.860,00:54:18.550
"That's what I have achieved
using the first few guys.",00:54:18.550,00:54:21.310
"So when I put them together,
that's what I get.",00:54:21.310,00:54:23.580
"60% and 40% means that 60% of the
examples I got right, if it's",00:54:23.580,00:54:28.210
"classification, and 40% I got wrong.",00:54:28.210,00:54:31.770
"So here is an idea to make the new guy
fairly independent of those guys.",00:54:31.770,00:54:36.980
"Let's say that I emphasize the
guys that I did badly on.",00:54:36.980,00:54:41.360
"I give them bigger weights
in the training.",00:54:41.360,00:54:43.430
"And de-emphasize the guys that I got
right, such that as far as the new",00:54:43.430,00:54:48.980
"distribution is concerned-- the new
emphasis I have-- it looks that what I",00:54:48.980,00:54:52.630
have so far is 50/50.,00:54:52.630,00:54:55.160
It's random.,00:54:55.160,00:54:56.800
"So what I have is not random,
because it deals with the",00:54:56.800,00:54:59.530
training set as it is.,00:54:59.530,00:55:00.870
"But if I give it different weights,
and I ask myself, what is the",00:55:00.870,00:55:04.340
weighted error now?,00:55:04.340,00:55:05.540
"And the weighted error is 50%, it means
that as far as the previous",00:55:05.540,00:55:09.150
"guys are concerned, it's as
if it's a random guess.",00:55:09.150,00:55:11.740
"So if I take that distribution and learn
on it and get something better",00:55:11.740,00:55:15.250
"than 50%, then the new guy I
am getting is adding value",00:55:15.250,00:55:19.310
to what I had before.,00:55:19.310,00:55:20.260
This is the general principle.,00:55:20.260,00:55:21.840
"And when you plug in this, you get
a very specific algorithm.",00:55:21.840,00:55:25.700
"You do this recursively, and you get
not only how you emphasize the",00:55:25.700,00:55:29.560
examples given the old ones.,00:55:29.560,00:55:31.560
"You also derive the different
weights of the mix.",00:55:31.560,00:55:36.960
"So some of the guys will be successful
in training, and some of them will not",00:55:36.960,00:55:40.130
be successful.,00:55:40.130,00:55:40.940
"And you are going to have weights
according to that.",00:55:40.940,00:55:43.762
"The most famous algorithm here, which
is a very specific prescription for",00:55:43.762,00:55:48.470
"how you do the emphasis, and how you do
the weighting, is called adaptive",00:55:48.470,00:55:51.780
"boosting, AdaBoost.",00:55:51.780,00:55:53.240
"And it is the one that is used in the
computer vision example that I gave.",00:55:53.240,00:55:58.330
"And indeed, in that case, what you are
doing, instead of working with just",00:55:58.330,00:56:04.590
"error trying to make it 50/50, you are
actually working with something",00:56:04.590,00:56:08.760
"similar to the margin
that we had before.",00:56:08.760,00:56:10.760
"Remember, when we had support vector
machines, we weren't settling",00:56:10.760,00:56:14.410
for getting it right.,00:56:14.410,00:56:15.490
"We want to get it right with
a margin of safety.",00:56:15.490,00:56:17.810
"So the AdaBoost algorithm defines
a cost function that has to do with",00:56:17.810,00:56:22.250
"violation of a margin, and then tries
to improve that margin as you go.",00:56:22.250,00:56:27.080
"And the weights, both for emphasizing
the examples and for picking the",00:56:27.080,00:56:33.190
"combination of the hypotheses
you have, are with a view to",00:56:33.190,00:56:35.810
maximizing that margin.,00:56:35.810,00:56:37.480
"And it's a very successful
algorithm in practice.",00:56:37.480,00:56:39.585
"Now let me,",00:56:43.310,00:56:44.400
"in the final technical slide,",00:56:44.400,00:56:46.700
"talk about blending after the fact
because it was applied to Netflix with",00:56:46.700,00:56:51.190
great success.,00:56:51.190,00:56:51.730
"And I want your attention because I'm
going to give you a puzzle.",00:56:51.730,00:56:54.170
"Last puzzle of the course, I guess.",00:56:54.170,00:56:56.840
Here is the deal.,00:56:56.840,00:56:58.580
"Now, I don't have the benefit of
de-correlation or anything.",00:56:58.580,00:57:00.780
I don't have a choice.,00:57:00.780,00:57:01.820
I just give the data to people.,00:57:01.820,00:57:03.190
They came up with solutions.,00:57:03.190,00:57:04.960
"And now, we want to put them together.",00:57:04.960,00:57:06.930
"Think of yourself in the last month
of Netflix, and you want to win.",00:57:06.930,00:57:10.270
"The other teams are getting together,
and getting good result.",00:57:10.270,00:57:12.780
"So you look for other guys
that look promising.",00:57:12.780,00:57:14.470
They have good solutions.,00:57:14.470,00:57:15.610
They already have the solutions.,00:57:15.610,00:57:16.810
"You are not going to ask them, let's redo
the whole thing with a view to de-correlation.",00:57:16.810,00:57:20.350
There is no time.,00:57:20.350,00:57:21.540
"So what you want to do is, you want to
take their solutions and put them",00:57:21.540,00:57:23.720
"together, and get the answer.",00:57:23.720,00:57:25.980
"So you want this and your plan
is, let me do this.",00:57:25.980,00:57:28.870
It's a regression problem.,00:57:28.870,00:57:29.970
You are trying to get a rating.,00:57:29.970,00:57:31.650
"And therefore, what I'm going to do, I
am going to combine the solutions that",00:57:31.650,00:57:35.270
"I have, using some coefficients",00:57:35.270,00:57:37.270
"from t equals 1 to T.
And now my job is to",00:57:37.270,00:57:39.940
pick the alpha's optimally.,00:57:39.940,00:57:42.270
"The best combination for the solution,
so that I get a good performance.",00:57:42.270,00:57:46.640
"Now, you can think of this as a very
simple training at a higher level.",00:57:46.640,00:57:51.570
"Now, you take the solutions as if they
were the inputs and you are trying to",00:57:51.570,00:57:56.040
"predict the output, which
is the same output.",00:57:56.040,00:57:58.180
"So what you are going to do, you are
going to have a principled choice of",00:57:58.180,00:58:01.570
"alpha's, using now not a training set,
not a test set, not a validation set,",00:58:01.570,00:58:07.240
but an aggregation set.,00:58:07.240,00:58:09.620
"So you set aside some points
that were not used in the",00:58:09.620,00:58:12.230
development of these guys.,00:58:12.230,00:58:14.780
"And then you use those just to decide,
what are the best coefficients you",00:58:14.780,00:58:19.140
"have for these solutions, such that the
error on that aggregation set is the",00:58:19.140,00:58:23.930
best possible?,00:58:23.930,00:58:25.670
"Now if you do this, if you use mean
squared error, what will your",00:58:25.670,00:58:30.200
algorithm be for choosing alpha's?,00:58:30.200,00:58:31.860
"It's the good old pseudo-inverse
again.",00:58:31.860,00:58:34.950
You do this and you minimize it.,00:58:34.950,00:58:36.620
"Now, it's important to realize here
that I really need a clean set.",00:58:36.620,00:58:39.960
"If I use the training set that these
guys used, then the guy that got the",00:58:39.960,00:58:45.120
"best training error will have
a big weight.",00:58:45.120,00:58:48.970
"And obviously, that's a problem
because we know that having ",00:58:48.970,00:58:52.400
"a small training error is
not indicated.",00:58:52.400,00:58:54.290
"But if these guys are frozen and I take
a fresh set, and then I get the",00:58:54.290,00:58:58.860
"combination, it's completely valid.",00:58:58.860,00:59:01.630
"And then I get those guys,
and get the solution.",00:59:01.630,00:59:05.890
Now comes an interesting thing.,00:59:05.890,00:59:07.370
"Let's say that I do this in class,
which I actually did.",00:59:07.370,00:59:10.070
"There was a time we had the Netflix
data, and people would come",00:59:10.070,00:59:16.150
"up with solutions with
a view to aggregation.",00:59:16.150,00:59:17.990
"That's when the competition
was still alive.",00:59:17.990,00:59:21.500
So people came up with a solution.,00:59:21.500,00:59:23.560
Now I want to combine them.,00:59:23.560,00:59:25.940
"So, imagine you work on this.",00:59:25.940,00:59:28.280
You have your solution.,00:59:28.280,00:59:29.200
"Your solution is supposed
to predict the rating.",00:59:29.200,00:59:31.220
"And the other guy is
predicting the rating.",00:59:31.220,00:59:32.760
And then I am putting them in.,00:59:32.760,00:59:34.750
"So you think, maybe the guy that
has a big alpha has a good solution,",00:59:34.750,00:59:40.400
"because its solution is affecting
the output a lot.",00:59:40.400,00:59:44.230
"Now, can you imagine what happens
if your alpha is negative?",00:59:44.230,00:59:48.060
You worked hard.,00:59:51.290,00:59:52.510
You got a solution.,00:59:52.510,00:59:54.490
"And then when you put that solution
together with the best solutions, the",00:59:54.490,00:59:58.280
"best possible outcome we can
get is by subtracting your",00:59:58.280,01:00:01.810
solution from the total.,01:00:01.810,01:00:05.680
"That was completely
devastating to people.",01:00:05.680,01:00:07.800
"But please, don't lose your
self-esteem because of this.",01:00:07.800,01:00:12.960
"The size of the weights is not the
criterion, or the sign of the weights",01:00:12.960,01:00:15.980
"is not the criterion for your
solution being valuable.",01:00:15.980,01:00:20.540
"Because it could be that you are so
correlated with other solutions, that",01:00:20.540,01:00:24.670
"what the system is trying to do is
trying to combine those in order to",01:00:24.670,01:00:27.840
"get the signal part right,
and eliminate the noise.",01:00:27.840,01:00:31.250
"So depending on the noise in your
solution, you could be negative.",01:00:31.250,01:00:33.805
You are contributing to that mix.,01:00:33.805,01:00:35.670
"So although it looks on face value
that negative-- oh my god.",01:00:35.670,01:00:39.630
"If I did nothing, I would've gotten
a weight 0 and now I have--",01:00:39.630,01:00:42.940
"no, that's not the case.",01:00:42.940,01:00:44.380
"So the question is, how do you evaluate
which of those solutions is",01:00:44.380,01:00:51.510
the most valuable in the blend?,01:00:51.510,01:00:53.530
"I had that practical problem, because
I wanted to reward people.",01:00:53.530,01:00:56.990
And I don't want people--,01:00:56.990,01:00:58.290
"when I give this problem,
everybody is trying to do the same",01:00:58.290,01:01:01.460
"thing, because it gives them
the best performance.",01:01:01.460,01:01:03.910
"So I would like to reward someone who
did something adventurous, and",01:01:03.910,01:01:07.190
therefore got a different angle on it.,01:01:07.190,01:01:09.180
"And therefore, contributed
to the blend.",01:01:09.180,01:01:11.760
"Whereas the other guys are all doing the
same thing, everybody will get",01:01:11.760,01:01:14.420
a small share so it's not a big deal.,01:01:14.420,01:01:16.620
"So I wanted to have an objective
criterion for doing that.",01:01:16.620,01:01:19.010
"What would you do in order
to evaluate that?",01:01:19.010,01:01:22.090
"By the way, this actually was used in the
competition as well when, eventually",01:01:25.810,01:01:30.120
"there was one team that decided
to have an open announcement.",01:01:30.120,01:01:35.420
Anybody can join.,01:01:35.420,01:01:37.150
"Give us your solution, and we
will see how useful it is.",01:01:37.150,01:01:40.630
"And then we'll give you stocks in the
prize according to how much you",01:01:40.630,01:01:44.560
contributed.,01:01:44.560,01:01:46.680
"And actually, that team ended up in
second place, so it's not a bad idea.",01:01:46.680,01:01:51.570
"So the idea here is that if you really
want to know the value of a particular",01:01:51.570,01:01:54.680
"hypothesis, here's what you do.",01:01:54.680,01:01:57.250
You take it out.,01:01:57.250,01:01:59.510
"You evaluate all, without
your solution.",01:01:59.510,01:02:02.300
You get a performance.,01:02:02.300,01:02:04.080
"And then evaluate with your solution,
and you get another performance.",01:02:04.080,01:02:08.590
"The difference is the contribution
of your solution.",01:02:08.590,01:02:12.570
"So one of the ramifications of that
is that if two people are doing",01:02:12.570,01:02:15.400
"identically the same thing, then
obviously each of them is useless.",01:02:15.400,01:02:21.480
"Because when you take it out, the
other guy will hold the day.",01:02:21.480,01:02:24.970
"But those guys who did something
completely fringy--",01:02:24.970,01:02:28.260
"I ask you, what is your performance?",01:02:28.260,01:02:29.570
"Oh, I got 6%.",01:02:29.570,01:02:30.655
Towards 10%.,01:02:30.655,01:02:32.450
And what is your performance?,01:02:32.450,01:02:33.820
I got only 3 and 1/2 %,01:02:33.820,01:02:36.150
"But then when I look at their
contribution to the final thing, when",01:02:36.150,01:02:39.130
"I put them together I get a total
performance, let's say, of 8%.",01:02:39.130,01:02:42.440
"If I take the 3 and 1/2 % out, the
8% drops to 7 and 1/2 %.",01:02:42.440,01:02:46.590
So they contributed half a percent.,01:02:46.590,01:02:48.640
"If I take the guy who had 6% and take it
out, the 8% percent goes to 7.95%.",01:02:48.640,01:02:52.620
Who cares?,01:02:52.620,01:02:54.310
"So this was the way in order to be
able to reward your actual",01:02:54.310,01:02:57.190
contribution to a mix.,01:02:57.190,01:03:00.790
"Now, there will be no Q&amp;A session
today, but I will be happy to answer",01:03:00.790,01:03:06.040
questions on the forum.,01:03:06.040,01:03:07.970
"What I'm going to do now, I am going to
do acknowledgements for people who",01:03:07.970,01:03:11.970
"contributed to the course, before
I close on a personal note.",01:03:11.970,01:03:16.800
"The first acknowledgment goes to
my colleagues, Professor Malik",01:03:16.800,01:03:20.590
"Magdon-Ismail and Professor
Hsuan-Tien Lin.",01:03:20.590,01:03:22.930
"All I can say is that they are as
responsible for the content of this",01:03:25.690,01:03:30.000
course as I am.,01:03:30.000,01:03:32.370
Enough said.,01:03:32.370,01:03:35.120
"Now, I'd like to acknowledge
the course staff.",01:03:35.120,01:03:37.730
There are many people who helped.,01:03:37.730,01:03:39.130
"I am singling out the people
who contributed the most.",01:03:39.130,01:03:41.460
"Carlos, Ron, Costis, and Doris have
contributed to everything you can",01:03:44.280,01:03:49.680
imagine about the course.,01:03:49.680,01:03:51.400
"From suggestions about the format, even
getting the right slide system,",01:03:51.400,01:03:56.610
"designing the homework, writing the
registration and online system from",01:03:56.610,01:04:00.970
"scratch, everything you can imagine.",01:04:00.970,01:04:03.430
"And they filled in to other tasks when
it was needed, and they ended up",01:04:03.430,01:04:06.990
"working far more than
they are paid for!",01:04:06.990,01:04:11.560
So I'm really grateful to them.,01:04:11.560,01:04:13.230
"And the head TA, who is Carlos,
happens to be familiar to you.",01:04:13.230,01:04:18.220
You heard his voice in every lecture.,01:04:18.220,01:04:20.410
He's the voice of the Q&amp;A session.,01:04:20.410,01:04:22.680
"And I suspect that people are curious
to see what the guy looks like.",01:04:22.680,01:04:25.630
They heard his voice.,01:04:25.630,01:04:27.150
"So let me ask Carlos to come
to the podium and say hello",01:04:27.150,01:04:29.900
to the online audience.,01:04:29.900,01:04:32.590
[APPLAUSE],01:04:32.590,01:04:36.590
YASER ABU-MOSTAFA: So here's Carlos.,01:04:36.590,01:04:38.000
"CARLOS GONZALEZ: Hi! You know
my voice. Now, you know my face.",01:04:38.010,01:04:40.790
"YASER ABU-MOSTAFA: OK, you are exempt
from the Q&amp;A session today.",01:04:40.790,01:04:43.540
Fair enough?,01:04:43.540,01:04:44.120
Thank you so much.,01:04:44.120,01:04:45.250
"CARLOS GONZALEZ: It's an honor
to work with Yaser.",01:04:45.250,01:04:47.150
It's really great to work with him.,01:04:47.150,01:04:48.440
"So thank you, Yaser.",01:04:48.440,01:04:49.649
YASER ABU-MOSTAFA: Thank you.,01:04:49.649,01:04:50.647
Very good.,01:04:50.647,01:04:51.146
Thank you.,01:04:51.146,01:04:51.645
[APPLAUSE],01:04:51.645,01:04:55.140
YASER ABU-MOSTAFA: OK.,01:04:55.140,01:04:56.490
"Now, most of the people have seen this
course, and everybody after that will",01:04:56.490,01:05:03.680
"see this course, through the tapes.",01:05:03.680,01:05:06.310
"And the medium that resulted in
those tapes are the AMT staff.",01:05:06.310,01:05:12.040
Leslie Maxfield being the director.,01:05:12.040,01:05:14.080
"And I would like to acknowledge
them in very passionate terms.",01:05:14.080,01:05:18.270
They have done an enormous job.,01:05:18.270,01:05:20.030
It was great amount of work for them.,01:05:20.030,01:05:22.560
"And they are all here, obviously
with the cameras and that.",01:05:22.560,01:05:25.220
"And I'm really grateful
to their contribution.",01:05:25.220,01:05:28.720
"I'm also grateful to the computing
support staff, and Rich in particular.",01:05:28.720,01:05:34.950
"Not only because of providing the
infrastructure for having this course,",01:05:34.950,01:05:38.250
"but also for supporting the idea of the
course very early, before we even",01:05:38.250,01:05:41.730
raised the money.,01:05:41.730,01:05:42.780
So we had a head start on this.,01:05:42.780,01:05:44.340
"And we started talking to
people and doing that.",01:05:44.340,01:05:46.550
"And we weren't sure even
that it will happen.",01:05:46.550,01:05:48.300
"So I appreciate the fact that there was
confidence that this might be",01:05:48.300,01:05:50.840
"a good idea, in order to put
that to begin with.",01:05:50.840,01:05:53.600
"Now, this course cost money.",01:05:57.010,01:06:00.080
"And I was insistent, and Caltech was
insistent, that this will be",01:06:00.080,01:06:04.380
perpetually free for everyone.,01:06:04.380,01:06:07.000
That was the whole idea.,01:06:07.000,01:06:08.550
"We wanted to give a Caltech-quality
course to anybody who has the",01:06:08.550,01:06:13.030
"discipline to follow such course,
without costing them a penny.",01:06:13.030,01:06:17.840
And we succeeded in that.,01:06:17.840,01:06:19.070
"And in order to succeed in that,
you actually need the money.",01:06:19.070,01:06:21.990
"If we didn't raise the money, this
would not have happened.",01:06:21.990,01:06:24.930
"And I'd like to acknowledge the sources
of the money, and the people",01:06:24.930,01:06:27.440
who drove the money raising.,01:06:27.440,01:06:29.760
"The Information Science and Technology
Initiative, the Engineering and",01:06:29.760,01:06:34.030
"Applied Science Division, and
the Provost's Office.",01:06:34.030,01:06:37.420
"Mathieu, in particular, took the
lead in raising the money,",01:06:37.420,01:06:40.710
in getting the publicity--,01:06:40.710,01:06:41.645
"He just took an interest in this,
and was incredibly invaluable in",01:06:41.645,01:06:46.310
getting this going.,01:06:46.310,01:06:47.890
"And at the Division, both Ares and Mani
were very helpful and supportive.",01:06:47.890,01:06:52.420
"And believe me, if you do something that
intensive, you need the support",01:06:52.420,01:06:55.960
of everybody.,01:06:55.960,01:06:56.630
"Otherwise, you lose heart
in the middle.",01:06:56.630,01:06:58.860
"And that was very instrumental
in getting this going.",01:06:58.860,01:07:02.190
"And at the Provost's Office, both Ed and
Melany reached for the educational",01:07:02.190,01:07:06.740
"funds and got the money, so we didn't
have to worry about it.",01:07:06.740,01:07:09.710
"So it's not only financial support, it's
also moral support and confidence",01:07:09.710,01:07:13.730
that this will be something good.,01:07:13.730,01:07:16.420
"Now, there are many people that I will
have forgotten to acknowledge, so I'm",01:07:16.420,01:07:21.190
"going to give a general
acknowledgment.",01:07:21.190,01:07:23.110
"And I apologize for any particular
person that contributed and I forgot",01:07:23.110,01:07:26.790
to give them their due reward.,01:07:26.790,01:07:31.270
"The TA's, other than the ones I
mentioned, have contributed greatly",01:07:31.270,01:07:35.630
"and they took a load off my agenda by
answering questions to the students,",01:07:35.630,01:07:42.390
and taking care of the homework.,01:07:42.390,01:07:44.760
"And there are many staff members, at
the division level and at the",01:07:44.760,01:07:48.140
"departmental level, who helped
in all kinds of ways.",01:07:48.140,01:07:51.520
"The Caltech alumni were
absolutely great.",01:07:51.520,01:07:53.900
"I got an incredible support from the
Caltech alumni who are genuinely",01:07:53.900,01:07:57.720
"a family, spread around the world.",01:07:57.720,01:07:59.840
"And the Alumni Association, that helped get
the word out, was very instrumental in",01:07:59.840,01:08:04.120
getting the publicity right.,01:08:04.120,01:08:06.460
"And I had incredible support from
colleagues all over the world.",01:08:06.460,01:08:11.860
"I usually don't like my email because
70% is spam and 20% are scams, and",01:08:11.860,01:08:18.100
then 10% are relevant.,01:08:18.100,01:08:20.050
"But it was worth going through all of
this, in order to hear the wonderful",01:08:20.050,01:08:24.189
"words of support that I'm getting from
the four corners of the world.",01:08:24.189,01:08:29.130
"Now on a personal note, allow me to
dedicate the course to the best friend",01:08:29.130,01:08:35.630
I have ever had.,01:08:35.630,01:08:37.600
"Well, I learned a lot from her,
and learning is precious.",01:08:37.600,01:08:41.890
"And my hope is that this course
was a positive learning",01:08:41.890,01:08:45.910
experience for everyone.,01:08:45.910,01:08:48.729
"And in particular, I thank my Caltech
students for really putting up with",01:08:48.729,01:08:54.170
"the inconvenience of cameras,
regimented lecture format, and",01:08:54.170,01:08:58.840
"whatnot, in order to share
this learning experience",01:08:58.840,01:09:01.890
with the whole world.,01:09:01.890,01:09:03.500
Thank you.,01:09:03.500,01:09:04.300
[APPLAUSE],01:09:04.300,01:09:05.550
