text,start,stop
"OK, here's the last lecture in
the chapter on orthogonality.",00:00:22.770,00:00:28.040
"So we met orthogonal
vectors, two vectors,",00:00:28.040,00:00:32.409
"we met orthogonal subspaces,
like the row space and null",00:00:32.409,00:00:38.030
space.,00:00:38.030,00:00:39.090
"Now today we meet
an orthogonal basis,",00:00:39.090,00:00:44.220
and an orthogonal matrix.,00:00:44.220,00:00:46.870
So we really --,00:00:46.870,00:00:48.420
"this chapter cleans
up orthogonality.",00:00:48.420,00:00:51.670
And really I want --,00:00:51.670,00:00:54.430
"I should use the
word orthonormal.",00:00:54.430,00:00:59.380
"Orthogonal is -- so my
vectors are q1,q2 up to qn --",00:00:59.380,00:01:07.190
"I use the letter ""q"",
here, to remind me,",00:01:07.190,00:01:11.680
"I'm talking about orthogonal
things, not just any vectors,",00:01:11.680,00:01:16.770
but orthogonal ones.,00:01:16.770,00:01:18.190
So what does that mean?,00:01:18.190,00:01:19.730
"That means that every q is
orthogonal to every other q.",00:01:19.730,00:01:24.100
"It's a natural idea,
to have a basis that's",00:01:24.100,00:01:29.380
"headed off at
ninety-degree angles,",00:01:29.380,00:01:32.560
the inner products are all zero.,00:01:32.560,00:01:34.620
"Of course if q is -- certainly
qi is not orthogonal to itself.",00:01:34.620,00:01:41.760
"But there we'll make
the best choice again,",00:01:41.760,00:01:44.700
make it a unit vector.,00:01:44.700,00:01:46.550
"Then qi transpose qi is
one, for a unit vector.",00:01:46.550,00:01:51.110
The length squared is one.,00:01:51.110,00:01:53.090
"And that's what I would
use the word normal.",00:01:53.090,00:01:56.930
"So for this part, normalized,
unit length for this part.",00:01:56.930,00:02:03.980
OK.,00:02:03.980,00:02:04.480
"So first part of
the lecture is how",00:02:04.480,00:02:10.620
"does having an orthonormal
basis make things nice?",00:02:10.620,00:02:14.820
It certainly does.,00:02:14.820,00:02:15.830
"It makes all the
calculations better,",00:02:15.830,00:02:17.990
"a whole lot of
numerical linear algebra",00:02:17.990,00:02:20.650
"is built around working
with orthonormal vectors,",00:02:20.650,00:02:26.020
"because they never
get out of hand,",00:02:26.020,00:02:27.730
"they never overflow
or underflow.",00:02:27.730,00:02:31.720
"And I'll put them
into a matrix Q,",00:02:31.720,00:02:35.890
"and then the second
part of the lecture",00:02:35.890,00:02:37.930
"will be suppose my
basis, my columns of A",00:02:37.930,00:02:42.130
are not orthonormal.,00:02:42.130,00:02:44.210
How do I make them so?,00:02:44.210,00:02:46.160
"And the two names associated
with that simple idea",00:02:46.160,00:02:50.610
are Graham and Schmidt.,00:02:50.610,00:02:52.340
"So the first part is we've
got a basis like this.",00:02:52.340,00:02:58.910
"Let's put those into
the columns of a matrix.",00:02:58.910,00:03:01.540
So a matrix Q that has --,00:03:04.120,00:03:09.490
"I'll put these
orthonormal vectors,",00:03:09.490,00:03:12.180
"q1 will be the first column,
qn will be the n-th column.",00:03:12.180,00:03:17.150
"And I want to say, I want
to write this property,",00:03:19.850,00:03:25.110
"qi transpose qj
being zero, I want",00:03:25.110,00:03:29.390
to put that in a matrix form.,00:03:29.390,00:03:33.140
"And just the right thing is
to look at Q transpose Q.",00:03:33.140,00:03:38.890
"So this chapter has been
looking at A transpose A.",00:03:38.890,00:03:43.020
"So it's natural to
look at Q transpose Q.",00:03:43.020,00:03:45.970
"And the beauty is it
comes out perfectly.",00:03:45.970,00:03:48.990
"Because Q transpose has
these vectors in its rows,",00:03:48.990,00:03:53.660
"the first row is q1 transpose,
the nth row is qn transpose.",00:03:53.660,00:04:01.010
So that's Q transpose.,00:04:01.010,00:04:04.570
And now I want to multiply by Q.,00:04:04.570,00:04:07.110
"That has q1 along to
qn in the columns.",00:04:07.110,00:04:12.310
That's Q.,00:04:12.310,00:04:13.930
And what do I get?,00:04:13.930,00:04:14.910
"You really -- this is the
first simplest most basic fact,",00:04:17.440,00:04:21.740
"that how do orthonormal
vectors, orthonormal columns",00:04:21.740,00:04:26.430
"in a matrix, what happens
if I compute Q transpose Q?",00:04:26.430,00:04:33.160
Do you see it?,00:04:33.160,00:04:34.350
"If I take the first row
times the first column,",00:04:34.350,00:04:38.560
what do I get?,00:04:38.560,00:04:40.670
A one.,00:04:40.670,00:04:42.180
"If I take the first row
times the second column,",00:04:42.180,00:04:45.070
what do I get?,00:04:45.070,00:04:46.830
Zero.,00:04:46.830,00:04:47.780
That's the orthogonality.,00:04:47.780,00:04:49.670
"The first row times the
last column is zero.",00:04:49.670,00:04:52.960
"And so I'm getting
ones on the diagonal",00:04:52.960,00:04:56.130
"and I'm getting zeroes
everywhere else.",00:04:56.130,00:04:59.120
I'm getting the identity matrix.,00:04:59.120,00:05:00.580
"You see how that's -- it's
just like the right calculation",00:05:03.380,00:05:06.420
to do.,00:05:06.420,00:05:07.240
"If you have orthonormal
columns, and the matrix",00:05:07.240,00:05:11.040
doesn't have to be square here.,00:05:11.040,00:05:14.920
We might have just two columns.,00:05:14.920,00:05:17.790
"And they might have
four, lots of components.",00:05:17.790,00:05:21.170
"So but they're orthonormal, and
when we do Q transpose times Q,",00:05:21.170,00:05:28.870
"that Q transpose times
Q or A transpose A",00:05:28.870,00:05:32.610
"just asks for all
those dot products.",00:05:32.610,00:05:38.180
Rows times columns.,00:05:38.180,00:05:40.030
"And in this orthonormal case,
we get the best possible answer,",00:05:40.030,00:05:44.890
the identity.,00:05:44.890,00:05:46.350
"OK, so this is --",00:05:46.350,00:05:48.830
"so I mean now we have a new
bunch of important matrices.",00:05:48.830,00:05:55.190
What have we seen previously?,00:05:55.190,00:05:56.570
"We've seen in the
distant past we",00:05:56.570,00:05:58.940
"had triangular matrices,
diagonal matrices, permutation",00:05:58.940,00:06:03.680
"matrices, that was
early chapters,",00:06:03.680,00:06:07.260
"then we had row echelon
forms, then in this chapter",00:06:07.260,00:06:14.690
"we've already seen
projection matrices,",00:06:14.690,00:06:18.400
"and now we're seeing this
new class of matrices",00:06:18.400,00:06:24.330
with orthonormal columns.,00:06:24.330,00:06:26.990
That's a very long expression.,00:06:26.990,00:06:29.010
"I sorry that I can't just
call them orthogonal matrices.",00:06:29.010,00:06:34.520
"But that word
orthogonal matrices --",00:06:34.520,00:06:37.590
"or maybe I should be able to
call it orthonormal matrices,",00:06:37.590,00:06:40.940
"why don't we call
it orthonormal --",00:06:40.940,00:06:43.590
"I mean that would be an
absolutely perfect name.",00:06:43.590,00:06:46.790
"For Q, call it an
orthonormal matrix",00:06:46.790,00:06:49.360
"because its columns
are orthonormal.",00:06:49.360,00:06:51.870
"OK, but the convention is
that we only use that name",00:06:51.870,00:06:57.770
"orthogonal matrix,
we only use this --",00:06:57.770,00:07:02.430
"this word orthogonal,
we don't even",00:07:02.430,00:07:05.170
"say orthonormal for
some unknown reason,",00:07:05.170,00:07:07.450
matrix when it's square.,00:07:07.450,00:07:10.035
"So in the case when this is a
square matrix, that's the case",00:07:14.630,00:07:20.240
we call it an orthogonal matrix.,00:07:20.240,00:07:23.330
"And what's special about
the case when it's square?",00:07:23.330,00:07:27.790
"When it's a square matrix,
we've got its inverse, so --",00:07:27.790,00:07:34.890
"so in the case if Q is square,
then Q transpose Q equals I",00:07:34.890,00:07:49.350
tells us --,00:07:49.350,00:07:51.230
let me write that underneath --,00:07:51.230,00:07:53.320
"tells us that Q
transpose is Q inverse.",00:07:53.320,00:08:03.170
"There we have the
easy to remember",00:08:03.170,00:08:06.500
"property for a square matrix
with orthonormal columns.",00:08:06.500,00:08:12.940
"That -- I need to write
some examples down.",00:08:12.940,00:08:17.460
Let's see.,00:08:17.460,00:08:19.680
"Some examples like if I
take any -- so examples,",00:08:19.680,00:08:23.250
let's do some examples.,00:08:23.250,00:08:24.220
"Any permutation matrix,
let me take just",00:08:27.600,00:08:30.330
some random permutation matrix.,00:08:30.330,00:08:32.860
"Permutation Q equals let's say
oh, make it three by three,",00:08:32.860,00:08:39.419
"say zero, zero, one, one,
zero, zero, zero, one, zero.",00:08:39.419,00:08:45.550
OK.,00:08:45.550,00:08:46.050
"That certainly has unit
vectors in its columns.",00:08:51.970,00:08:57.360
"Those vectors are certainly
perpendicular to each other.",00:08:57.360,00:09:01.440
And if I -- and so that's it.,00:09:01.440,00:09:04.200
That makes it a Q.,00:09:04.200,00:09:05.940
"And -- if I took its transpose,
if I multiplied by Q transpose,",00:09:05.940,00:09:11.860
"shall I do that -- and let
me stick in Q transpose",00:09:11.860,00:09:15.140
here.,00:09:15.140,00:09:15.900
"Just to do that
multiplication once more,",00:09:15.900,00:09:18.490
transpose it'll put the --,00:09:18.490,00:09:20.700
"make that into a column,
make that into a column,",00:09:20.700,00:09:24.220
make that into a column.,00:09:24.220,00:09:26.420
And the transpose is also --,00:09:26.420,00:09:29.700
another Q.,00:09:29.700,00:09:31.190
Another orthonormal matrix.,00:09:31.190,00:09:32.570
"And when I multiply that
product I get I. OK,",00:09:32.570,00:09:37.610
so there's an example.,00:09:37.610,00:09:39.390
"And actually there's
a second example.",00:09:39.390,00:09:42.360
"But those are real
easy examples, right,",00:09:42.360,00:09:44.920
"I mean to get orthogonal
columns by just",00:09:44.920,00:09:50.280
"putting ones in different
places is like too easy.",00:09:50.280,00:09:56.130
"So let me keep
going with examples.",00:09:56.130,00:09:58.530
"So here's another
simple example.",00:09:58.530,00:10:01.670
"Cos theta sine theta,
there's a unit vector,",00:10:01.670,00:10:06.670
"oh, let me even
take it, well, yeah.",00:10:06.670,00:10:09.420
"Cos theta sine theta
and now the other way",00:10:09.420,00:10:14.000
I want sine theta cos theta.,00:10:14.000,00:10:17.290
"But I want the inner
product to be zero.",00:10:17.290,00:10:21.200
"And if I put a minus
there, it'll do it.",00:10:21.200,00:10:24.650
"So that's -- unit vector,
that's a unit vector.",00:10:24.650,00:10:28.260
"And if I take the dot product,
I get minus plus zero.",00:10:28.260,00:10:32.420
OK.,00:10:34.970,00:10:35.470
"For example Q equals say
one, one, one, minus one,",00:10:35.470,00:10:42.730
is that an orthogonal matrix?,00:10:42.730,00:10:46.210
"I've got orthogonal
columns there,",00:10:48.780,00:10:51.100
"but it's not quite
an orthogonal matrix.",00:10:51.100,00:10:53.420
"How shall I fix it to
be an orthogonal matrix?",00:10:53.420,00:10:58.500
"Well, what's the length
of those column vectors,",00:10:58.500,00:11:01.280
"the dot product with themselves
is -- right now it's two,",00:11:01.280,00:11:07.040
"right, the --",00:11:07.040,00:11:08.260
the length squared.,00:11:08.260,00:11:10.540
"The length squared would be
one plus one would be two,",00:11:10.540,00:11:13.216
"the length would be
square root of two,",00:11:13.216,00:11:14.840
"so I better divide by
square root of two.",00:11:14.840,00:11:18.290
OK.,00:11:18.290,00:11:19.250
"So there's a -- there now I
have got an orthogonal matrix,",00:11:19.250,00:11:23.580
"in fact, it's this one --
when theta is pi over four.",00:11:23.580,00:11:28.850
"The cosines and
well almost, I guess",00:11:28.850,00:11:31.710
"the minus sine is down
there, so maybe, I",00:11:31.710,00:11:35.110
"don't know, maybe minus
pi over four or something.",00:11:35.110,00:11:39.151
OK.,00:11:39.151,00:11:39.650
"Let me do one
final example, just",00:11:42.260,00:11:44.260
"to show that you
can get bigger ones.",00:11:44.260,00:11:47.500
"Q equals let me take that
matrix up in the corner",00:11:47.500,00:11:53.770
"and I'll sort of
repeat that pattern,",00:11:53.770,00:11:57.330
"repeat it again, and
then minus it down here.",00:11:57.330,00:12:02.510
"That's one of the world's
favorite orthogonal matrices.",00:12:06.610,00:12:13.300
"I hope I got it right, is --",00:12:13.300,00:12:15.590
can you see whether --,00:12:15.590,00:12:18.000
"if I take the inner product of
one column with another one,",00:12:18.000,00:12:21.390
"let's see, if I take
the inner product",00:12:21.390,00:12:23.490
"of that column with that I have
two minuses and two pluses,",00:12:23.490,00:12:26.570
that's good.,00:12:26.570,00:12:27.460
"When I take the inner
product of that with that",00:12:27.460,00:12:29.780
"I have a plus and a
minus, a minus and a plus.",00:12:29.780,00:12:32.891
Good.,00:12:32.891,00:12:33.390
I think it all works out.,00:12:33.390,00:12:35.030
"And what do I have
to divide by now?",00:12:35.030,00:12:37.710
To make those into unit vectors.,00:12:37.710,00:12:40.005
"Right now the vector one,
one, one, one has length two.",00:12:42.820,00:12:50.020
Square root of four.,00:12:50.020,00:12:51.160
"So I have to divide by two
to make it unit vector,",00:12:51.160,00:12:55.180
so there's another.,00:12:55.180,00:12:56.690
"That's my entire array
of simple examples.",00:12:56.690,00:13:01.050
"This construction is named after
a guy called Adhemar and we",00:13:04.690,00:13:12.110
"know how to do it for
two, four, sixteen,",00:13:12.110,00:13:18.460
"sixty-four and so on, but we --
nobody knows exactly which size",00:13:18.460,00:13:26.170
matrices have --,00:13:26.170,00:13:28.470
"which size -- which sizes allow
orthogonal matrices of ones",00:13:28.470,00:13:33.750
and minus ones.,00:13:33.750,00:13:34.800
"So Adhemar matrix is an
orthogonal matrix that's got",00:13:34.800,00:13:39.950
"ones and minus ones, and a
lot of ones -- some we know,",00:13:39.950,00:13:45.570
"some other sizes, there couldn't
be a five by five I think.",00:13:45.570,00:13:49.630
"But there are some
sizes that nobody",00:13:49.630,00:13:51.470
"yet knows whether there could be
or can't be a matrix like that.",00:13:51.470,00:13:57.720
OK.,00:13:57.720,00:13:58.660
"You see those
orthogonal matrices.",00:13:58.660,00:14:03.360
"Now let me ask what -- why
is it good to have orthogonal",00:14:03.360,00:14:10.410
matrices?,00:14:10.410,00:14:11.550
What calculation is made easy?,00:14:11.550,00:14:15.330
If I have an orthogonal matrix.,00:14:15.330,00:14:17.540
"And -- let me remember that the
matrix could be rectangular.",00:14:17.540,00:14:22.160
Shall I put down --,00:14:22.160,00:14:23.380
"I better put a
rectangular example down.",00:14:23.380,00:14:26.180
"So the -- these were
all square examples.",00:14:26.180,00:14:28.770
Can I put down just --,00:14:28.770,00:14:30.410
"a rectangular one
just to be sure",00:14:30.410,00:14:33.690
"that we realize that
this is possible.",00:14:33.690,00:14:37.580
let's help me out.,00:14:37.580,00:14:39.430
"Let's see, if I put like a
one, two, two and a minus two,",00:14:39.430,00:14:49.370
"minus one, two.",00:14:49.370,00:14:51.135
"That's -- a matrix -- oh its
columns aren't normalized yet.",00:14:56.030,00:15:00.840
"I always have to
remember to do that.",00:15:00.840,00:15:03.450
"I always do that last
because it's easy to do.",00:15:03.450,00:15:06.090
"What's the length
of those columns?",00:15:06.090,00:15:08.960
"So if I wanted them -- if I
wanted them to be length one,",00:15:08.960,00:15:11.920
"I should divide by their
length, which is --",00:15:11.920,00:15:15.340
"so I'd look at one squared plus
two squared plus two squared,",00:15:15.340,00:15:18.940
"that's one and four
and four is nine,",00:15:18.940,00:15:21.920
"so I take the square root and
I need to divide by three.",00:15:21.920,00:15:26.920
OK.,00:15:26.920,00:15:27.420
So there is --,00:15:27.420,00:15:30.280
"well, without that, I've
got one orthonormal vector.",00:15:30.280,00:15:36.820
I mean just one unit vector.,00:15:36.820,00:15:39.560
Now put that guy in.,00:15:39.560,00:15:41.630
"Now I have a basis
for the column",00:15:41.630,00:15:44.730
"space for a two-dimensional
space, an orthonormal basis,",00:15:44.730,00:15:50.480
right?,00:15:50.480,00:15:51.000
"These two columns
are orthonormal,",00:15:51.000,00:15:53.640
"they would be an
orthonormal basis",00:15:53.640,00:15:56.160
"for this two-dimensional
space that they span.",00:15:56.160,00:16:00.690
"Orthonormal vectors by the way
have got to be independent.",00:16:00.690,00:16:04.200
"It's easy to show that
orthonormal vectors",00:16:04.200,00:16:08.410
"since they're headed off
all at ninety degrees",00:16:08.410,00:16:11.140
"there's no combination
that gives zero.",00:16:11.140,00:16:14.130
"Now if I wanted to
create now a third one,",00:16:14.130,00:16:22.470
"I could either just put in
some third vector that was",00:16:22.470,00:16:28.720
"independent and go to this
Graham-Schmidt calculation that",00:16:28.720,00:16:34.300
"I'm going to explain, or I
could be inspired and say look,",00:16:34.300,00:16:38.360
"that -- with that pattern,
why not put a one in there,",00:16:38.360,00:16:42.490
"and a two in there,
and a two in there,",00:16:42.490,00:16:45.150
"and try to fix up the
signs so that they worked.",00:16:45.150,00:16:48.760
Hmm.,00:16:52.030,00:16:52.570
"I don't know if I've done
this too brilliantly.",00:16:52.570,00:16:56.750
"Let's see, what
signs, that's minus,",00:16:56.750,00:16:58.730
"maybe I'd make a minus sign
there, how would that be?",00:16:58.730,00:17:04.770
"Yeah, maybe that works.",00:17:04.770,00:17:08.490
"I think that those three columns
are orthonormal and they --",00:17:08.490,00:17:15.670
"the beauty of this -- this is
the last example I'll probably",00:17:15.670,00:17:19.220
"find where there's no
square root, the --",00:17:19.220,00:17:23.599
"the punishing thing
in Graham-Schmidt,",00:17:23.599,00:17:26.750
"maybe we better know
that in advance,",00:17:26.750,00:17:30.220
"is that because I want these
vectors to be unit vectors,",00:17:30.220,00:17:35.450
"I'm always running
into square roots.",00:17:35.450,00:17:37.400
I'm always dividing by lengths.,00:17:37.400,00:17:39.770
"And those lengths
are square roots.",00:17:39.770,00:17:41.610
"So you'll see as soon as I
do a Graham-Schmidt example,",00:17:41.610,00:17:45.400
"square roots are
going to show up.",00:17:45.400,00:17:47.690
"But here are some
examples where we did it",00:17:47.690,00:17:50.460
without any square root.,00:17:50.460,00:17:52.350
OK.,00:17:52.350,00:17:53.160
OK.,00:17:53.160,00:17:54.400
So -- so great.,00:17:54.400,00:17:57.610
"Now next question is what's
the good of having a Q?",00:17:57.610,00:18:06.260
What formulas become easier?,00:18:06.260,00:18:08.360
"Suppose I want to
project, so suppose Q --",00:18:08.360,00:18:13.040
"suppose Q has
orthonormal columns.",00:18:13.040,00:18:18.510
"I'm using the letter
Q to mean this,",00:18:18.510,00:18:20.650
"I'll write it this
one more time,",00:18:20.650,00:18:22.630
"but I always mean
when I write a Q,",00:18:22.630,00:18:27.620
"I always mean that it
has orthonormal columns.",00:18:27.620,00:18:30.410
"So suppose I want to project
onto its column space.",00:18:30.410,00:18:41.415
So what's the projection matrix?,00:18:47.090,00:18:48.670
"What's the projection matrix is
I project onto a column space?",00:18:51.980,00:18:56.260
"OK, that gives me a chance to
review the projection section,",00:18:56.260,00:19:01.810
"including that big formula,
which used to be --",00:19:01.810,00:19:06.270
"those four As in a
row, but now it's",00:19:06.270,00:19:09.080
"got Qs, because I'm projecting
onto the column space of Q,",00:19:09.080,00:19:12.850
so do you remember what it was?,00:19:12.850,00:19:14.280
"It's Q Q transpose Q
inverse Q transpose.",00:19:14.280,00:19:21.200
That's my four Qs in a row.,00:19:24.000,00:19:27.890
But what's good here?,00:19:27.890,00:19:29.190
"What -- what makes this formula
nice if I'm projecting onto",00:19:31.990,00:19:36.540
"a column space when I have
orthonormal basis for that",00:19:36.540,00:19:40.160
space?,00:19:40.160,00:19:40.940
"What makes it nice is
this is the identity.",00:19:40.940,00:19:44.610
"I don't have to
do any inversion.",00:19:44.610,00:19:46.860
I just get Q Q transpose.,00:19:46.860,00:19:48.690
"So Q Q transpose is
a projection matrix.",00:19:55.670,00:19:59.750
"Oh, I can't help --",00:19:59.750,00:20:01.090
"I can't resist just
checking the properties,",00:20:01.090,00:20:03.470
"what are the properties
of a projection matrix?",00:20:03.470,00:20:08.140
"There are two properties to
know for any projection matrix.",00:20:08.140,00:20:12.780
"And I'm saying that this
is the right projection",00:20:12.780,00:20:16.060
"matrix when we've got
this orthonormal basis",00:20:16.060,00:20:20.000
in the columns.,00:20:20.000,00:20:22.480
OK.,00:20:22.480,00:20:23.040
"So there's the
projection matrix.",00:20:23.040,00:20:26.150
Suppose the matrix is square.,00:20:26.150,00:20:29.170
"First just tell me
first this extreme case.",00:20:29.170,00:20:32.590
"If my matrix is square and it's
got these orthonormal columns,",00:20:32.590,00:20:37.690
then what's the column space?,00:20:37.690,00:20:41.670
"If I have a square matrix and
I have independent columns,",00:20:41.670,00:20:46.770
"and even orthonormal columns,
then the column space",00:20:46.770,00:20:50.450
"is the whole space, right?",00:20:50.450,00:20:52.670
"And what's the projection
matrix onto the whole space?",00:20:52.670,00:20:56.750
The identity matrix.,00:20:56.750,00:20:59.290
"If I'm projecting
in the whole space,",00:20:59.290,00:21:00.860
"every vector B is right
where it's supposed to be",00:21:00.860,00:21:05.190
"and I don't have to
move it by projection.",00:21:05.190,00:21:08.310
So this would be --,00:21:08.310,00:21:13.300
"I'll put in parentheses
this is I if Q is square.",00:21:13.300,00:21:17.890
Well that we said that already.,00:21:23.390,00:21:25.860
"If Q is square, that's the case
where Q transpose is Q inverse,",00:21:25.860,00:21:30.490
"we can put it on the right,
we can put it on the left,",00:21:30.490,00:21:33.640
"we always get the identity
matrix, if it's square.",00:21:33.640,00:21:38.500
"But if it's not a square
matrix then it's not --",00:21:38.500,00:21:44.570
"we don't get the
identity matrix.",00:21:44.570,00:21:48.010
"We have Q Q transpose,
and just again",00:21:48.010,00:21:53.210
"what are those two properties
of a projection matrix?",00:21:53.210,00:21:56.550
"First of all, it's symmetric.",00:21:56.550,00:21:59.900
"OK, no problem, that's
certainly a symmetric So what's",00:21:59.900,00:22:04.370
"that second property
of a projection?",00:22:04.370,00:22:06.360
matrix.,00:22:06.360,00:22:06.860
"That if you project and project
again you don't move the second",00:22:06.860,00:22:10.510
time.,00:22:10.510,00:22:11.260
"So the other property
of a projection matrix",00:22:11.260,00:22:13.720
"should be that Q
Q transpose twice",00:22:13.720,00:22:19.570
"should be the same as
Q Q transpose once.",00:22:19.570,00:22:24.820
That's projection matrices.,00:22:24.820,00:22:27.050
"And that property
better fall out",00:22:27.050,00:22:29.670
"right away because
from the fact we",00:22:29.670,00:22:34.040
"know about orthonormal matrices,
Q transpose Q is I. OK,",00:22:34.040,00:22:39.560
you see it.,00:22:39.560,00:22:40.510
"In the middle here is sitting
Q Q t- Q transpose Q, sorry,",00:22:40.510,00:22:45.820
"that's what I meant to
say, Q transpose Q is I.",00:22:45.820,00:22:49.530
"So that's sitting right in
the middle, that cancels out,",00:22:49.530,00:22:52.500
"to give the identity, we're
left with one Q Q transpose,",00:22:52.500,00:22:56.260
and we're all set.,00:22:56.260,00:22:58.980
OK.,00:22:58.980,00:22:59.680
"So this is the
projection matrix --",00:22:59.680,00:23:04.340
"all the equation -- all the
messy equations of this chapter",00:23:04.340,00:23:10.170
"become trivial
when our matrix --",00:23:10.170,00:23:14.870
"when we have this
orthonormal basis.",00:23:14.870,00:23:18.040
"I mean what do I mean
by all the equations?",00:23:18.040,00:23:20.130
"Well, the most
important equation",00:23:20.130,00:23:21.780
"was the normal equation, do
you remember old A transpose",00:23:21.780,00:23:26.180
A x hat equals A transpose b?,00:23:26.180,00:23:31.120
But now -- now A is Q.,00:23:31.120,00:23:37.700
"Now I'm thinking I have
Q transpose Q X hat",00:23:37.700,00:23:43.640
equals Q transpose b.,00:23:43.640,00:23:47.500
And what's good about that?,00:23:47.500,00:23:48.780
"What's good is that matrix on
the left side is the identity.",00:23:52.720,00:23:58.450
"The matrix on the left is
the identity, Q transpose Q,",00:23:58.450,00:24:01.610
"normally it isn't, normally it's
that matrix of inner products",00:24:01.610,00:24:05.010
"and you've to compute all those
dopey inner products and --",00:24:05.010,00:24:09.370
and -- and solve the system.,00:24:09.370,00:24:11.530
"Here the inner products
are all one or zero.",00:24:11.530,00:24:15.450
This is the identity matrix.,00:24:15.450,00:24:17.040
It's gone.,00:24:17.040,00:24:18.780
And there's the answer.,00:24:18.780,00:24:21.410
There's no inversion involved.,00:24:21.410,00:24:24.640
"Each component of
x is a Q times b.",00:24:24.640,00:24:31.230
"What that equation is saying
is that the i-th component is",00:24:31.230,00:24:36.740
the i-th basis vector times b.,00:24:36.740,00:24:41.920
"That's -- probably the most
important formula in some major",00:24:41.920,00:24:50.260
"parts of mathematics, that
if we have orthonormal basis,",00:24:50.260,00:24:56.220
"then the component in the --
in the i-th, along the i-th --",00:24:56.220,00:25:03.160
"the projection on the i-th basis
vector is just qi transpose b.",00:25:03.160,00:25:10.130
"That number x that we look
for is just a dot product.",00:25:10.130,00:25:16.080
OK.,00:25:16.080,00:25:16.580
"OK, so I'm ready now for
the sort of like second half",00:25:19.550,00:25:25.540
of the lecture.,00:25:25.540,00:25:27.030
"Where we don't start with
an orthogonal matrix,",00:25:27.030,00:25:31.820
orthonormal vectors.,00:25:31.820,00:25:34.410
"We just start with
independent vectors",00:25:34.410,00:25:37.110
"and we want to make
them orthonormal.",00:25:37.110,00:25:40.870
"So I'm going to --
can I do that now?",00:25:40.870,00:25:43.360
Now here comes Graham-Schmidt.,00:25:43.360,00:25:45.440
So -- Graham-Schmidt.,00:25:45.440,00:25:46.990
"So this is a calculation,
I won't say --",00:25:54.960,00:25:59.490
"I can't quite say it's like
elimination, because it's",00:25:59.490,00:26:08.690
"different, our goal
isn't triangular anymore.",00:26:08.690,00:26:12.130
"With elimination our goal was
make the matrix triangular.",00:26:12.130,00:26:16.280
"Now our goal is make
the matrix orthogonal.",00:26:16.280,00:26:19.700
Make those columns orthonormal.,00:26:19.700,00:26:23.080
"So let me start
with two columns.",00:26:23.080,00:26:25.740
So I start with vectors a and b.,00:26:25.740,00:26:28.505
"And they're just like --
here, let me draw them.",00:26:32.460,00:26:35.930
Here's a.,00:26:35.930,00:26:38.280
Here's b.,00:26:38.280,00:26:38.905
For example.,00:26:41.870,00:26:43.080
"A isn't specially
horizontal, wasn't",00:26:43.080,00:26:45.200
"meant to be, just a is
one vector, b is another.",00:26:45.200,00:26:49.650
"I want to produce
those two vectors,",00:26:49.650,00:26:53.540
"they might be in
twelve-dimensional space,",00:26:53.540,00:26:56.260
"or they might be in
two-dimensional space.",00:26:56.260,00:26:59.440
"They're independent, anyway.",00:26:59.440,00:27:01.800
So I better be sure I say that.,00:27:01.800,00:27:05.000
"I start with
independent vectors.",00:27:05.000,00:27:06.830
"And I want to produce
out of that q 1 and q2,",00:27:10.360,00:27:14.000
"I want to produce
orthonormal vectors.",00:27:14.000,00:27:16.470
"And Graham and
Schmidt tell me how.",00:27:19.380,00:27:25.230
OK.,00:27:25.230,00:27:25.760
"Well, actually you could tell me
how, we don't need -- frankly,",00:27:25.760,00:27:29.830
"I don't know -- there's
only one idea here,",00:27:29.830,00:27:33.300
"if Graham had the idea, I
don't know what Schmidt did.",00:27:33.300,00:27:40.350
But OK.,00:27:40.350,00:27:43.640
So you'll see it.,00:27:43.640,00:27:44.970
"We don't need either
of them, actually.",00:27:44.970,00:27:47.400
"OK, so what I going to do.",00:27:47.400,00:27:49.130
"I'll take that --
this first guy.",00:27:49.130,00:27:52.130
OK.,00:27:52.130,00:27:53.470
"Well, he's fine.",00:27:53.470,00:27:55.290
That direction is fine except --,00:27:58.980,00:28:02.120
"yeah, I'll say OK, I'll
settle for that direction.",00:28:02.120,00:28:05.800
So I'm going to --,00:28:05.800,00:28:06.910
"I'm going to get, so
what I going to --",00:28:06.910,00:28:09.130
"my goal is I'm going to
get orthogonal vectors",00:28:09.130,00:28:14.870
"and I'll call those
capital A and B.",00:28:14.870,00:28:18.280
"So that's the key step is
to get from any two vectors",00:28:18.280,00:28:23.090
to two orthogonal vectors.,00:28:23.090,00:28:24.930
"And then at the end, no problem,
I'll get orthonormal vectors,",00:28:24.930,00:28:30.030
"how will -- what will those
will be my qs, q1 and q2,",00:28:30.030,00:28:36.130
and what will they,00:28:36.130,00:28:36.950
be?,00:28:36.950,00:28:37.450
"Once I've got A and B
orthogonal, well, look,",00:28:41.480,00:28:45.770
"it's no big deal -- maybe
that's what Schmidt did, he,",00:28:45.770,00:28:50.890
"brilliant Schmidt, thought
OK, divide by the length,",00:28:50.890,00:28:54.340
all right.,00:28:54.340,00:28:55.810
That's Schmidt's contribution.,00:28:55.810,00:28:58.325
OK.,00:29:01.140,00:29:01.640
"But Graham had a little
more thinking to do, right?",00:29:06.750,00:29:11.120
We haven't done Graham's part.,00:29:11.120,00:29:14.280
"This part except OK,
I'm happy with A,",00:29:14.280,00:29:18.550
"A can be A. That first
direction is fine.",00:29:18.550,00:29:22.670
"Why should -- no
complaint about that.",00:29:22.670,00:29:25.120
"The trouble is the second
direction is not fine.",00:29:25.120,00:29:29.120
"Because it's not
orthogonal to the first.",00:29:29.120,00:29:33.670
"I'm looking for a vector
that's -- starts with B,",00:29:33.670,00:29:39.210
but makes it orthogonal to A.,00:29:39.210,00:29:45.050
What's the vector?,00:29:45.050,00:29:46.480
How do I do that?,00:29:46.480,00:29:48.370
"How do I produce
from this vector",00:29:48.370,00:29:51.460
"a piece that's
orthogonal to this one?",00:29:51.460,00:29:57.320
"And the -- remember these
vectors might be in two",00:29:57.320,00:30:00.400
"dimensions or they might
be in twelve dimensions.",00:30:00.400,00:30:04.070
I'm just looking for the idea.,00:30:04.070,00:30:06.710
So what's the idea?,00:30:06.710,00:30:09.340
Where did we have orthogonal --,00:30:09.340,00:30:12.610
"a vector showing up that
was orthogonal to this guy?",00:30:12.610,00:30:16.940
"Well, that was the
first basic calculation",00:30:16.940,00:30:19.490
of the whole chapter.,00:30:19.490,00:30:21.280
"We -- we did a projection and
the projection gave us this",00:30:21.280,00:30:26.350
"part, which was the
part in the A direction.",00:30:26.350,00:30:31.390
"Now, the part we want is
the other part, the e part.",00:30:31.390,00:30:35.000
This part.,00:30:35.000,00:30:36.550
This is going to be our --,00:30:36.550,00:30:39.290
that guy is that guy.,00:30:39.290,00:30:40.950
"This is our vector B. That gives
us that ninety-degree angle.",00:30:40.950,00:30:46.610
So B is you could say --,00:30:46.610,00:30:48.740
"B is really what we
previously called",00:30:48.740,00:30:51.230
e.,00:30:51.230,00:30:52.640
The error vector.,00:30:52.640,00:30:56.560
And what is it?,00:30:56.560,00:30:58.450
"I mean what do I
-- what is B here?",00:30:58.450,00:31:01.450
"A is A, no problem.",00:31:01.450,00:31:03.190
B is --,00:31:03.190,00:31:07.910
"OK, what's this error piece?",00:31:07.910,00:31:09.620
Do you remember?,00:31:09.620,00:31:12.030
"It's I start with the original
B and I take away what?",00:31:12.030,00:31:19.650
"Its projection, this P.
This -- the vector B,",00:31:19.650,00:31:24.170
"this error vector, is the
original vector removing",00:31:24.170,00:31:27.660
the projection.,00:31:27.660,00:31:28.390
"So instead of wanting
the projection,",00:31:28.390,00:31:31.090
"now that's what I
want to throw away.",00:31:31.090,00:31:35.760
"I want to get the part
that's perpendicular.",00:31:35.760,00:31:38.280
"And there will be a
perpendicular part,",00:31:38.280,00:31:40.220
it won't be zero.,00:31:40.220,00:31:40.955
"Because these vectors
were independent, so B --",00:31:44.390,00:31:48.380
"if B was along the
direction of A,",00:31:48.380,00:31:50.380
"then if the original B and A
were in the same direction,",00:31:50.380,00:31:53.330
then I'm --,00:31:53.330,00:31:54.260
I've only got one direction.,00:31:54.260,00:31:56.000
"But here they're in two
independent directions",00:31:56.000,00:31:58.940
"and all I'm doing
is getting that guy.",00:31:58.940,00:32:01.690
So what's its formula?,00:32:01.690,00:32:05.050
"What's the formula
for that if --",00:32:05.050,00:32:09.010
"I want to subtract
the projection,",00:32:09.010,00:32:11.040
"so do you remember
the projection?",00:32:11.040,00:32:12.950
"It's some multiple of A
and what's that multiple?",00:32:12.950,00:32:18.990
"It's -- it's that thing we
called x in the very very first",00:32:18.990,00:32:22.530
lecture on this chapter.,00:32:22.530,00:32:25.650
"There's an A transpose
A in the bottom",00:32:25.650,00:32:32.040
"and there's an A transpose
B, isn't that it?",00:32:32.040,00:32:39.495
I think that's Graham's formula.,00:32:45.280,00:32:47.740
Or Graham-Schmidt.,00:32:47.740,00:32:48.800
"No, that's Graham.",00:32:48.800,00:32:50.100
"Schmidt has got to divide the
whole thing by the length,",00:32:50.100,00:32:53.620
so he --,00:32:53.620,00:32:55.160
"his formula makes a mess which
I'm not willing to write down.",00:32:55.160,00:32:58.780
"So let's just see that
what I saying here?",00:32:58.780,00:33:03.570
"I'm saying that this vector
is perpendicular to A.",00:33:03.570,00:33:07.170
That these are orthogonal.,00:33:07.170,00:33:08.760
A is perpendicular to B.,00:33:08.760,00:33:12.210
Can you check that?,00:33:12.210,00:33:13.990
"How do you see that
yes, of course, we --",00:33:13.990,00:33:16.930
"our picture is telling
us, yes, we did it right.",00:33:16.930,00:33:19.660
"How would I check that this
matrix is perpendicular to A?",00:33:19.660,00:33:24.224
"I would multiply by A transpose
and I better get zero, right?",00:33:26.890,00:33:32.240
I should check that.,00:33:32.240,00:33:33.910
"A transpose B should
come out zero.",00:33:33.910,00:33:38.430
"So this is A transpose times
-- now what did we say B was?",00:33:38.430,00:33:42.420
"We start with the original
B, and we take away",00:33:42.420,00:33:45.870
"this projection, and that
should come out zero.",00:33:45.870,00:33:53.590
"Well, here we get an
A transpose B minus --",00:33:53.590,00:33:58.450
"and here is another A
transpose B, and the --",00:33:58.450,00:34:01.550
"and it's an A transpose A
over A transpose A, a one,",00:34:01.550,00:34:05.620
"those cancel, and
we do get zero.",00:34:05.620,00:34:09.340
Right.,00:34:09.340,00:34:09.840
"Now I guess I can
do numbers in there.",00:34:13.860,00:34:21.449
"But I have to take
a third vector",00:34:21.449,00:34:24.920
"to be sure we've got
this system down.",00:34:24.920,00:34:28.830
"So now I have to say if I have
independent vectors A, B and C,",00:34:28.830,00:34:35.750
"I'm looking for orthogonal
vectors A, B and capital C,",00:34:35.750,00:34:41.320
"and then of course the
third guy will just",00:34:41.320,00:34:44.670
"be C over its length,
the unit vector.",00:34:44.670,00:34:48.479
So this is now the problem.,00:34:51.360,00:34:55.489
I got B here.,00:34:55.489,00:34:58.430
I got A very easily.,00:34:58.430,00:35:01.390
"And now -- if you see the idea,
we could figure out a formula",00:35:01.390,00:35:08.110
"for C. So now that -- so this
is like a typical homework quiz",00:35:08.110,00:35:16.890
problem.,00:35:16.890,00:35:17.650
"I give you two vectors, you do
this, I give you three vectors,",00:35:17.650,00:35:22.760
"and you have to make
them orthonormal.",00:35:22.760,00:35:25.960
"So you do this again,
the first vector's fine,",00:35:25.960,00:35:29.020
"the second vector is
perpendicular to the first,",00:35:29.020,00:35:32.660
"and now I need a
third vector that's",00:35:32.660,00:35:35.220
"perpendicular to the first
one and the second one.",00:35:35.220,00:35:38.740
Right?,00:35:38.740,00:35:41.060
"Tthis is the end of a -- the
lecture is to find this guy.",00:35:41.060,00:35:45.160
"Find this vector -- this vector
C, that's perpendicular we n-",00:35:45.160,00:35:49.480
at this point we know A and B.,00:35:49.480,00:35:54.910
"But C, the little c that
we're given, is off in some --",00:35:54.910,00:36:00.040
"it's got to come out of the
blackboard to be independent,",00:36:00.040,00:36:03.530
"so -- so can I sort of draw
off -- off comes a c somewhere.",00:36:03.530,00:36:07.949
"I don't know, where I
going to put the darn",00:36:07.949,00:36:09.740
thing?,00:36:09.740,00:36:10.550
"Maybe I'll put it
off, oh, I don't know,",00:36:10.550,00:36:14.950
"like that somehow, C, little c.",00:36:14.950,00:36:17.660
"And I already know that
perpendicular direction,",00:36:21.110,00:36:24.430
that one and that one.,00:36:24.430,00:36:26.250
So now what's the idea?,00:36:26.250,00:36:29.300
"Give me the Graham-Schmidt
formula for C.",00:36:29.300,00:36:32.580
What is this C here?,00:36:32.580,00:36:36.200
Equals what?,00:36:36.200,00:36:37.020
What I going to do?,00:36:42.840,00:36:43.660
I'll start with the given one.,00:36:43.660,00:36:46.800
As before.,00:36:46.800,00:36:48.230
Right?,00:36:48.230,00:36:48.780
"I start with the
vector I'm given.",00:36:48.780,00:36:51.910
And what do I do with it?,00:36:51.910,00:36:53.900
"I want to remove out of
it, I want to subtract off,",00:36:53.900,00:36:57.560
"so I'll put a minus sign
in, I want to subtract off",00:36:57.560,00:37:02.010
"its components in the A, capital
A and capital B directions.",00:37:02.010,00:37:08.510
"I just want to get
those out of there.",00:37:08.510,00:37:11.350
"Well, I know how to do that.",00:37:11.350,00:37:12.790
I did it with B.,00:37:12.790,00:37:14.210
"So I'll just -- so
let me take away --",00:37:14.210,00:37:17.910
what if I do this?,00:37:17.910,00:37:18.940
What have I done?,00:37:23.460,00:37:24.350
"I've got little c and what
have I subtracted from it?",00:37:27.560,00:37:32.020
"Its component, its projection
if you like, in the A direction.",00:37:32.020,00:37:37.780
"And now I've got to subtract
off its component B transpose",00:37:40.510,00:37:46.320
"C over B transpose B,
that multiple of B,",00:37:46.320,00:37:50.700
"is its component
in the B direction.",00:37:50.700,00:37:53.075
"And that gives me the vector
capital C that if anything is",00:37:55.600,00:38:02.980
--,00:38:02.980,00:38:03.660
"if there's any justice, this
C should be perpendicular to A",00:38:03.660,00:38:10.200
"and it should be
perpendicular to B.",00:38:10.200,00:38:14.250
"And the only thing it's --
hasn't got is unit vector,",00:38:14.250,00:38:18.160
"so we divide by its
length to get that too.",00:38:18.160,00:38:21.330
OK.,00:38:24.160,00:38:25.890
Let me do an example.,00:38:25.890,00:38:30.440
Can I --,00:38:30.440,00:38:31.910
"I'll make my life easy,
I'll just take two vectors.",00:38:31.910,00:38:36.490
"So let me do a
numerical example.",00:38:36.490,00:38:39.380
"If I'll give you
two vectors, you",00:38:39.380,00:38:41.980
"give me back the Graham-Schmidt
orthonormal basis,",00:38:41.980,00:38:46.720
"and we'll see how to
express that in matrix form.",00:38:46.720,00:38:51.490
OK.,00:38:51.490,00:38:52.030
"So let me give you
the two vectors.",00:38:52.030,00:38:56.580
"So I'll take the vector A
equals let's say one, one, one,",00:38:56.580,00:39:01.920
why not?,00:39:01.920,00:39:03.410
"And B equals let's say
one, zero, two, OK?",00:39:03.410,00:39:11.316
"I didn't want to cheat
and make them orthogonal",00:39:17.900,00:39:20.800
"in the first place because
then Graham-Schmidt",00:39:20.800,00:39:22.830
wouldn't be needed.,00:39:22.830,00:39:23.931
OK.,00:39:23.931,00:39:24.430
So those are not orthogonal.,00:39:24.430,00:39:26.260
So what is capital A?,00:39:26.260,00:39:27.830
Well that's the same as big A.,00:39:27.830,00:39:29.780
That was fine.,00:39:29.780,00:39:30.850
What's B?,00:39:30.850,00:39:34.090
"So B is this b --
is the original B,",00:39:34.090,00:39:37.100
"and then I subtract off
some multiple of the A.",00:39:37.100,00:39:45.180
And what's the multiple?,00:39:45.180,00:39:46.400
What goes in here?,00:39:49.310,00:39:52.020
"B -- here's the A -- this is
the -- this is the little b,",00:39:52.020,00:39:56.740
"this is the big A, also
the little a, and I want",00:39:56.740,00:40:00.930
"to multiply it by that
right -- that right ratio,",00:40:00.930,00:40:04.180
"which has A transpose
A, here's my ratio.",00:40:04.180,00:40:08.980
I'm just doing this.,00:40:08.980,00:40:12.600
"So it's A transpose B,
what is A transpose B,",00:40:12.600,00:40:16.110
it looks like three.,00:40:16.110,00:40:18.290
"And what is A -- oh, my --",00:40:18.290,00:40:22.280
what's A transpose A?,00:40:22.280,00:40:23.971
Three.,00:40:23.971,00:40:24.470
I'm sorry.,00:40:27.040,00:40:28.190
"I didn't know that
was going to happen.",00:40:28.190,00:40:30.490
OK.,00:40:30.490,00:40:30.990
But it happened.,00:40:30.990,00:40:31.940
Why should we knock it?,00:40:31.940,00:40:34.250
OK.,00:40:34.250,00:40:35.110
So do you see it all right?,00:40:35.110,00:40:36.930
"That's A transpose B,
there's A transpose A, that's",00:40:36.930,00:40:40.540
"the fraction, so
I take this away,",00:40:40.540,00:40:44.140
"and I get one take away one
is a zero, zero minus this one",00:40:44.140,00:40:49.140
"is a minus one, and two
minus the one is a one.",00:40:49.140,00:40:54.680
OK.,00:40:54.680,00:40:55.430
"And what's this vector
that we finally found?",00:40:55.430,00:40:57.830
This is B.,00:40:57.830,00:41:02.520
And how do I know it's right?,00:41:02.520,00:41:04.080
"How do I know I've
got a vector I want?",00:41:07.430,00:41:10.190
"I check that B is
perpendicular to --",00:41:10.190,00:41:13.200
that A and B are perpendicular.,00:41:13.200,00:41:15.480
That A is perpendicular to B.,00:41:15.480,00:41:17.780
Just look at that.,00:41:17.780,00:41:18.690
"That one -- the dot product
of that with that is zero.",00:41:18.690,00:41:22.050
OK.,00:41:22.050,00:41:22.680
So now what is my q1 and q2?,00:41:22.680,00:41:26.355
"Why don't I put
them in a matrix?",00:41:30.220,00:41:33.200
Of course.,00:41:33.200,00:41:33.980
"Since I'm always putting
these -- so the Q,",00:41:33.980,00:41:36.470
"I'll put the q1 and
the q2 in a matrix.",00:41:36.470,00:41:39.760
And what are they?,00:41:39.760,00:41:41.220
"Now when I'm writing
q-s I'm supposed",00:41:44.770,00:41:48.200
to make things normalized.,00:41:48.200,00:41:49.700
"I'm supposed to make
things unit vectors.",00:41:49.700,00:41:51.950
"So I'm going to take that A
but I'm going to divide it",00:41:51.950,00:41:55.240
by square root of three.,00:41:55.240,00:41:57.150
"And I'm going to
take this B but I'm",00:42:02.420,00:42:04.280
"going to divide it
by square root of two",00:42:04.280,00:42:08.870
"to make it a unit vector,
and there is my matrix.",00:42:08.870,00:42:13.226
"That's my matrix with
orthonormal columns coming from",00:42:16.500,00:42:20.930
"Graham-Schmidt and
it sort of it --",00:42:20.930,00:42:24.290
"it came from the original
one, one, one, one, zero, two,",00:42:24.290,00:42:30.240
right?,00:42:30.240,00:42:30.740
That was my original guys.,00:42:30.740,00:42:32.120
"These were the two
I started with.",00:42:36.380,00:42:38.700
"These are the two that
I'm happy to end with.",00:42:38.700,00:42:41.450
Because those are orthonormal.,00:42:41.450,00:42:45.610
"So that's what
Graham-Schmidt did.",00:42:45.610,00:42:48.990
"It -- well, tell me about
the column spaces of these",00:42:48.990,00:42:53.550
matrices.,00:42:53.550,00:42:55.760
"How is the column space of Q
related to the column space of",00:42:55.760,00:42:59.680
A?,00:42:59.680,00:43:00.400
"So I'm always asking
you things like this,",00:43:00.400,00:43:02.650
"and that makes you think,
OK, the column space",00:43:02.650,00:43:05.470
"is all combinations of the
columns, it's that plane,",00:43:05.470,00:43:10.050
right?,00:43:10.050,00:43:11.040
"I've got two vectors in
three-dimensional space,",00:43:11.040,00:43:14.270
"their column space is a plane,
the column space of this matrix",00:43:14.270,00:43:19.130
"is a plane, what's the
relation between the planes?",00:43:19.130,00:43:23.700
Between the two column spaces?,00:43:23.700,00:43:25.245
"They're one and the same, right?",00:43:28.250,00:43:30.690
It's the same column space.,00:43:30.690,00:43:33.260
"All I'm taking is here this
B thing that I computed,",00:43:33.260,00:43:39.080
"this B thing that I computed
is a combination of B and A,",00:43:39.080,00:43:45.620
"and A was little A, so
I'm always working here",00:43:45.620,00:43:50.130
with this in the same space.,00:43:50.130,00:43:52.420
"I'm just like getting
ninety-degree angles in there.",00:43:52.420,00:43:57.950
"Where my original column space
had a perfectly good basis,",00:43:57.950,00:44:02.950
"but it wasn't as
good as this basis,",00:44:02.950,00:44:05.970
because it wasn't orthonormal.,00:44:05.970,00:44:09.110
"Now this one is orthonormal,
and I have a basis then that --",00:44:09.110,00:44:15.060
"so now projections, all the
calculations I would ever want",00:44:15.060,00:44:18.550
"to do are -- are a cinch
with this orthonormal basis.",00:44:18.550,00:44:25.070
One final point.,00:44:25.070,00:44:28.210
One final point in this chapter.,00:44:28.210,00:44:29.980
"And it's -- just
like elimination.",00:44:32.700,00:44:36.740
"We learned how to
do elimination,",00:44:36.740,00:44:39.030
"we know all the
steps, we can do it.",00:44:39.030,00:44:41.660
"But then I came back to it and
said look at it as a matrix",00:44:41.660,00:44:50.220
"in matrix language and
elimination gave me --",00:44:50.220,00:44:55.640
"what was elimination
in matrix language?",00:44:55.640,00:44:57.980
I'll just put it up there.,00:44:57.980,00:44:59.500
A was LU.,00:44:59.500,00:45:01.740
"That was matrix,
that was elimination.",00:45:01.740,00:45:05.220
"Now, I want to do the
same for Graham-Schmidt.",00:45:05.220,00:45:08.680
"Everybody who works
in linear algebra",00:45:08.680,00:45:11.700
"isn't going to write
out the columns",00:45:11.700,00:45:14.030
"are orthogonal, or orthonormal.",00:45:14.030,00:45:16.720
"And isn't going to write
out these formulas.",00:45:16.720,00:45:20.030
"They're going to write out the
connection between the matrix A",00:45:20.030,00:45:24.320
and the matrix Q.,00:45:24.320,00:45:26.820
"And the two matrices have
the same column space,",00:45:26.820,00:45:29.730
"but there's some -- some
matrix is taking the --",00:45:29.730,00:45:33.220
"and I'm going to call it R, so
A equals QR is the magic formula",00:45:33.220,00:45:40.611
here.,00:45:40.611,00:45:41.110
"It's the expression
of Graham-Schmidt.",00:45:43.700,00:45:45.765
"And I'll -- let me
just capture that.",00:45:48.360,00:45:53.930
"So that's the -- my final
step then is A equal QR.",00:45:53.930,00:45:57.740
Maybe I can squeeze it in here.,00:45:57.740,00:45:59.810
"So A has columns,
let's say a1 and a2.",00:46:02.800,00:46:06.460
"Let me suppose n is
two, just two vectors.",00:46:10.920,00:46:14.650
OK.,00:46:14.650,00:46:15.790
"So that's some
combination of q1 and q2.",00:46:15.790,00:46:21.800
And times some matrix R.,00:46:21.800,00:46:28.670
They have the same column space.,00:46:28.670,00:46:31.830
"This is just -- this matrix just
includes in it whatever these",00:46:31.830,00:46:35.920
"numbers like three over three
and one over square root",00:46:35.920,00:46:38.930
"of three and one over
square root of two,",00:46:38.930,00:46:40.860
probably that's what it's got.,00:46:40.860,00:46:43.900
"One over square root of three,
one over square root of two,",00:46:43.900,00:46:46.640
"something there, but actually
it's got a zero there.",00:46:46.640,00:46:49.890
"So the main point about
this A equal QR is this R",00:46:53.190,00:47:00.760
"turns out to be
upper triangular.",00:47:00.760,00:47:03.770
"It turns out that this
zero is upper triangular.",00:47:03.770,00:47:06.258
We could see why.,00:47:09.010,00:47:11.940
"Let me see, I can put in
general formulas for what these",00:47:11.940,00:47:16.140
"This I think in here should
be the inner product of a1",00:47:16.140,00:47:20.699
with q1. are.,00:47:20.699,00:47:21.240
And this one should be the --,00:47:24.100,00:47:27.660
the inner product of a1 with q2.,00:47:27.660,00:47:31.730
"And that's what I
believe is zero.",00:47:31.730,00:47:34.470
"This will be something here,
and this will be something here",00:47:37.210,00:47:40.610
"with inner -- a1 transpose q2,
sorry a2 transpose q1 and a2",00:47:40.610,00:47:49.460
transpose q2.,00:47:49.460,00:47:50.560
But why is that guy zero?,00:47:50.560,00:47:52.635
Why is a1 q2 zero?,00:47:55.600,00:47:59.400
"That's the key to this being
-- this R here being upper",00:47:59.400,00:48:03.080
triangular.,00:48:03.080,00:48:04.610
"You know why a1q2 is
zero, because a1 --",00:48:04.610,00:48:10.600
that was my --,00:48:10.600,00:48:12.810
this was really a and b here.,00:48:12.810,00:48:15.680
This was really a and b.,00:48:15.680,00:48:18.200
So this is a transpose q2.,00:48:18.200,00:48:21.280
"And the whole point of
Graham-Schmidt was that we",00:48:21.280,00:48:24.880
"constructed these later q-s to
be perpendicular to the earlier",00:48:24.880,00:48:30.320
"vectors, to the earlier --
all the earlier vectors.",00:48:30.320,00:48:34.530
"So that's why we get
a triangular matrix.",00:48:34.530,00:48:36.590
"The -- result is
extremely satisfactory.",00:48:39.300,00:48:45.252
"That if I have a matrix
with independent columns,",00:48:48.030,00:48:52.950
"the Graham-Schmidt
produces a matrix",00:48:52.950,00:48:56.040
"with orthonormal columns, and
the connection between those",00:48:56.040,00:49:00.280
is a triangular matrix.,00:49:00.280,00:49:03.730
"That last point, that the
connection is a triangular",00:49:03.730,00:49:06.700
"matrix, please look
in the book, you",00:49:06.700,00:49:09.010
have to see that one more time.,00:49:09.010,00:49:11.890
OK.,00:49:11.890,00:49:12.430
"Thanks, that's great.",00:49:12.430,00:49:14.670
